{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d65851d-3622-4eec-8475-e76f99e0d9c4",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74ae2fc8-f6d6-473c-b023-aeaeb617270a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import importlib to reload modules and sys and os to add the path for other imports\n",
    "import importlib\n",
    "import sys\n",
    "import os\n",
    "import torch\n",
    "from accelerate import Accelerator\n",
    "\n",
    "# Append the parent directory to the path to import the necessary modules\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "# Import the utilities and the dataloader\n",
    "from utils import trainutil, inferutil, setuputil\n",
    "\n",
    "# Now reload the modules to ensure they are up-to-date\n",
    "importlib.reload(setuputil)\n",
    "importlib.reload(trainutil)\n",
    "importlib.reload(inferutil)\n",
    "#importlib.reload(GeluAvgEmbed)\n",
    "\n",
    "# Import the funcs needed from utils\n",
    "from utils.setuputil import setup_bert_config, display_bert_config\n",
    "from utils.trainutil import train_model\n",
    "from utils.inferutil import infer_one, infer_full\n",
    "\n",
    "# Import the model class\n",
    "#from classes.GeluAvgEmbed import GeluAvgEmbed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb8749f-c28d-46a8-8712-595caf4c967e",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e002e5a6-33ca-45bc-85ea-825b9bc56713",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the input config file\n",
    "setup_config = {\n",
    "    # Environment and Model Info\n",
    "    \"env\": \"gcp\",                \n",
    "    \"approach\": \"bert\",         \n",
    "    \"model_name\": \"BertCustomAdd\",     \n",
    "    \"model_base\": \"prajjwal1/bert-tiny\",  \n",
    "    \n",
    "    # System Configuration\n",
    "    \"device\": \"cuda:0\",\n",
    "    \"threads\": 12,\n",
    "    \"seed\": 42,\n",
    "    \n",
    "    # Data Configuration\n",
    "    \"data_dir\": \"../../data/farzan\",\n",
    "    \"data_ds\": \"manual\",\n",
    "    \n",
    "    # Model Parameters\n",
    "    \"rows\": 100,\n",
    "    \"cols\": 100,\n",
    "    \"tokens\": 32,\n",
    "    \n",
    "    # Training Parameters\n",
    "    \"batch\": 40,\n",
    "    \"lr\": 5e-3,\n",
    "    \"mu\": 0.25,\n",
    "    \"epochs\": 20,\n",
    "    \"patience\": 2,\n",
    "    \"save_int\": 10,\n",
    "    \"save_dir\": '../models/'\n",
    "}\n",
    "\n",
    "new_config = {\n",
    "    # Environment and Model Info\n",
    "    \"env\": \"gcp\",                \n",
    "    \"approach\": \"simple\",         \n",
    "    \"model_name\": \"SimpleGeluEmbedAdd\",\n",
    "    \"model_base\": \"glove50\", \n",
    "    \n",
    "    # System Configuration\n",
    "    \"device\": \"cuda:0\",\n",
    "    \"threads\": 12,\n",
    "    \"seed\": 42,\n",
    "    \n",
    "    # Data Configuration\n",
    "    \"data_dir\": \"../../data/farzan\",\n",
    "    \"data_ds\": \"manual\",\n",
    "    \n",
    "    # Model Parameters\n",
    "    \"rows\": 100,\n",
    "    \"cols\": 100,\n",
    "    \"tokens\": 32,\n",
    "    \n",
    "    # Vocabulary Parameters\n",
    "    \"vocab_size\": 150000,\n",
    "    \"vocab_space\": True,\n",
    "    \"vocab_case\": \"both\",\n",
    "    \n",
    "    # Training Parameters\n",
    "    \"batch\": 40,\n",
    "    \"lr\": 5e-3,\n",
    "    \"mu\": 0.25,\n",
    "    \"epochs\": 20,\n",
    "    \"patience\": 2,\n",
    "    \"save_int\": 10,\n",
    "    \"save_dir\": '../models/'\n",
    "}\n",
    "\n",
    "# Define the input configuration for the RNN model\n",
    "rnn_config = {\n",
    "    # Environment and Model Info\n",
    "    \"env\": \"gcp\",                \n",
    "    \"approach\": \"rnn\",         \n",
    "    \"model_name\": \"Rnn2dSquare\",\n",
    "    \n",
    "    # System Configuration\n",
    "    \"device\": \"cuda:0\",\n",
    "    \"threads\": 12,\n",
    "    \"seed\": 42,\n",
    "    \n",
    "    # Data Configuration\n",
    "    \"data_dir\": \"../../data/farzan\",\n",
    "    \"data_ds\": \"manual\",\n",
    "    \n",
    "    # Model Parameters\n",
    "    \"rows\": 100,\n",
    "    \"cols\": 100,\n",
    "    \"tokens\": 32,\n",
    "    \n",
    "    # RNN-Specific Parameters\n",
    "    \"hidden_dim\": 100,         # Dimension of the hidden state vector\n",
    "    \"rnn_layers\": 2,           # Number of RNN layers\n",
    "    \"dropout_rate\": 0.05,      # Dropout rate for regularization\n",
    "    \"nonlinearity\": \"relu\",    # Nonlinearity for the RNN (e.g., relu, tanh)\n",
    "    \n",
    "    # Vocabulary Parameters\n",
    "    \"vocab_size\": 150000,\n",
    "    \"vocab_space\": True,\n",
    "    \"vocab_case\": \"both\",\n",
    "    \n",
    "    # Training Parameters\n",
    "    \"batch\": 10,\n",
    "    \"lr\": 7e-5,\n",
    "    \"mu\": 0.25,\n",
    "    \"epochs\": 20,\n",
    "    \"patience\": 3,\n",
    "    \"save_int\": 5,\n",
    "    \"save_dir\": '../models/'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d2df3f3f-defe-4d6d-8bc0-19ecf992176a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# General imports\n",
    "import os\n",
    "import torch\n",
    "import importlib\n",
    "import copy\n",
    "import json\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Reload the selfutil module and import required functions\n",
    "from utils import selfutil\n",
    "from classes import SpreadsheetDataLoader, BertLoader\n",
    "importlib.reload(selfutil)\n",
    "importlib.reload(SpreadsheetDataLoader)\n",
    "importlib.reload(BertLoader)\n",
    "from utils.selfutil import set_seed, get_vocab, create_embeddings, get_fileList\n",
    "from classes.SpreadsheetDataLoader import SpreadsheetDataLoader\n",
    "from classes.BertLoader import BertLoader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7cf2141a-2599-4a84-a1de-c6d3b18b82c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def h_env(setup_config):\n",
    "    \"\"\"Helper function to validate and setup environment-related configurations.\"\"\"\n",
    "    config = {}\n",
    "    \n",
    "    ######## ENVIRONMENT ########\n",
    "    valid_envs = [\"gcp\", \"bvm\", \"local\", \"colab\"]\n",
    "    valid_approaches = [\"simple\", \"saffu\", \"bert\", \"rnn\"]\n",
    "    \n",
    "    if setup_config[\"env\"] not in valid_envs:\n",
    "        raise ValueError(f\"ERR: env must be one of {valid_envs}\")\n",
    "    if setup_config[\"approach\"] not in valid_approaches:\n",
    "        raise ValueError(f\"ERR: approach must be one of {valid_approaches}\")\n",
    "        \n",
    "    config.update({\n",
    "        \"env\": setup_config[\"env\"],\n",
    "        \"approach\": setup_config[\"approach\"]\n",
    "    })\n",
    "    \n",
    "    ######## DEVICE ########\n",
    "    device_config = setup_config[\"device\"]\n",
    "    if (device_config.startswith(\"cuda\") and torch.cuda.is_available() \n",
    "        and int(device_config.split(\":\")[1]) < torch.cuda.device_count()):\n",
    "        config[\"DEVICE\"] = torch.device(device_config)\n",
    "    elif device_config.startswith(\"mps\") and hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "        config[\"DEVICE\"] = torch.device(\"mps\")\n",
    "    else:\n",
    "        config[\"DEVICE\"] = torch.device(\"cpu\")\n",
    "    \n",
    "    ######## THREADS ########\n",
    "    if not isinstance(setup_config[\"threads\"], (int, float)):\n",
    "        raise ValueError(\"ERR: threads must be a number\")\n",
    "    \n",
    "    threads = int(setup_config[\"threads\"])\n",
    "    if (os.cpu_count() - threads) < 4:\n",
    "        raise ValueError(f\"ERR: Must leave at least 4 threads free (requested {threads})\")\n",
    "    config[\"THREADS\"] = max(1, threads)\n",
    "    \n",
    "    ######## SEED ########\n",
    "    config[\"seed\"] = setup_config[\"seed\"]\n",
    "    set_seed(config[\"seed\"])\n",
    "    \n",
    "    return config\n",
    "\n",
    "def h_model(config, setup_config):\n",
    "    \"\"\"Helper function to setup model-related configurations.\"\"\"\n",
    "    \n",
    "    ######## MODEL ########\n",
    "    # Ensure model_name is always provided\n",
    "    if \"model_name\" not in setup_config:\n",
    "        raise ValueError(\"ERR: model_name must be provided for all approaches\")\n",
    "    \n",
    "    # Set model_base based on approach, overriding any provided value if needed\n",
    "    if config[\"approach\"] in [\"simple\", \"rnn\"]:\n",
    "        config[\"model_base\"] = \"glove50\"  # Force glove50 for simple/rnn\n",
    "    elif config[\"approach\"] == \"saffu\":\n",
    "        config[\"model_base\"] = \"saffu\"    # Force saffu\n",
    "    elif config[\"approach\"] == \"bert\":\n",
    "        # Use provided model_base or default to bert-tiny\n",
    "        config[\"model_base\"] = setup_config.get(\"model_base\", \"prajjwal1/bert-tiny\")\n",
    "    \n",
    "    # Set model_name as provided\n",
    "    config[\"model_name\"] = setup_config[\"model_name\"]\n",
    "    \n",
    "    ######## CONTEXT PARAMS ########\n",
    "    config.update({\n",
    "        \"rows\": setup_config[\"rows\"],\n",
    "        \"cols\": setup_config[\"cols\"],\n",
    "        \"tokens\": setup_config[\"tokens\"]\n",
    "    })\n",
    "    \n",
    "    return config\n",
    "\n",
    "def h_data(config, setup_config):\n",
    "    \"\"\"Helper function to setup data-related configurations.\"\"\"\n",
    "    ######## DATA DIR & DATASET ########\n",
    "    if not os.path.isdir(setup_config[\"data_dir\"]):\n",
    "        raise ValueError(f\"ERR: data_dir '{setup_config['data_dir']}' is not a valid path\")\n",
    "    \n",
    "    config.update({\n",
    "        \"data_ds\": setup_config[\"data_ds\"],\n",
    "        \"data_dir\": setup_config[\"data_dir\"]\n",
    "    })\n",
    "    \n",
    "    ######## DATA DIRECTORIES ########\n",
    "    # Create directory paths\n",
    "    train_dir = os.path.join(config[\"data_dir\"], f\"{setup_config['data_ds']}_train\")\n",
    "    val_dir = os.path.join(config[\"data_dir\"], f\"{setup_config['data_ds']}_val\")\n",
    "    test_dir = os.path.join(config[\"data_dir\"], f\"{setup_config['data_ds']}_test\")\n",
    "    \n",
    "    # Validate directories exist\n",
    "    missing_dirs = [\n",
    "        dir_name for dir_name, path in \n",
    "        {\"train\": train_dir, \"val\": val_dir, \"test\": test_dir}.items() \n",
    "        if not os.path.isdir(path)\n",
    "    ]\n",
    "    if missing_dirs:\n",
    "        raise ValueError(f\"ERR: Missing dataset directories: {', '.join(missing_dirs)}\")\n",
    "    \n",
    "    # Update config after validation\n",
    "    config.update({\n",
    "        \"train_dir\": train_dir,\n",
    "        \"val_dir\": val_dir,\n",
    "        \"test_dir\": test_dir\n",
    "    })\n",
    "    \n",
    "    return config\n",
    "\n",
    "def h_vocab(config, setup_config):\n",
    "    \"\"\"Helper function to setup vocabulary only for simple/rnn approaches.\"\"\"\n",
    "    if config[\"approach\"] not in [\"simple\", \"rnn\"]:\n",
    "        return config\n",
    "        \n",
    "    ######## VOCAB ########\n",
    "    # Validate vocab parameters\n",
    "    if not isinstance(setup_config[\"vocab_size\"], int) or not 4 <= setup_config[\"vocab_size\"] <= 2000000:\n",
    "        raise ValueError(f\"ERR: vocab_size '{setup_config['vocab_size']}' must be an integer between 4 and 2,000,000\")\n",
    "    \n",
    "    vocab_space = setup_config.get(\"vocab_space\", True)\n",
    "    if not isinstance(vocab_space, bool):\n",
    "        vocab_space = True\n",
    "        \n",
    "    vocab_case = setup_config.get(\"vocab_case\", \"lower\")\n",
    "    if vocab_case not in [\"both\", \"upper\", \"lower\"]:\n",
    "        vocab_case = \"lower\"\n",
    "    \n",
    "    # Generate vocab object using train_dir\n",
    "    config[\"vocab\"] = get_vocab(\n",
    "        config[\"train_dir\"],\n",
    "        setup_config[\"vocab_size\"],\n",
    "        space=vocab_space,\n",
    "        case=vocab_case,\n",
    "        threads=config[\"THREADS\"]\n",
    "    )\n",
    "    \n",
    "    ######## WVS ########\n",
    "    config[\"wvs\"] = create_embeddings(config[\"vocab\"])\n",
    "    config.update({\n",
    "        \"vocab_size\": config[\"wvs\"].shape[0],\n",
    "        \"vocab_space\": vocab_space,\n",
    "        \"vocab_case\": vocab_case\n",
    "    })\n",
    "    \n",
    "    return config\n",
    "\n",
    "def h_rnn(config, setup_config):\n",
    "    \"\"\"Helper function to setup RNN-specific parameters.\"\"\"\n",
    "    if config[\"approach\"] != \"rnn\":\n",
    "        return config\n",
    "        \n",
    "    ######## RNN PARAMETERS ########\n",
    "    config.update({\n",
    "        \"hidden_dim\": setup_config.get(\"hidden_dim\", 128),\n",
    "        \"rnn_layers\": setup_config.get(\"rnn_layers\", 2),\n",
    "        \"dropout_rate\": setup_config.get(\"dropout_rate\", 0.05),\n",
    "        \"nonlinearity\": setup_config.get(\"nonlinearity\", \"relu\")\n",
    "    })\n",
    "    \n",
    "    return config\n",
    "\n",
    "def h_training(config, setup_config):\n",
    "    \"\"\"Helper function to setup training parameters and generate save name.\"\"\"\n",
    "    ######## TRAINING PARAMS ########\n",
    "    config.update({\n",
    "        \"batch\": setup_config[\"batch\"],\n",
    "        \"lr\": setup_config[\"lr\"],\n",
    "        \"mu\": setup_config[\"mu\"],\n",
    "        \"epochs\": setup_config[\"epochs\"],\n",
    "        \"patience\": setup_config[\"patience\"],\n",
    "        \"save_int\": setup_config[\"save_int\"],\n",
    "        \"save_dir\": setup_config[\"save_dir\"]\n",
    "    })\n",
    "\n",
    "    ######## SAVE NAME ########\n",
    "    # Basic components (common across all approaches)\n",
    "    env_map = {\"gcp\": \"g\", \"local\": \"l\", \"bvm\": \"b\", \"colab\": \"c\"}\n",
    "    env_abbr = env_map[config[\"env\"]]\n",
    "    app_prefix = config[\"approach\"][:3]\n",
    "    base_name = f\"{env_abbr}{app_prefix}{config['seed']}\"\n",
    "    \n",
    "    # Context dims component\n",
    "    dims = f\"{config['model_name']}_{config['data_ds']}_{config['rows']}x{config['cols']}x{config['tokens']}\"\n",
    "    \n",
    "    # Training params component\n",
    "    train_params = (f\"bsz{config['batch']}lr{config['lr']:.0e}\"\n",
    "                   .replace('e-0', 'e-') + \n",
    "                   f\"ep{config['epochs']}pa{config['patience']}\")\n",
    "\n",
    "    # Approach-specific components\n",
    "    if config[\"approach\"] in [\"simple\", \"rnn\"]:\n",
    "        # Vocab string for simple/rnn approaches\n",
    "        case_prefix = {\"both\": \"b\", \"upper\": \"u\", \"lower\": \"l\"}[config[\"vocab_case\"]]\n",
    "        space_str = \"Sp\" if config[\"vocab_space\"] else \"Nsp\"\n",
    "        vocab_str = f\"{case_prefix}{space_str}{config['vocab_size']//1000}k\"\n",
    "        \n",
    "        # Additional RNN-specific component\n",
    "        if config[\"approach\"] == \"rnn\":\n",
    "            rnn_str = f\"_rnn{config['rnn_layers']}hid{config['hidden_dim']}\"\n",
    "        else:\n",
    "            rnn_str = \"\"\n",
    "            \n",
    "        save_name = f\"{base_name}_{dims}_{vocab_str}_{train_params}{rnn_str}\"\n",
    "    \n",
    "    elif config[\"approach\"] == \"bert\":\n",
    "        # BERT models don't need vocab string\n",
    "        save_name = f\"{base_name}_{dims}_{train_params}\"\n",
    "    \n",
    "    elif config[\"approach\"] == \"saffu\":\n",
    "        # SAFFU models don't need vocab string\n",
    "        save_name = f\"{base_name}_{dims}_{train_params}\"\n",
    "    \n",
    "    config[\"save_name\"] = save_name\n",
    "    return config\n",
    "\n",
    "def h_simpleloader(config):\n",
    "    \"\"\"Helper function to setup SpreadsheetDataLoaders for simple/rnn approaches.\"\"\"\n",
    "    ######## SIMPLE LOADERS ########\n",
    "    # Generate file lists\n",
    "    train_files, _ = get_fileList(config[\"train_dir\"])\n",
    "    val_files, _ = get_fileList(config[\"val_dir\"])\n",
    "    test_files, _ = get_fileList(config[\"test_dir\"])\n",
    "\n",
    "    # Create SpreadsheetDataLoaders\n",
    "    config.update({\n",
    "        \"train_loader\": SpreadsheetDataLoader(\n",
    "            train_files, config[\"vocab\"], \n",
    "            config[\"rows\"], config[\"cols\"], config[\"tokens\"], \n",
    "            threads=config[\"THREADS\"]\n",
    "        ),\n",
    "        \"val_loader\": SpreadsheetDataLoader(\n",
    "            val_files, config[\"vocab\"], \n",
    "            config[\"rows\"], config[\"cols\"], config[\"tokens\"], \n",
    "            threads=config[\"THREADS\"]\n",
    "        ),\n",
    "        \"test_loader\": SpreadsheetDataLoader(\n",
    "            test_files, config[\"vocab\"], \n",
    "            config[\"rows\"], config[\"cols\"], config[\"tokens\"], \n",
    "            threads=config[\"THREADS\"]\n",
    "        )\n",
    "    })\n",
    "    \n",
    "    return config\n",
    "\n",
    "def setup_simple_config(setup_config):\n",
    "    \"\"\"Sets up the configuration for model training with modular helper functions.\"\"\"\n",
    "    ######## ENVIRONMENT ########\n",
    "    config = h_env(setup_config)\n",
    "    \n",
    "    ######## MODEL ########\n",
    "    config = h_model(config, setup_config)\n",
    "    \n",
    "    ######## DATA ########\n",
    "    config = h_data(config, setup_config)\n",
    "    \n",
    "    ######## APPROACH-SPECIFIC SETUP ########\n",
    "    if config[\"approach\"] in [\"simple\", \"rnn\"]:\n",
    "        ######## VOCAB ########\n",
    "        config = h_vocab(config, setup_config)\n",
    "        \n",
    "        ######## DATALOADERS ########\n",
    "        config = h_simpleloader(config)\n",
    "        \n",
    "        ######## RNN PARAMS ########\n",
    "        if config[\"approach\"] == \"rnn\":\n",
    "            config = h_rnn(config, setup_config)\n",
    "            \n",
    "    ######## BERT-SPECIFIC ########\n",
    "    elif config[\"approach\"] == \"bert\":\n",
    "        pass\n",
    "    \n",
    "    ######## SAFFU-SPECIFIC ########\n",
    "    elif config[\"approach\"] == \"saffu\":\n",
    "        pass\n",
    "    \n",
    "    ######## TRAINING & SAVE NAME ########\n",
    "    config = h_training(config, setup_config)\n",
    "    \n",
    "    return config\n",
    "\n",
    "\n",
    "def display_config(config):\n",
    "    \"\"\"Display the current configuration settings.\"\"\"\n",
    "    config_serializable = copy.deepcopy(config)\n",
    "    config_serializable[\"DEVICE\"] = str(config_serializable[\"DEVICE\"])\n",
    "    \n",
    "    # Base configuration that exists for all approaches\n",
    "    ordered_config = {\n",
    "        # Environment Info\n",
    "        \"env\": config_serializable[\"env\"],\n",
    "        \"approach\": config_serializable[\"approach\"],\n",
    "        \n",
    "        # Model Info\n",
    "        \"model_base\": config_serializable[\"model_base\"],\n",
    "        \"model_name\": config_serializable[\"model_name\"],\n",
    "        \n",
    "        # Context Parameters\n",
    "        \"rows\": config_serializable[\"rows\"],\n",
    "        \"cols\": config_serializable[\"cols\"],\n",
    "        \"tokens\": config_serializable[\"tokens\"],\n",
    "        \n",
    "        # System Configuration\n",
    "        \"DEVICE\": config_serializable[\"DEVICE\"],\n",
    "        \"THREADS\": config_serializable[\"THREADS\"],\n",
    "        \"seed\": config_serializable[\"seed\"],\n",
    "        \n",
    "        # Data Configuration\n",
    "        \"data_ds\": config_serializable[\"data_ds\"],\n",
    "        \"data_dir\": config_serializable[\"data_dir\"],\n",
    "        \"train_dir\": config_serializable[\"train_dir\"],\n",
    "        \"val_dir\": config_serializable[\"val_dir\"],\n",
    "        \"test_dir\": config_serializable[\"test_dir\"]\n",
    "    }\n",
    "\n",
    "    # Add vocabulary configuration if it exists (simple/rnn approaches)\n",
    "    if \"vocab\" in config_serializable:\n",
    "        vocab_config = {\n",
    "            # Vocabulary Configuration\n",
    "            \"vocab_size\": config_serializable[\"vocab_size\"],\n",
    "            \"vocab_space\": config_serializable[\"vocab_space\"],\n",
    "            \"vocab_case\": config_serializable[\"vocab_case\"],\n",
    "            \"vocab\": \"<Vocab Object>\",\n",
    "            \"wvs\": \"<Embedding Matrix>\"\n",
    "        }\n",
    "        ordered_config.update(vocab_config)\n",
    "        \n",
    "    # Add training configuration for all approaches\n",
    "    ordered_config.update({\n",
    "        # Training Configuration\n",
    "        \"batch\": config_serializable[\"batch\"],\n",
    "        \"lr\": config_serializable[\"lr\"],\n",
    "        \"mu\": config_serializable[\"mu\"],\n",
    "        \"epochs\": config_serializable[\"epochs\"],\n",
    "        \"patience\": config_serializable[\"patience\"],\n",
    "        \"save_int\": config_serializable[\"save_int\"],\n",
    "        \"save_dir\": config_serializable[\"save_dir\"],\n",
    "        \"save_name\": config_serializable[\"save_name\"]\n",
    "    })\n",
    "\n",
    "    # Add RNN-specific configuration if it exists\n",
    "    if config_serializable[\"approach\"] == \"rnn\":\n",
    "        rnn_config = {\n",
    "            # RNN Parameters\n",
    "            \"hidden_dim\": config_serializable[\"hidden_dim\"],\n",
    "            \"rnn_layers\": config_serializable[\"rnn_layers\"],\n",
    "            \"dropout_rate\": config_serializable[\"dropout_rate\"],\n",
    "            \"nonlinearity\": config_serializable[\"nonlinearity\"]\n",
    "        }\n",
    "        ordered_config.update(rnn_config)\n",
    "\n",
    "    print(f\"\\nConfiguration for {config_serializable['approach'].upper()} approach:\")\n",
    "    print(json.dumps(ordered_config, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8f548e36-3a56-4f88-a777-13077c0e749d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting Vocab: 100%|████████████████████████████| 40/40 [00:03<00:00, 13.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40(P) = 40(G) + 0(E)\n",
      "Unique Tokens: 5593\n",
      "Vocab Size: 5597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Word Embeddings: 100%|██████████| 5597/5597 [00:00<00:00, 73377.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Embeddings Shape: torch.Size([5597, 50])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting Vocab: 100%|██████████████████████████| 40/40 [00:00<00:00, 1796.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40(P) = 40(G) + 0(E)\n",
      "Unique Tokens: 5593\n",
      "Vocab Size: 5597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Word Embeddings: 100%|██████████| 5597/5597 [00:00<00:00, 74206.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Embeddings Shape: torch.Size([5597, 50])\n",
      "\n",
      "Configuration for BERT approach:\n",
      "{\n",
      "  \"env\": \"gcp\",\n",
      "  \"approach\": \"bert\",\n",
      "  \"model_base\": \"prajjwal1/bert-tiny\",\n",
      "  \"model_name\": \"BertCustomAdd\",\n",
      "  \"rows\": 100,\n",
      "  \"cols\": 100,\n",
      "  \"tokens\": 32,\n",
      "  \"DEVICE\": \"cuda:0\",\n",
      "  \"THREADS\": 12,\n",
      "  \"seed\": 42,\n",
      "  \"data_ds\": \"manual\",\n",
      "  \"data_dir\": \"../../data/farzan\",\n",
      "  \"train_dir\": \"../../data/farzan/manual_train\",\n",
      "  \"val_dir\": \"../../data/farzan/manual_val\",\n",
      "  \"test_dir\": \"../../data/farzan/manual_test\",\n",
      "  \"batch\": 40,\n",
      "  \"lr\": 0.005,\n",
      "  \"mu\": 0.25,\n",
      "  \"epochs\": 20,\n",
      "  \"patience\": 2,\n",
      "  \"save_int\": 10,\n",
      "  \"save_dir\": \"../models/\",\n",
      "  \"save_name\": \"gber42_BertCustomAdd_manual_100x100x32_bsz40lr5e-3ep20pa2\"\n",
      "}\n",
      "\n",
      "Configuration for SIMPLE approach:\n",
      "{\n",
      "  \"env\": \"gcp\",\n",
      "  \"approach\": \"simple\",\n",
      "  \"model_base\": \"glove50\",\n",
      "  \"model_name\": \"SimpleGeluEmbedAdd\",\n",
      "  \"rows\": 100,\n",
      "  \"cols\": 100,\n",
      "  \"tokens\": 32,\n",
      "  \"DEVICE\": \"cuda:0\",\n",
      "  \"THREADS\": 12,\n",
      "  \"seed\": 42,\n",
      "  \"data_ds\": \"manual\",\n",
      "  \"data_dir\": \"../../data/farzan\",\n",
      "  \"train_dir\": \"../../data/farzan/manual_train\",\n",
      "  \"val_dir\": \"../../data/farzan/manual_val\",\n",
      "  \"test_dir\": \"../../data/farzan/manual_test\",\n",
      "  \"batch\": 40,\n",
      "  \"lr\": 0.005,\n",
      "  \"mu\": 0.25,\n",
      "  \"epochs\": 20,\n",
      "  \"patience\": 2,\n",
      "  \"save_int\": 10,\n",
      "  \"save_dir\": \"../models/\",\n",
      "  \"save_name\": \"gsim42_SimpleGeluEmbedAdd_manual_100x100x32_bSp5k_bsz40lr5e-3ep20pa2\",\n",
      "  \"vocab_size\": 5597,\n",
      "  \"vocab_space\": true,\n",
      "  \"vocab_case\": \"both\",\n",
      "  \"vocab\": \"<Vocab Object>\",\n",
      "  \"wvs\": \"<Embedding Matrix>\"\n",
      "}\n",
      "\n",
      "Configuration for RNN approach:\n",
      "{\n",
      "  \"env\": \"gcp\",\n",
      "  \"approach\": \"rnn\",\n",
      "  \"model_base\": \"glove50\",\n",
      "  \"model_name\": \"Rnn2dSquare\",\n",
      "  \"rows\": 100,\n",
      "  \"cols\": 100,\n",
      "  \"tokens\": 32,\n",
      "  \"DEVICE\": \"cuda:0\",\n",
      "  \"THREADS\": 12,\n",
      "  \"seed\": 42,\n",
      "  \"data_ds\": \"manual\",\n",
      "  \"data_dir\": \"../../data/farzan\",\n",
      "  \"train_dir\": \"../../data/farzan/manual_train\",\n",
      "  \"val_dir\": \"../../data/farzan/manual_val\",\n",
      "  \"test_dir\": \"../../data/farzan/manual_test\",\n",
      "  \"batch\": 10,\n",
      "  \"lr\": 7e-05,\n",
      "  \"mu\": 0.25,\n",
      "  \"epochs\": 20,\n",
      "  \"patience\": 3,\n",
      "  \"save_int\": 5,\n",
      "  \"save_dir\": \"../models/\",\n",
      "  \"save_name\": \"grnn42_Rnn2dSquare_manual_100x100x32_bSp5k_bsz10lr7e-5ep20pa3_rnn2hid100\",\n",
      "  \"vocab_size\": 5597,\n",
      "  \"vocab_space\": true,\n",
      "  \"vocab_case\": \"both\",\n",
      "  \"vocab\": \"<Vocab Object>\",\n",
      "  \"wvs\": \"<Embedding Matrix>\",\n",
      "  \"hidden_dim\": 100,\n",
      "  \"rnn_layers\": 2,\n",
      "  \"dropout_rate\": 0.05,\n",
      "  \"nonlinearity\": \"relu\"\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "res = setup_simple_config(setup_config)\n",
    "res2 = setup_simple_config(new_config)\n",
    "res3 = setup_simple_config(rnn_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7f70b960-4a86-4f6d-b5fa-8fd18482c2a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configuration for BERT approach:\n",
      "{\n",
      "  \"env\": \"gcp\",\n",
      "  \"approach\": \"bert\",\n",
      "  \"model_base\": \"prajjwal1/bert-tiny\",\n",
      "  \"model_name\": \"BertCustomAdd\",\n",
      "  \"rows\": 100,\n",
      "  \"cols\": 100,\n",
      "  \"tokens\": 32,\n",
      "  \"DEVICE\": \"cuda:0\",\n",
      "  \"THREADS\": 12,\n",
      "  \"seed\": 42,\n",
      "  \"data_ds\": \"manual\",\n",
      "  \"data_dir\": \"../../data/farzan\",\n",
      "  \"train_dir\": \"../../data/farzan/manual_train\",\n",
      "  \"val_dir\": \"../../data/farzan/manual_val\",\n",
      "  \"test_dir\": \"../../data/farzan/manual_test\",\n",
      "  \"batch\": 40,\n",
      "  \"lr\": 0.005,\n",
      "  \"mu\": 0.25,\n",
      "  \"epochs\": 20,\n",
      "  \"patience\": 2,\n",
      "  \"save_int\": 10,\n",
      "  \"save_dir\": \"../models/\",\n",
      "  \"save_name\": \"gber42_BertCustomAdd_manual_100x100x32_bsz40lr5e-3ep20pa2\"\n",
      "}\n",
      "\n",
      "Configuration for SIMPLE approach:\n",
      "{\n",
      "  \"env\": \"gcp\",\n",
      "  \"approach\": \"simple\",\n",
      "  \"model_base\": \"glove50\",\n",
      "  \"model_name\": \"SimpleGeluEmbedAdd\",\n",
      "  \"rows\": 100,\n",
      "  \"cols\": 100,\n",
      "  \"tokens\": 32,\n",
      "  \"DEVICE\": \"cuda:0\",\n",
      "  \"THREADS\": 12,\n",
      "  \"seed\": 42,\n",
      "  \"data_ds\": \"manual\",\n",
      "  \"data_dir\": \"../../data/farzan\",\n",
      "  \"train_dir\": \"../../data/farzan/manual_train\",\n",
      "  \"val_dir\": \"../../data/farzan/manual_val\",\n",
      "  \"test_dir\": \"../../data/farzan/manual_test\",\n",
      "  \"vocab_size\": 5597,\n",
      "  \"vocab_space\": true,\n",
      "  \"vocab_case\": \"both\",\n",
      "  \"vocab\": \"<Vocab Object>\",\n",
      "  \"wvs\": \"<Embedding Matrix>\",\n",
      "  \"batch\": 40,\n",
      "  \"lr\": 0.005,\n",
      "  \"mu\": 0.25,\n",
      "  \"epochs\": 20,\n",
      "  \"patience\": 2,\n",
      "  \"save_int\": 10,\n",
      "  \"save_dir\": \"../models/\",\n",
      "  \"save_name\": \"gsim42_SimpleGeluEmbedAdd_manual_100x100x32_bSp5k_bsz40lr5e-3ep20pa2\"\n",
      "}\n",
      "\n",
      "Configuration for RNN approach:\n",
      "{\n",
      "  \"env\": \"gcp\",\n",
      "  \"approach\": \"rnn\",\n",
      "  \"model_base\": \"glove50\",\n",
      "  \"model_name\": \"Rnn2dSquare\",\n",
      "  \"rows\": 100,\n",
      "  \"cols\": 100,\n",
      "  \"tokens\": 32,\n",
      "  \"DEVICE\": \"cuda:0\",\n",
      "  \"THREADS\": 12,\n",
      "  \"seed\": 42,\n",
      "  \"data_ds\": \"manual\",\n",
      "  \"data_dir\": \"../../data/farzan\",\n",
      "  \"train_dir\": \"../../data/farzan/manual_train\",\n",
      "  \"val_dir\": \"../../data/farzan/manual_val\",\n",
      "  \"test_dir\": \"../../data/farzan/manual_test\",\n",
      "  \"vocab_size\": 5597,\n",
      "  \"vocab_space\": true,\n",
      "  \"vocab_case\": \"both\",\n",
      "  \"vocab\": \"<Vocab Object>\",\n",
      "  \"wvs\": \"<Embedding Matrix>\",\n",
      "  \"batch\": 10,\n",
      "  \"lr\": 7e-05,\n",
      "  \"mu\": 0.25,\n",
      "  \"epochs\": 20,\n",
      "  \"patience\": 3,\n",
      "  \"save_int\": 5,\n",
      "  \"save_dir\": \"../models/\",\n",
      "  \"save_name\": \"grnn42_Rnn2dSquare_manual_100x100x32_bSp5k_bsz10lr7e-5ep20pa3_rnn2hid100\",\n",
      "  \"hidden_dim\": 100,\n",
      "  \"rnn_layers\": 2,\n",
      "  \"dropout_rate\": 0.05,\n",
      "  \"nonlinearity\": \"relu\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "display_config(res)\n",
    "display_config(res2)\n",
    "display_config(res3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "438d603f-bc92-4d2b-95fd-5b142e029c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configuration Final:\n",
      "{\n",
      "  \"env\": \"gcp\",\n",
      "  \"approach\": \"bert\",\n",
      "  \"model_base\": \"prajjwal1/bert-tiny\",\n",
      "  \"model_name\": \"BertCustomAdd\",\n",
      "  \"rows\": 100,\n",
      "  \"cols\": 100,\n",
      "  \"tokens\": 32,\n",
      "  \"DEVICE\": \"cuda:0\",\n",
      "  \"THREADS\": 12,\n",
      "  \"seed\": 42,\n",
      "  \"data_ds\": \"manual\",\n",
      "  \"data_dir\": \"../../data/farzan\",\n",
      "  \"train_dir\": \"../../data/farzan/manual_train\",\n",
      "  \"val_dir\": \"../../data/farzan/manual_val\",\n",
      "  \"test_dir\": \"../../data/farzan/manual_test\"\n",
      "}\n",
      "\n",
      "Configuration Final:\n",
      "{\n",
      "  \"env\": \"gcp\",\n",
      "  \"approach\": \"simple\",\n",
      "  \"model_base\": \"glove50\",\n",
      "  \"model_name\": \"SimpleGeluEmbedAdd\",\n",
      "  \"rows\": 100,\n",
      "  \"cols\": 100,\n",
      "  \"tokens\": 32,\n",
      "  \"DEVICE\": \"cuda:0\",\n",
      "  \"THREADS\": 12,\n",
      "  \"seed\": 42,\n",
      "  \"data_ds\": \"manual\",\n",
      "  \"data_dir\": \"../../data/farzan\",\n",
      "  \"train_dir\": \"../../data/farzan/manual_train\",\n",
      "  \"val_dir\": \"../../data/farzan/manual_val\",\n",
      "  \"test_dir\": \"../../data/farzan/manual_test\",\n",
      "  \"vocab_size\": 5597,\n",
      "  \"vocab_space\": true,\n",
      "  \"vocab_case\": \"both\",\n",
      "  \"vocab\": \"<Vocab Object>\",\n",
      "  \"wvs\": \"<Embedding Matrix>\"\n",
      "}\n",
      "\n",
      "Configuration Final:\n",
      "{\n",
      "  \"env\": \"gcp\",\n",
      "  \"approach\": \"rnn\",\n",
      "  \"model_base\": \"glove50\",\n",
      "  \"model_name\": \"Rnn2dSquare\",\n",
      "  \"rows\": 100,\n",
      "  \"cols\": 100,\n",
      "  \"tokens\": 32,\n",
      "  \"DEVICE\": \"cuda:0\",\n",
      "  \"THREADS\": 12,\n",
      "  \"seed\": 42,\n",
      "  \"data_ds\": \"manual\",\n",
      "  \"data_dir\": \"../../data/farzan\",\n",
      "  \"train_dir\": \"../../data/farzan/manual_train\",\n",
      "  \"val_dir\": \"../../data/farzan/manual_val\",\n",
      "  \"test_dir\": \"../../data/farzan/manual_test\",\n",
      "  \"vocab_size\": 5597,\n",
      "  \"vocab_space\": true,\n",
      "  \"vocab_case\": \"both\",\n",
      "  \"vocab\": \"<Vocab Object>\",\n",
      "  \"wvs\": \"<Embedding Matrix>\",\n",
      "  \"hidden_dim\": 100,\n",
      "  \"rnn_layers\": 2,\n",
      "  \"dropout_rate\": 0.05,\n",
      "  \"nonlinearity\": \"relu\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "display_config(res)\n",
    "display_config(res2)\n",
    "display_config(res3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ea7f38-b515-42fa-b03c-9d5546ee865e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36403ba4-b772-4ad6-a8b2-bc86f92e815e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b4febea-dc13-4a94-8c5c-25f8f15a791b",
   "metadata": {},
   "source": [
    "# Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c1330ae-16f9-49e9-9564-23d652b4d498",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModel\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class TestBERT(nn.Module):\n",
    "    def __init__(self, model_name=\"bert-base-cased\", dropout_rate=0.05):\n",
    "        super(TestBERT, self).__init__()\n",
    "\n",
    "        # 1. Load pretrained BERT\n",
    "        self.bert = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "        # 2. Define a dropout\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "        # 3. Non-linear activation (GELU)\n",
    "        self.gelu = nn.GELU()\n",
    "\n",
    "        # 4. Final predictor (1-dim output per cell)\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size, 1)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "\n",
    "        # 1) Allocate the (batch_size, rows, cols) S_cube\n",
    "        S_cube = torch.zeros(\n",
    "            (input_ids.shape[0], input_ids.shape[1], input_ids.shape[2]),\n",
    "            device=input_ids.device,\n",
    "        )\n",
    "\n",
    "        # 2) Loop over cells in row-major order\n",
    "        for cell in tqdm(\n",
    "            range(input_ids.shape[1] * input_ids.shape[2]), desc=\"Forward\"\n",
    "        ):\n",
    "\n",
    "            # In one shot, store logits → S_cube\n",
    "            # cell // input_ids.shape[2] = row, cell % input_ids.shape[2] = col\n",
    "            S_cube[\n",
    "                :, cell // input_ids.shape[2], cell % input_ids.shape[2]\n",
    "            ] = self.classifier(\n",
    "                self.gelu(\n",
    "                    self.dropout(\n",
    "                        self.bert(\n",
    "                            input_ids[\n",
    "                                :,\n",
    "                                cell // input_ids.shape[2],\n",
    "                                cell % input_ids.shape[2],\n",
    "                                :,\n",
    "                            ],\n",
    "                            attention_mask=attention_mask[\n",
    "                                :,\n",
    "                                cell // input_ids.shape[2],\n",
    "                                cell % input_ids.shape[2],\n",
    "                                :,\n",
    "                            ],\n",
    "                        ).pooler_output\n",
    "                    )\n",
    "                )\n",
    "            ).view(\n",
    "                -1\n",
    "            )\n",
    "\n",
    "        return S_cube\n",
    "\n",
    "\n",
    "# class TestBERT(nn.Module):\n",
    "#     def __init__(self, model_name=\"bert-base-cased\", dropout_rate=0.05):\n",
    "#         super(TestBERT, self).__init__()\n",
    "\n",
    "#         # 1. Load pretrained BERT\n",
    "#         self.bert = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "#         # 2. Define a dropout\n",
    "#         self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "#         # 3. Non-linear activation (GELU)\n",
    "#         self.gelu = nn.GELU()\n",
    "\n",
    "#         # 4. Final predictor (1-dim output per cell)\n",
    "#         self.classifier = nn.Linear(self.bert.config.hidden_size, 1)\n",
    "\n",
    "#     def forward(self, input_ids, attention_mask):\n",
    "\n",
    "#         # 1. Print the overall shapes\n",
    "#         # print(\"batch_size:\", input_ids.shape[0])\n",
    "#         # print(\"rows:\",      input_ids.shape[1])\n",
    "#         # print(\"cols:\",      input_ids.shape[2])\n",
    "#         # print(\"tokens:\",    input_ids.shape[3])\n",
    "\n",
    "#         # 2. Initialize S_cube => (batch_size, rows, cols)\n",
    "#         S_cube = torch.zeros(\n",
    "#             (input_ids.shape[0], input_ids.shape[1], input_ids.shape[2]),\n",
    "#             device=input_ids.device\n",
    "#         )\n",
    "\n",
    "#         # 3. Loop over all cells\n",
    "#         for cell in tqdm(range(input_ids.shape[1] * input_ids.shape[2]), desc = 'Forward'):\n",
    "\n",
    "#             r = cell // input_ids.shape[2]\n",
    "#             c = cell %  input_ids.shape[2]\n",
    "\n",
    "#             # Extract the slice for current cell (batch_size x tokens)\n",
    "#             cell_input_ids  = input_ids[:, r, c, :]\n",
    "#             cell_attn_mask  = attention_mask[:, r, c, :]\n",
    "\n",
    "#             # Pass them through the BERT model\n",
    "#             outputs = self.bert(cell_input_ids, attention_mask=cell_attn_mask)\n",
    "\n",
    "#             # pooler_out => (batch_size, hidden_dim)\n",
    "#             pooler_out = outputs.pooler_output\n",
    "\n",
    "#             # Inlined pipeline: dropout -> GELU -> classifier => (batch_size, 1)\n",
    "#             logits = self.classifier(self.gelu(self.dropout(pooler_out)))\n",
    "\n",
    "#             # Flatten (batch_size, 1) => (batch_size,)\n",
    "#             logits_flat = logits.view(-1)\n",
    "\n",
    "#             # Populate S_cube => shape: (batch_size, rows, cols)\n",
    "#             S_cube[:, r, c] = logits_flat\n",
    "\n",
    "#             # If this is the first cell, do some prints and break\n",
    "#             if r == 0 and c == 0:\n",
    "#                 print(f\"\\nFirst cell => row={r}, col={c}\")\n",
    "#                 print(f\"cell_input_ids.shape: {cell_input_ids.shape}\")\n",
    "#                 print(f\"cell_attn_mask.shape: {cell_attn_mask.shape}\")\n",
    "#                 print(f\"logits.shape: {logits.shape}\")\n",
    "#                 print(f\"logits_flat.shape: {logits_flat.shape}\")\n",
    "#                 print(f\"S_cube[:, {r}, {c}].shape: {S_cube[:, r, c].shape}\")\n",
    "\n",
    "#                 break  # Stop after the first cell\n",
    "\n",
    "#         # 4. Print the shape of S_cube\n",
    "#         # print(f\"\\nS_cube.shape: {S_cube.shape}\")\n",
    "\n",
    "#         # Return S_cube or None, depending on your use case\n",
    "#         return S_cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fc45c9c-b142-4f61-8f8b-50982c2e62ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|████████████████████████████████████████| 40/40 [00:22<00:00,  1.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "40(P) = 40(G) + 0(E)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████████████████████████████████████| 5/5 [00:00<00:00,  9.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5(P) = 5(G) + 0(E)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████████████████████████████████████| 5/5 [00:00<00:00, 11.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5(P) = 5(G) + 0(E)\n",
      "\n",
      "Final BERT configuration:\n",
      "{\n",
      "  \"model_name\": \"prajjwal1/bert-tiny\",\n",
      "  \"data_dir\": \"../../data/farzan/\",\n",
      "  \"DEVICE\": \"cuda:0\",\n",
      "  \"THREADS\": 8,\n",
      "  \"data_ds\": \"manual\",\n",
      "  \"train_dir\": \"../../data/farzan/manual_train\",\n",
      "  \"val_dir\": \"../../data/farzan/manual_val\",\n",
      "  \"test_dir\": \"../../data/farzan/manual_test\",\n",
      "  \"rows\": 100,\n",
      "  \"cols\": 100,\n",
      "  \"tokens\": 32,\n",
      "  \"tokenizer\": \"<ModernBert Tokenizer Object>\",\n",
      "  \"train_loader\": \"<Train BertLoader Object>\",\n",
      "  \"val_loader\": \"<Validation BertLoader Object>\",\n",
      "  \"test_loader\": \"<Test BertLoader Object>\"\n",
      "}\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import transformers.models.bert.modeling_bert because of the following error (look up to see its traceback):\nArtifact name: 'trace_shape_events' not registered,please call register_artifact('trace_shape_events') in torch._logging.registrations.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py:1793\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1792\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1793\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1794\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1050\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1006\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:688\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:883\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:25\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcheckpoint\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpackaging\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m version\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:15\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraceback\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mfx_traceback\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_functorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_aot_autograd\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_fun\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_pytree\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tree_map\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/functional_utils.py:19\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_subclasses\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmeta_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_sparse_any\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msymbolic_shapes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m definitely_true, sym_eq\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmultiprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreductions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StorageWeakRef\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/fx/experimental/symbolic_shapes.py:51\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _config \u001b[38;5;28;01mas\u001b[39;00m config\n\u001b[0;32m---> 51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrecording\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     52\u001b[0m     FakeTensorMeta,\n\u001b[1;32m     53\u001b[0m     ShapeEnvEvent,\n\u001b[1;32m     54\u001b[0m     record_shapeenv_event,\n\u001b[1;32m     55\u001b[0m     replay_shape_env_events,\n\u001b[1;32m     56\u001b[0m     shape_env_check_state_equal\n\u001b[1;32m     57\u001b[0m )\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msym_node\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SymNode, SymTypes\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/fx/experimental/recording.py:14\u001b[0m\n\u001b[1;32m     13\u001b[0m log \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m---> 14\u001b[0m trace_shape_events_log \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_logging\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetArtifactLogger\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrace_shape_events\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     16\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShapeEnvEvent\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecord_shapeenv_event\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNotEqualError\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     26\u001b[0m ]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_logging/_internal.py:532\u001b[0m, in \u001b[0;36mgetArtifactLogger\u001b[0;34m(module_qname, artifact_name)\u001b[0m\n\u001b[1;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001b[0;31mValueError\u001b[0m: Artifact name: 'trace_shape_events' not registered,please call register_artifact('trace_shape_events') in torch._logging.registrations.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 115\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m S_cube\n\u001b[1;32m    114\u001b[0m \u001b[38;5;66;03m# 1) Create model and move to GPU\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m untrained_model \u001b[38;5;241m=\u001b[39m \u001b[43mTestBERT\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[1;32m    117\u001b[0m \u001b[38;5;66;03m# 2) Single-batch DataLoader\u001b[39;00m\n\u001b[1;32m    118\u001b[0m check_loader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(train_loader, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[4], line 65\u001b[0m, in \u001b[0;36mTestBERT.__init__\u001b[0;34m(self, model_name, dropout_rate)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28msuper\u001b[39m(TestBERT, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# 1. Load pretrained BERT\u001b[39;00m\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbert \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# Enable gradient checkpointing if desired\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbert\u001b[38;5;241m.\u001b[39mgradient_checkpointing_enable()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:563\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m    560\u001b[0m         pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39mmodel_args, config\u001b[38;5;241m=\u001b[39mconfig, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    561\u001b[0m     )\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m--> 563\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m \u001b[43m_get_model_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model_mapping\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    564\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m    565\u001b[0m         pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39mmodel_args, config\u001b[38;5;241m=\u001b[39mconfig, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    566\u001b[0m     )\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    570\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:388\u001b[0m, in \u001b[0;36m_get_model_class\u001b[0;34m(config, model_mapping)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_model_class\u001b[39m(config, model_mapping):\n\u001b[0;32m--> 388\u001b[0m     supported_models \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_mapping\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(supported_models, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[1;32m    390\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m supported_models\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:763\u001b[0m, in \u001b[0;36m_LazyAutoMapping.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_type \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping:\n\u001b[1;32m    762\u001b[0m     model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping[model_type]\n\u001b[0;32m--> 763\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_attr_from_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    765\u001b[0m \u001b[38;5;66;03m# Maybe there was several model types associated with this config.\u001b[39;00m\n\u001b[1;32m    766\u001b[0m model_types \u001b[38;5;241m=\u001b[39m [k \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_config_mapping\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;241m==\u001b[39m key\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:777\u001b[0m, in \u001b[0;36m_LazyAutoMapping._load_attr_from_module\u001b[0;34m(self, model_type, attr)\u001b[0m\n\u001b[1;32m    775\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m module_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules:\n\u001b[1;32m    776\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules[module_name] \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransformers.models\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 777\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgetattribute_from_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_modules\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattr\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:693\u001b[0m, in \u001b[0;36mgetattribute_from_module\u001b[0;34m(module, attr)\u001b[0m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(attr, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    692\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(getattribute_from_module(module, a) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m attr)\n\u001b[0;32m--> 693\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mhasattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattr\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    694\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(module, attr)\n\u001b[1;32m    695\u001b[0m \u001b[38;5;66;03m# Some of the mappings have entries model_type -> object of another model type. In that case we try to grab the\u001b[39;00m\n\u001b[1;32m    696\u001b[0m \u001b[38;5;66;03m# object at the top level.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py:1781\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1779\u001b[0m     value \u001b[38;5;241m=\u001b[39m Placeholder\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m-> 1781\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1782\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py:1795\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1793\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m   1794\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1795\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1796\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1797\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1798\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to import transformers.models.bert.modeling_bert because of the following error (look up to see its traceback):\nArtifact name: 'trace_shape_events' not registered,please call register_artifact('trace_shape_events') in torch._logging.registrations."
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------\n",
    "#  Full Notebook Code with ONLY Mixed Precision (fp16), No DeepSpeed\n",
    "# ---------------------------------------------------\n",
    "\n",
    "# 1) Standard imports\n",
    "import importlib\n",
    "import sys\n",
    "import os\n",
    "import torch\n",
    "from torch.cuda.amp import autocast\n",
    "\n",
    "# Append the parent directory to the path to import the necessary modules\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "# Import the utilities and the dataloader\n",
    "from utils import trainutil, inferutil, setuputil\n",
    "\n",
    "# Now reload the modules to ensure they are up-to-date\n",
    "importlib.reload(setuputil)\n",
    "importlib.reload(trainutil)\n",
    "importlib.reload(inferutil)\n",
    "\n",
    "# Import the funcs needed from utils\n",
    "from utils.setuputil import setup_bert_config, display_bert_config\n",
    "from utils.trainutil import train_model\n",
    "from utils.inferutil import infer_one, infer_full\n",
    "\n",
    "# Define the input config file\n",
    "setup_config = {\n",
    "    \"model_name\": \"prajjwal1/bert-tiny\",\n",
    "    \"device\": \"cuda:0\",\n",
    "    \"threads\": 8,\n",
    "    \"seed\": 0,\n",
    "    \"data_dir\": \"../../data/farzan/\",\n",
    "    \"data_ds\": \"manual\",\n",
    "    \"rows\": 100,\n",
    "    \"cols\": 100,\n",
    "    \"tokens\": 32\n",
    "}\n",
    "\n",
    "# Get the actual to use config file and view\n",
    "config = setup_bert_config(setup_config)\n",
    "display_bert_config(config)\n",
    "\n",
    "# Define local variables as per the variables from config\n",
    "DEVICE = config['DEVICE']\n",
    "THREADS = config['THREADS']\n",
    "train_loader = config['train_loader']\n",
    "val_loader = config['val_loader']\n",
    "test_loader = config['test_loader']\n",
    "model_name = config['model_name']\n",
    "tokenizer = config['tokenizer']\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModel\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class TestBERT(nn.Module):\n",
    "    def __init__(self, model_name=\"bert-base-cased\", dropout_rate=0.05):\n",
    "        super(TestBERT, self).__init__()\n",
    "\n",
    "        # 1. Load pretrained BERT\n",
    "        self.bert = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "        # Enable gradient checkpointing if desired\n",
    "        self.bert.gradient_checkpointing_enable()\n",
    "\n",
    "        # 2. Define a dropout\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "        # 3. Non-linear activation (GELU)\n",
    "        self.gelu = nn.GELU()\n",
    "\n",
    "        # 4. Final predictor (1-dim output per cell)\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size, 1)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "\n",
    "        # 1) Allocate the (batch_size, rows, cols) S_cube\n",
    "        S_cube = torch.zeros(\n",
    "            (input_ids.shape[0], input_ids.shape[1], input_ids.shape[2]),\n",
    "            device=input_ids.device,\n",
    "        )\n",
    "\n",
    "        # 2) Loop over cells in row-major order\n",
    "        for cell in tqdm(\n",
    "            range(input_ids.shape[1] * input_ids.shape[2]), desc=\"Forward\"\n",
    "        ):\n",
    "\n",
    "            # cell // input_ids.shape[2] = row, cell % input_ids.shape[2] = col\n",
    "            S_cube[\n",
    "                :, cell // input_ids.shape[2], cell % input_ids.shape[2]\n",
    "            ] = (\n",
    "                self.classifier(\n",
    "                    self.gelu(\n",
    "                        self.dropout(\n",
    "                            self.bert(\n",
    "                                input_ids[:, cell // input_ids.shape[2],\n",
    "                                          cell % input_ids.shape[2], :],\n",
    "                                attention_mask=attention_mask[:, cell // input_ids.shape[2],\n",
    "                                                              cell % input_ids.shape[2], :]\n",
    "                            ).pooler_output\n",
    "                        )\n",
    "                    )\n",
    "                )\n",
    "                .view(-1)\n",
    "            )\n",
    "\n",
    "        return S_cube\n",
    "\n",
    "\n",
    "# 1) Create model and move to GPU\n",
    "untrained_model = TestBERT(model_name=model_name).to(DEVICE)\n",
    "\n",
    "# 2) Single-batch DataLoader\n",
    "check_loader = torch.utils.data.DataLoader(train_loader, batch_size=1, shuffle=False)\n",
    "batch = next(iter(check_loader))\n",
    "\n",
    "ex_xtok = batch[\"x_tok\"].to(DEVICE)\n",
    "ex_xmask = batch[\"x_masks\"].to(DEVICE)\n",
    "\n",
    "# 3) FP16 forward pass with torch.cuda.amp\n",
    "with autocast():\n",
    "    out = untrained_model.forward(ex_xtok, ex_xmask)\n",
    "\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83f013c9-3af7-4ab0-8d0f-0132df57e78f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Forward: 100%|███████████████████████████| 10000/10000 [00:24<00:00, 409.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 100, 100])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f452d771-1242-48df-aac1-2165a709deec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
