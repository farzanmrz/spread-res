{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4dd17d8867486cb8",
   "metadata": {
    "id": "4dd17d8867486cb8"
   },
   "source": [
    "# Setup\n",
    "\n",
    "## Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdb5c68b937d0f70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-06T18:11:19.875851Z",
     "start_time": "2024-09-06T18:11:19.866673Z"
    },
    "executionInfo": {
     "elapsed": 362,
     "status": "ok",
     "timestamp": 1724981219889,
     "user": {
      "displayName": "Farzan Mirza",
      "userId": "00574002115746201032"
     },
     "user_tz": 240
    },
    "id": "fdb5c68b937d0f70"
   },
   "outputs": [],
   "source": [
    "# Import importlib to reload modules and sys and os to add the path for other imports\n",
    "import importlib\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Append the parent directory to the path to import the necessary modules\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "# Import the utilities and the dataloader\n",
    "from utils import selfutil\n",
    "from classes import SpreadsheetDataLoader, TestRNN\n",
    "\n",
    "# Now reload the modules to ensure they are up-to-date\n",
    "importlib.reload(selfutil)\n",
    "importlib.reload(SpreadsheetDataLoader)\n",
    "importlib.reload(TestRNN)\n",
    "\n",
    "# Import the funcs needed from utils\n",
    "from utils.selfutil import get_vocabulary, create_embeddings, to_gpu\n",
    "\n",
    "# Import the SpreadsheetDataLoader class\n",
    "from classes.SpreadsheetDataLoader import SpreadsheetDataLoader\n",
    "from classes.TestRNN import TestRNN\n",
    "\n",
    "# Other regular imports\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import os\n",
    "import pandas as pd\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905f6bd9fb11ab7d",
   "metadata": {
    "id": "905f6bd9fb11ab7d"
   },
   "source": [
    "# Build Vocabulary\n",
    "\n",
    "Get the vocabulary object from the helper function as well as the processed file paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a54968e9a1de1905",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-06T17:49:49.996224Z",
     "start_time": "2024-09-06T17:49:46.404854Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 42112,
     "status": "ok",
     "timestamp": 1724980968619,
     "user": {
      "displayName": "Farzan Mirza",
      "userId": "00574002115746201032"
     },
     "user_tz": 240
    },
    "id": "a54968e9a1de1905",
    "outputId": "53b62034-6124-41c2-e00e-40e9263c9d68"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing Files in Parallel:   0%|                      | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.005995750427246094,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 20,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 10,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ada28221fc114eacb2ac7fc6a24acfb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Vocabulary size: 10010\n",
      "Files Processed: 10\n"
     ]
    }
   ],
   "source": [
    "# Set the directory containing the spreadsheets\n",
    "data_dir = '../data/train_small/'\n",
    "\n",
    "# Get the list of file paths\n",
    "spreadsheet_vocab,file_paths = get_vocabulary(data_dir)\n",
    "\n",
    "# Print info\n",
    "print(f'\\n\\nVocabulary size: {len(spreadsheet_vocab._word2idx)}')\n",
    "print(f'Files Processed: {len(file_paths)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611dd5a38c5da752",
   "metadata": {
    "id": "611dd5a38c5da752"
   },
   "source": [
    "# Word Embeddings\n",
    "\n",
    "Create the vector representation for each word in the vocabulary using Glove that represents each word with a 50-dimensional vector else makes it a normally distributed random vector.\n",
    "\n",
    "**NOTE**: You keep confusing word embeddings with words vectors, they are used interchangeably"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "573deb5d6dc61188",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-06T17:50:06.281987Z",
     "start_time": "2024-09-06T17:49:58.380077Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31247,
     "status": "ok",
     "timestamp": 1724981006502,
     "user": {
      "displayName": "Farzan Mirza",
      "userId": "00574002115746201032"
     },
     "user_tz": 240
    },
    "id": "573deb5d6dc61188",
    "outputId": "7ed60160-aa4d-484d-8ee4-0b547f0eb4b8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                 | 0/10010 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████████████████████████████| 10010/10010 [00:00<00:00, 80004.77it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Embeddings Shape: torch.Size([10010, 50])\n",
      "\n",
      "Example Embedding for <unk> at index 0:\n",
      "tensor([-1.1258, -1.1524, -0.2506, -0.4339,  0.8487,  0.6920, -0.3160, -2.1152,\n",
      "         0.3223, -1.2633,  0.3500,  0.3081,  0.1198,  1.2377,  1.1168, -0.2473,\n",
      "        -1.3527, -1.6959,  0.5667,  0.7935,  0.5988, -1.5551, -0.3414,  1.8530,\n",
      "         0.7502, -0.5855, -0.1734,  0.1835,  1.3894,  1.5863,  0.9463, -0.8437,\n",
      "        -0.6136,  0.0316,  1.0554,  0.1778, -0.2303, -0.3918,  0.5433, -0.3952,\n",
      "         0.2055, -0.4503,  1.5210,  3.4105, -1.5312, -1.2341,  1.8197, -0.5515,\n",
      "        -1.3253,  0.1886])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Create the embeddings for each word in the vocabulary and view info\n",
    "spreadsheet_wvs = create_embeddings(spreadsheet_vocab)\n",
    "print(f'Word Embeddings Shape: {spreadsheet_wvs.shape}')\n",
    "print(f'\\nExample Embedding for <unk> at index 0:\\n{spreadsheet_wvs[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd7621cb7e75248",
   "metadata": {
    "id": "efd7621cb7e75248"
   },
   "source": [
    "# Data Loader\n",
    "\n",
    "DataLoader standardizes the data into uniform batches and we will be represent each spreadsheet as a 100x100x32 LongTensor because we standardize rows and columns as 100x100 and for each cell allow exactly 32 tokens. Therefore each index in x_tok list will be for a single spreadsheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a275661796aa11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-06T17:50:38.504245Z",
     "start_time": "2024-09-06T17:50:24.412584Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 218719,
     "status": "ok",
     "timestamp": 1724981442188,
     "user": {
      "displayName": "Farzan Mirza",
      "userId": "00574002115746201032"
     },
     "user_tz": 240
    },
    "id": "4a275661796aa11",
    "outputId": "7e977fdf-9eff-414f-8ce8-e832d2d65c4d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing files: 100%|███████████████████████| 10/10 [00:00<00:00, 5799.65it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spreadsheets Processed: 10\n",
      "x_tok Tensor Shape: torch.Size([100, 100, 32])\n",
      "y_tok Tensor Shape: torch.Size([100, 100, 17])\n"
     ]
    }
   ],
   "source": [
    "# Create the SpreadsheetDataLoader object with the vocabulary and file paths and view\n",
    "check_loader = SpreadsheetDataLoader(file_paths, spreadsheet_vocab)\n",
    "print(f'Spreadsheets Processed: {len(check_loader)}')\n",
    "print(f'x_tok Tensor Shape: {check_loader.x_tok[0].shape}')\n",
    "print(f'y_tok Tensor Shape: {check_loader.y_tok[0].shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e246ddfa",
   "metadata": {},
   "source": [
    "# Tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d23caa2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "\n",
    "# class TestRNN(nn.Module):\n",
    "\n",
    "#     # Constructor of the RNN_LM class, initializing the layers and weights\n",
    "#     def __init__(self, hidden_state_dim, rnn_layers, embedding_matrix, dropout_rate=0.05, nonlinearity='relu'):\n",
    "\n",
    "#         # Ensures functions of parent class nn.Module are called in subclass RNN_LM\n",
    "#         super(TestRNN, self).__init__()\n",
    "\n",
    "#         # Rows of embed matrix = Each word in the vocabulary\n",
    "#         self.vocab_size = embedding_matrix.shape[0]  # vocab_size = 34057\n",
    "\n",
    "#         # Cols of embed matrix = Length of each embedding vector\n",
    "#         self.embedding_dim = embedding_matrix.shape[1]  # embed_dim = 50\n",
    "\n",
    "#         # The dimension of the hidden state vector 'h' for each step/token\n",
    "#         self.hidden_dim = hidden_state_dim  # hid_dim = 100\n",
    "\n",
    "#         # Number of recurrent layers we will use\n",
    "#         self.rnn_layers = rnn_layers  # rnn_layers = 2\n",
    "\n",
    "#         # Creates an embedding layer from the pre-trained embedding matrix that maps input tokens to their corresponding word vectors\n",
    "#         # If freezing then embeddings don't change during training, we need False because we need them to finetune to our task\n",
    "#         self._embed = nn.Embedding.from_pretrained(embedding_matrix, freeze=False)\n",
    "\n",
    "#         # Randomly zeroes out a percentage of input units determined by dropout_rate for each update during training\n",
    "#         self._drop = nn.Dropout(dropout_rate)\n",
    "\n",
    "#         # RNN layer with 'relu' nonlinearity but not managing exploding gradients, dropout and multiple recurrent layers\n",
    "#         self._rnn = nn.RNN(\n",
    "#             self.embedding_dim,\n",
    "#             self.hidden_dim,\n",
    "#             self.rnn_layers,\n",
    "#             nonlinearity=nonlinearity,\n",
    "#             dropout=dropout_rate\n",
    "#         )\n",
    "\n",
    "#         # Linear layer to map the concatenated hidden states to logits (1 to predict bold or not)\n",
    "#         self._pred = nn.Linear(2 * self.hidden_dim, 1)\n",
    "\n",
    "#     def cell_hs(self, x):\n",
    "\n",
    "#         torch.manual_seed(0)\n",
    "\n",
    "#         \"\"\"\n",
    "#         Create a single CPU tensor to reduce GPU load to near zero and return H_global directly by calculating \n",
    "#         using this tensor and then casting it to the GPU device\n",
    "#         \"\"\"\n",
    "\n",
    "#         H_local = torch.stack(\n",
    "#             [\n",
    "#                 self._rnn(\n",
    "#                     self._drop(\n",
    "#                         self._embed(\n",
    "#                             x[:, cell // x.shape[2], cell % x.shape[2], :]  # batch_size x tokens = 10 x 32\n",
    "#                         )  # batch_size x tokens x embed_dim = 10 x 32 x 50\n",
    "#                     )\n",
    "#                 )[1][-1, -1, :].view(-1)  # hidden_dim = 100\n",
    "#                 for cell in range(x.shape[1] * x.shape[2])  # cells x hidden_dim = 10000 x 100\n",
    "#             ]  # cells x hidden_dim = 10000 x 100\n",
    "#         )  # cells x hidden_dim = 10000 x 100\n",
    "\n",
    "\n",
    "#         # Calculate global sum directly and cast to GPU then return\n",
    "#         return H_local.sum(dim=0, keepdim=True) - H_local  # cells x hidden_dim = 10000 x 100\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         torch.manual_seed(0)\n",
    "\n",
    "#         # Global hidden states containing info around current cell\n",
    "#         H_global = self.cell_hs(x)  # Move H_global to GPU\n",
    "\n",
    "#         S_cube = torch.zeros((x.shape[0], x.shape[1], x.shape[2]), device=x.device)\n",
    "\n",
    "#         for cell in range(x.shape[1] * x.shape[2]):\n",
    "\n",
    "#             # Compute the predictions for each cell using list comprehension\n",
    "#             S_cube[:, cell // x.shape[2], cell % x.shape[2]] = self._pred(\n",
    "#                 self._drop(\n",
    "#                     torch.cat(\n",
    "#                         (\n",
    "#                             self._rnn(\n",
    "#                                 self._drop(\n",
    "#                                     self._embed(\n",
    "#                                         x[:, cell // x.shape[2], cell % x.shape[2], :]\n",
    "#                                     )\n",
    "#                                 )\n",
    "#                             )[0][:, -1, :].squeeze(1),\n",
    "#                             H_global[cell].unsqueeze(0).expand(x.shape[0], -1)\n",
    "#                         ),\n",
    "#                         dim=1\n",
    "#                     )\n",
    "#                 )\n",
    "#             ).view(-1)\n",
    "\n",
    "#         # Clean up to free memory\n",
    "#         del H_global\n",
    "\n",
    "#         # Return final 3D tensor containing vocab tensors for a single batch\n",
    "#         return S_cube\n",
    "\n",
    "# #     # Function to calculate the last hidden state for each cell\n",
    "# #     def init_hidden(self, batch_size):\n",
    "# #         weight = next(self.parameters())\n",
    "# #         return weight.new_zeros(self.rnn_layers, batch_size, self.hidden_dim).detach().cpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "920d3264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a DataLoader from your check_loader\n",
    "# test_loader = torch.utils.data.DataLoader(check_loader, batch_size=5, shuffle=False)\n",
    "\n",
    "# # Get one batch from the DataLoader\n",
    "# batch = next(iter(test_loader))\n",
    "\n",
    "# exfile = to_gpu(batch['x_tok'],2)\n",
    "\n",
    "# # Define a new neural network model to be trained and transfer it to GPU\n",
    "# hidden_state_dim = 100\n",
    "# rnn_layers = 2\n",
    "# rnn_model = to_gpu(TestRNN(hidden_state_dim, rnn_layers, spreadsheet_wvs),2)\n",
    "\n",
    "# out = rnn_model.forward(exfile)\n",
    "\n",
    "# # Print the shape of S_cube\n",
    "# print(\"S_cube shape:\", out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd7b16c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ac5bed9647d6da52",
   "metadata": {
    "id": "ac5bed9647d6da52"
   },
   "source": [
    "# Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d776bbf4f1c2760",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14106,
     "status": "ok",
     "timestamp": 1724981465827,
     "user": {
      "displayName": "Farzan Mirza",
      "userId": "00574002115746201032"
     },
     "user_tz": 240
    },
    "id": "8d776bbf4f1c2760",
    "outputId": "6b406761-fb57-46ba-9e4b-29ba57ea71e1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Files in Parallel:   0%|                      | 0/10 [00:20<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "def train_test(model, train_data, batch_size=8, lr=1.4e-5, mu=0.25, max_epochs=5, patience=2, save_int = 1, save_dir='../models/'):\n",
    "    \"\"\"\n",
    "    Train the model for 1 batch, print the length of the train_loader, the training loss, and average training loss.\n",
    "    \"\"\"\n",
    "\n",
    "    # Check if save_int > 0 and save_dir exists\n",
    "    if save_int > 0 and not os.path.exists(save_dir):\n",
    "        raise ValueError(f\"Directory '{save_dir}' DNE\")\n",
    "\n",
    "    # Define the path where to save model and logfile\n",
    "    timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    model_path = os.path.join(save_dir, f\"rnnsmall_{timestamp}.pth\")\n",
    "    log_file = os.path.join(save_dir, f\"rnnsmall_{timestamp}.txt\")\n",
    "\n",
    "    # Setup optimizer\n",
    "    opt = torch.optim.Adagrad(model.parameters(), lr=lr)\n",
    "\n",
    "    # Convert incoming training DataLoader into batches\n",
    "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # Calculate the class imbalance (ratio of non-bold to bold cells)\n",
    "    num_bold_cells = sum((batch['y_tok'][:, :, :, 6] == 1).sum() for batch in train_loader)\n",
    "\n",
    "    # Binary Cross-Entropy Loss with Logits\n",
    "    loss_fn = nn.BCEWithLogitsLoss(\n",
    "        pos_weight=to_gpu(\n",
    "            torch.tensor(\n",
    "                [((len(train_loader) * batch_size * 100 * 100)-num_bold_cells)/num_bold_cells], dtype=torch.float\n",
    "            )\n",
    "            ,2\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Define the starting epoch\n",
    "    epoch = 0\n",
    "\n",
    "    # Define the best average training loss, perplexity as inf max value and epoch as 0\n",
    "    best_avgtrloss = float('inf')\n",
    "    best_perp = float('inf')\n",
    "    best_epoch = 0\n",
    "    \n",
    "\n",
    "    # Epochs without improvement counter\n",
    "    nimp_ctr = 0\n",
    "\n",
    "    # Variable to denote training is on\n",
    "    training = True\n",
    "    lr_adjusted = False\n",
    "\n",
    "    # Loop while model is in training mode and the epoch is less than max_epochs given\n",
    "    while training and (epoch < max_epochs):\n",
    "\n",
    "\n",
    "        # Print the epoch number and write to file also\n",
    "        print(f'Epoch {epoch}')\n",
    "        with open(log_file, 'a') as log:\n",
    "            log.write(f\"\\nEpoch {epoch}\\n\")\n",
    "\n",
    "        # Turn on training mode which enables dropout.\n",
    "        model.train()\n",
    "\n",
    "        # Initialize training loss\n",
    "        curr_trloss = 0\n",
    "\n",
    "        # Loop through the batches in train_loader\n",
    "        for i, batch in enumerate(tqdm(train_loader, desc =f'Batch Processing')):\n",
    "\n",
    "            \n",
    "\n",
    "            # Clear any remaining gradients\n",
    "            model.zero_grad()\n",
    "\n",
    "            # Compute the loss\n",
    "            loss = loss_fn(\n",
    "\n",
    "                model(\n",
    "\n",
    "                    to_gpu(\n",
    "\n",
    "                        batch['x_tok'], 2\n",
    "\n",
    "                    )\n",
    "\n",
    "                ).view(-1), # Predicted labels from model\n",
    "\n",
    "                to_gpu(\n",
    "\n",
    "                    batch['y_tok'][:, :, :, 6], 2\n",
    "\n",
    "                ).view(-1).float() # Actual labels from dataloader\n",
    "\n",
    "            )\n",
    "\n",
    "            # Accumulate the training loss\n",
    "            curr_trloss += loss.detach().cpu().item()\n",
    "\n",
    "            # Compute the gradients of the model parameters by backpropagating the loss\n",
    "            loss.backward()\n",
    "\n",
    "            # Apply gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=mu)\n",
    "\n",
    "            # Update the model parameters\n",
    "            opt.step()\n",
    "\n",
    "            # Clear memory\n",
    "            del loss\n",
    "\n",
    "        # Calculate average training loss for this epoch\n",
    "        curr_avgtrloss = curr_trloss / len(train_loader)\n",
    "\n",
    "        \"\"\"\n",
    "        Calculate the perplexity = e^(loss/(num_batches x batch_size x cells))\n",
    "                                 = e^(loss/(78 x 8 x 10000)) = e^(loss/6240000)\n",
    "        \"\"\"\n",
    "        curr_perp = math.exp(curr_trloss/(len(train_loader) * batch_size * 10000))\n",
    "\n",
    "        # Print the average training loss, perplexity for this current epoch and write to file\n",
    "        print(f'Train Loss: {curr_avgtrloss}, Perplexity: {curr_perp}')\n",
    "        with open(log_file, 'a') as log:\n",
    "            log.write(f'Train Loss: {curr_avgtrloss}, Perplexity: {curr_perp}\\n')\n",
    "        \n",
    "\n",
    "\n",
    "        # Save the model and log if current epoch is a multiple of save_int\n",
    "        if save_int > 0 and (epoch + 1) % save_int == 0:\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            print(f\"Model Saved\")\n",
    "            with open(log_file, 'a') as log:\n",
    "                log.write(f\"Model Saved\\n\")\n",
    "\n",
    "        # Check if current perplexity for this epoch is less than the best perplexity encountered till now\n",
    "        if curr_perp < best_perp:\n",
    "\n",
    "            # If it is then set the best loss and perplexity to current epoch's\n",
    "            best_perp = curr_perp\n",
    "            best_avgtrloss = curr_avgtrloss\n",
    "            best_epoch = epoch\n",
    "\n",
    "            # Also set epochs without improvement counter to 0 since we did see improvement\n",
    "            nimp_ctr = 0\n",
    "\n",
    "        # If it isn't the best then increment no improvement counter\n",
    "        else:\n",
    "            nimp_ctr +=1\n",
    "\n",
    "        # Check if epochs without improvement have cross the patience threshold\n",
    "        if nimp_ctr >= patience:\n",
    "\n",
    "            # If they have then print early stopping message\n",
    "            print(f\"\\nEARLY STOP Epoch {epoch}, Best: Epoch = {best_epoch}, Train Loss = {best_avgtrloss}, Perplexity = {best_perp}\")\n",
    "            with open(log_file, 'a') as log:\n",
    "                log.write(f\"\\nEARLY STOP Epoch {epoch}, Best: Epoch = {best_epoch}, Train Loss = {best_avgtrloss}, Perplexity = {best_perp}\")\n",
    "            training = False\n",
    "\n",
    "\n",
    "        # Increment the epoch and print a new line\n",
    "        epoch += 1\n",
    "        print()\n",
    "\n",
    "    # Save model and log at the end of training (or early stopping)\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    # Print training complete message\n",
    "    print(f\"\\nTRAINING DONE Best: Epoch = {best_epoch}, Train Loss = {best_avgtrloss}, Perplexity = {best_perp}\")\n",
    "    with open(log_file, 'a') as log:\n",
    "        log.write(f\"\\nTRAINING DONE Best: Epoch = {best_epoch}, Train Loss = {best_avgtrloss}, Perplexity = {best_perp}\")\n",
    "\n",
    "    # Return trained model at the end\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e56b5624fee6add8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T00:46:39.175105Z",
     "start_time": "2024-08-30T00:45:32.954729Z"
    },
    "id": "e56b5624fee6add8",
    "outputId": "57357a02-d00c-4f9b-f1ea-543e9311e865"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch Processing: 100%|███████████████████████████| 2/2 [01:03<00:00, 31.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 328.30101013183594, Perplexity: 1.0065876237705587\n",
      "\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch Processing: 100%|███████████████████████████| 2/2 [01:01<00:00, 30.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 313.88185119628906, Perplexity: 1.0062973826842998\n",
      "\n",
      "\n",
      "TRAINING DONE Best: Epoch = 1, Train Loss = 313.88185119628906, Perplexity = 1.0062973826842998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Define a new neural network model to be trained and transfer it to GPU\n",
    "hidden_state_dim = 100\n",
    "rnn_layers = 3\n",
    "test_model = TestRNN(hidden_state_dim, rnn_layers, spreadsheet_wvs)\n",
    "\n",
    "# # Load the state_dict from the saved file\n",
    "# state_dict = torch.load('../models/rnnsmall_20240930_070804.pth')\n",
    "\n",
    "# # Load the weights into the model\n",
    "# test_model.load_state_dict(state_dict)\n",
    "\n",
    "# Move the model to GPU device 2\n",
    "trained_testmodel = to_gpu(test_model, 2)\n",
    "\n",
    "# Call the function to train the model\n",
    "trained_testmodel = train_test(\n",
    "    test_model, check_loader,\n",
    "    batch_size=5, lr=1.4e-5, mu=0.25, max_epochs=2, patience=1,\n",
    "    save_int=5, save_dir='../models/'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4968c74bdb861f2d",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28935cd4ea6c0388",
   "metadata": {
    "id": "28935cd4ea6c0388"
   },
   "outputs": [],
   "source": [
    "def infer(trained_model, infer_loader):\n",
    "    \"\"\"\n",
    "    Takes a trained model and a dataloader, and returns a 100x100 2D grid of predictions\n",
    "    (1 for bold, 0 for not bold) for the first spreadsheet in the dataloader.\n",
    "\n",
    "    Args:\n",
    "        trained_model (nn.Module): The trained PyTorch model.\n",
    "        infer_loader (DataLoader): Dataloader object for the inference files.\n",
    "        device (str): The device to run the inference on ('cuda' or 'cpu').\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: A 100x100 tensor where each element is 1 (bold) or 0 (not bold).\n",
    "    \"\"\"\n",
    "\n",
    "    # Move the model to eval mode\n",
    "    trained_model.eval()\n",
    "\n",
    "    # Get the first spreadsheet from the inference data loader\n",
    "    x_infer = to_gpu(infer_loader.x_tok[0].unsqueeze(0),2)\n",
    "\n",
    "\n",
    "    # Pass the input through the model and get predictions (no gradient needed for inference)\n",
    "    with torch.no_grad():\n",
    "        predictions = trained_model(x_infer)\n",
    "\n",
    "    # Process the output, remove batch dimension, and apply sigmoid to get probabilities\n",
    "    pred_grid = predictions.squeeze(0)  # Convert 1x100x100 -> 100x100\n",
    "    \n",
    "    # Set the print options to display more decimal places\n",
    "    torch.set_printoptions(precision=20)\n",
    "\n",
    "    # Print pred_grid\n",
    "    print(pred_grid)\n",
    "    pred_probs = torch.sigmoid(pred_grid)  # Convert logits to probabilities\n",
    "\n",
    "    # Convert probabilities to binary (1 for bold, 0 for not bold), using 0.5 threshold\n",
    "    pred_labels = (pred_probs > 0.5).long()\n",
    "\n",
    "    # Return the 100x100 grid of prediction probabilities\n",
    "    return pred_probs.detach().cpu(), infer_loader.y_tok[0][:, :, 6], infer_loader.file_paths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0913cefc-99de-4190-9843-80cc38ff2326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a new neural network model to be trained and transfer it to GPU\n",
    "hidden_state_dim = 100\n",
    "rnn_layers = 3\n",
    "#test_model = TestRNN(hidden_state_dim, rnn_layers, spreadsheet_wvs)\n",
    "\n",
    "# Load the state_dict from the saved file\n",
    "#state_dict = torch.load('../models/rnnsmall_20240930_065323.pth')\n",
    "\n",
    "# Load the weights into the model\n",
    "#test_model.load_state_dict(state_dict)\n",
    "\n",
    "# Move the model to GPU device 2\n",
    "#trained_testmodel = to_gpu(test_model, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de6b59f02991c450",
   "metadata": {
    "id": "de6b59f02991c450"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████████████████████| 1/1 [00:00<00:00, 989.92it/s]\n"
     ]
    }
   ],
   "source": [
    "# Define the directory to be used for inference\n",
    "infer_dir = '../data/infer_small/'\n",
    "\n",
    "# List all files in the directory and append the full path\n",
    "infer_files = [\n",
    "    os.path.join(infer_dir, filename)\n",
    "    for filename in os.listdir(infer_dir)\n",
    "    if filename.lower().endswith(('.xls', '.xlsx', '.csv'))  # Adjust the file extensions as needed\n",
    "]\n",
    "\n",
    "# Define the dataloader for inference\n",
    "infer_loader = SpreadsheetDataLoader(infer_files, spreadsheet_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e2f730e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-208.17042541503906250000, -208.17042541503906250000,\n",
      "         -208.17042541503906250000,  ...,\n",
      "         -208.17042541503906250000, -208.17042541503906250000,\n",
      "         -208.17042541503906250000],\n",
      "        [-208.17042541503906250000, -208.17042541503906250000,\n",
      "         -208.17042541503906250000,  ...,\n",
      "         -208.17042541503906250000, -208.17042541503906250000,\n",
      "         -208.17042541503906250000],\n",
      "        [-208.17042541503906250000, -208.17042541503906250000,\n",
      "         -208.17042541503906250000,  ...,\n",
      "         -208.17042541503906250000, -208.17042541503906250000,\n",
      "         -208.17042541503906250000],\n",
      "        ...,\n",
      "        [-208.17042541503906250000, -208.17042541503906250000,\n",
      "         -208.17042541503906250000,  ...,\n",
      "         -208.17042541503906250000, -208.17042541503906250000,\n",
      "         -208.17042541503906250000],\n",
      "        [-208.17042541503906250000, -208.17042541503906250000,\n",
      "         -208.17042541503906250000,  ...,\n",
      "         -208.17042541503906250000, -208.17042541503906250000,\n",
      "         -208.17042541503906250000],\n",
      "        [-208.17042541503906250000, -208.17042541503906250000,\n",
      "         -208.17042541503906250000,  ...,\n",
      "         -208.17042541503906250000, -208.17042541503906250000,\n",
      "         -208.17042541503906250000]], device='cuda:2')\n",
      "\n",
      "Filename: ../data/infer_small/f1.xlsx\n",
      "\n",
      "Predictions (1 = Bold, 0 = Not Bold):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9   ...   90   91   92   93  \\\n",
       "0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "1   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "2   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "3   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "4   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "..  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "95  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "96  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "97  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "98  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "99  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "\n",
       "     94   95   96   97   98   99  \n",
       "0   0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1   0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2   0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3   0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4   0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "..  ...  ...  ...  ...  ...  ...  \n",
       "95  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "96  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "97  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "98  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "99  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[100 rows x 100 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Actual Grid (1 = Bold, 0 = Not Bold):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0   1   2   3   4   5   6   7   8   9   ...  90  91  92  93  94  95  96  \\\n",
       "0    1   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
       "1    0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
       "2    0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
       "3    0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
       "4    0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
       "..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ..  ..  ..  ..  ..  ..  ..   \n",
       "95   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
       "96   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
       "97   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
       "98   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
       "99   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
       "\n",
       "    97  98  99  \n",
       "0    0   0   0  \n",
       "1    0   0   0  \n",
       "2    0   0   0  \n",
       "3    0   0   0  \n",
       "4    0   0   0  \n",
       "..  ..  ..  ..  \n",
       "95   0   0   0  \n",
       "96   0   0   0  \n",
       "97   0   0   0  \n",
       "98   0   0   0  \n",
       "99   0   0   0  \n",
       "\n",
       "[100 rows x 100 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No bold predictions were made by the model.\n"
     ]
    }
   ],
   "source": [
    "pred_bold, act_bold, file = infer(trained_testmodel, infer_loader)\n",
    "# Convert to pandas DataFrames for better display\n",
    "pred_df = pd.DataFrame(pred_bold.numpy())  # Convert tensor to numpy, then to pandas DataFrame\n",
    "actual_df = pd.DataFrame(act_bold.numpy())  # Convert tensor to numpy, then to pandas DataFrame\n",
    "\n",
    "# Print the filename\n",
    "print(f\"\\nFilename: {file}\")\n",
    "\n",
    "# Print the predictions\n",
    "print(\"\\nPredictions (1 = Bold, 0 = Not Bold):\")\n",
    "display(pred_df)\n",
    "\n",
    "# Print the actual grid\n",
    "print(\"\\nActual Grid (1 = Bold, 0 = Not Bold):\")\n",
    "display(actual_df)\n",
    "\n",
    "# Find the locations where the model predicted bold (1)\n",
    "bold_pred_locations = pred_df[pred_df == 1].stack().index.tolist()\n",
    "\n",
    "# Print the bold predictions\n",
    "if bold_pred_locations:\n",
    "    print(f\"Bold predictions at the following row, col locations: {bold_pred_locations}\")\n",
    "else:\n",
    "    print(\"No bold predictions were made by the model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0943c977",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
