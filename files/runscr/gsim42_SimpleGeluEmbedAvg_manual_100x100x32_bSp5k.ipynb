{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import importlib to reload modules and sys and os to add the path for other imports\n",
    "import importlib\n",
    "import sys\n",
    "import os\n",
    "import torch\n",
    "\n",
    "# Append the parent directory to the path to import the necessary modules\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "# Import utilities\n",
    "from utils import setuputil, trainutil, inferutil\n",
    "from classes.models import SimpleGeluEmbed\n",
    "\n",
    "# Reload the necessary modules to ensure they are up-to-date\n",
    "importlib.reload(setuputil)\n",
    "importlib.reload(trainutil)\n",
    "importlib.reload(inferutil)\n",
    "importlib.reload(SimpleGeluEmbed)\n",
    "\n",
    "# Import the required utils\n",
    "from utils.setuputil import setup_config, display_config\n",
    "from utils.trainutil import train_model\n",
    "from utils.inferutil import infer_one, infer_full\n",
    "\n",
    "# Import the SimpleGeluEmbedAdd class\n",
    "from classes.models.SimpleGeluEmbed import SimpleGeluEmbedAvg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Config Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the input configuration for the simple model\n",
    "input_config = {\n",
    "    # Environment and Model Info\n",
    "    \"env\": \"gcp\",                \n",
    "    \"approach\": \"simple\",         \n",
    "    \"model_name\": \"SimpleGeluEmbedAvg\",\n",
    "    \n",
    "    # System Configuration\n",
    "    \"device\": \"cuda:0\",\n",
    "    \"threads\": 14,\n",
    "    \"seed\": 42,\n",
    "    \n",
    "    # Data Configuration\n",
    "    \"data_dir\": \"../../data/farzan\",\n",
    "    \"data_ds\": \"manual\",\n",
    "    \n",
    "    # Model Parameters\n",
    "    \"rows\": 100,\n",
    "    \"cols\": 100,\n",
    "    \"tokens\": 32,\n",
    "    \n",
    "    # Vocabulary Parameters\n",
    "    \"vocab_size\": 150000,\n",
    "    \"vocab_space\": True,\n",
    "    \"vocab_case\": \"both\",\n",
    "    \n",
    "    # Training Parameters\n",
    "    \"batch\": 40,\n",
    "    \"lr\": 1e-1,\n",
    "    \"mu\": 0.25,\n",
    "    \"epochs\": 20,\n",
    "    \"patience\": 2,\n",
    "    \"save_int\": 0,\n",
    "    \"save_dir\": '../models/'\n",
    "}\n",
    "\n",
    "# Setup the configuration using setuputil and display it\n",
    "config = setup_config(input_config)\n",
    "display_config(config)\n",
    "\n",
    "# Define local variables from the config dictionary\n",
    "# System variables\n",
    "DEVICE = config[\"DEVICE\"]\n",
    "THREADS = config[\"THREADS\"]\n",
    "\n",
    "# Data loaders and vocab\n",
    "train_loader = config[\"train_loader\"]\n",
    "val_loader = config[\"val_loader\"]\n",
    "test_loader = config[\"test_loader\"]\n",
    "spreadsheet_vocab = config[\"vocab\"]\n",
    "spreadsheet_wvs = config[\"wvs\"]\n",
    "\n",
    "# Training parameters\n",
    "batch_size = config[\"batch\"]\n",
    "lr = config[\"lr\"]\n",
    "mu = config[\"mu\"]\n",
    "epochs = config[\"epochs\"]\n",
    "patience = config[\"patience\"]\n",
    "save_int = config[\"save_int\"]\n",
    "save_dir = config[\"save_dir\"]\n",
    "save_name = config[\"save_name\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the first item from train_loader\n",
    "first_item = train_loader[0]\n",
    "\n",
    "# Get the components\n",
    "x_tok = first_item['x_tok']\n",
    "x_masks = first_item['x_masks']\n",
    "y_tok = first_item['y_tok']\n",
    "filepath = first_item['file_paths']\n",
    "\n",
    "print(f\"File: {filepath}\\n\")\n",
    "\n",
    "print(\"Shapes:\")\n",
    "print(f\"x_tok: {x_tok.shape}\")  # Should be 32-length vector\n",
    "print(f\"y_tok: {y_tok.shape}\")  # Should be 32-length vector\n",
    "print(f\"x_masks: {x_masks.shape if isinstance(x_masks, torch.Tensor) else len(x_masks)}\\n\")\n",
    "\n",
    "# Extract cell location [10,10]\n",
    "x_cell = x_tok[10,10,:]  \n",
    "y_cell = y_tok[10,10,:]\n",
    "\n",
    "print(\"Values at position [10,10]:\")\n",
    "print(f\"\\nx_tok: {x_cell.tolist()}\")\n",
    "print(f\"\\nx_tok decoded: {[spreadsheet_vocab.decode(idx) for idx in x_cell.tolist()]}\")\n",
    "print(f\"\\ny_tok: {y_cell.tolist()}\")\n",
    "\n",
    "\n",
    "\n",
    "# Get the first item from train_loader\n",
    "first_item = val_loader[0]\n",
    "\n",
    "# Get the components\n",
    "x_tok = first_item['x_tok']\n",
    "x_masks = first_item['x_masks']\n",
    "y_tok = first_item['y_tok']\n",
    "filepath = first_item['file_paths']\n",
    "\n",
    "print(f\"File: {filepath}\\n\")\n",
    "\n",
    "print(\"Shapes:\")\n",
    "print(f\"x_tok: {x_tok.shape}\")  # Should be 32-length vector\n",
    "print(f\"y_tok: {y_tok.shape}\")  # Should be 32-length vector\n",
    "print(f\"x_masks: {x_masks.shape if isinstance(x_masks, torch.Tensor) else len(x_masks)}\\n\")\n",
    "\n",
    "# Extract cell location [10,10]\n",
    "x_cell = x_tok[10,10,:]  \n",
    "y_cell = y_tok[10,10,:]\n",
    "\n",
    "print(\"Values at position [10,10]:\")\n",
    "print(f\"\\nx_tok: {x_cell.tolist()}\")\n",
    "print(f\"\\nx_tok decoded: {[spreadsheet_vocab.decode(idx) for idx in x_cell.tolist()]}\")\n",
    "print(f\"\\ny_tok: {y_cell.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "\n",
    "## Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the untrained model and move it to the device\n",
    "untrained_model = SimpleGeluEmbedAvg(spreadsheet_wvs).to(DEVICE)\n",
    "print(untrained_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trained_model = train_model(\n",
    "    model=untrained_model,\n",
    "    train_data=train_loader, \n",
    "    val_data=val_loader, \n",
    "    DEVICE=DEVICE, \n",
    "    batch_size=batch_size,\n",
    "    lr=lr,\n",
    "    mu=mu,\n",
    "    max_epochs=epochs,\n",
    "    patience=patience,\n",
    "    save_int=save_int,\n",
    "    save_dir=save_dir,\n",
    "    save_name=save_name,\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define params for evaluation\n",
    "thresh = 0.91\n",
    "loc = 0\n",
    "cond = '>'\n",
    "disp_max=True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## Single Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check with single example\n",
    "infer_one(trained_model, train_loader, loc=loc, threshold=thresh, condition=cond, disp_max=disp_max, device=DEVICE)\n",
    "infer_one(trained_model, val_loader, loc=loc, threshold=thresh, condition=cond, disp_max=disp_max, device=DEVICE)\n",
    "infer_one(trained_model, test_loader, loc=loc, threshold=thresh, condition=cond, disp_max=disp_max, device=DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## All Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluate the model on all train files\n",
    "infer_full(trained_model, train_loader, batch_size=batch_size, threshold=thresh, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# All val files\n",
    "infer_full(trained_model, val_loader, batch_size=batch_size, threshold=thresh, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# All test files\n",
    "infer_full(trained_model, test_loader, batch_size=batch_size, threshold=thresh, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
