{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc980c87",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "## Notebook formatting"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ae277fb0-df34-488e-9754-70693e223a62",
   "metadata": {},
   "source": [
    "%%javascript\n",
    "Jupyter.notebook.get_cells().map(function(c) {\n",
    "    if (c.cell_type === 'code') {\n",
    "        c.code_mirror.setOption('lineWrapping', true);\n",
    "    }\n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5765f20",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d28dae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import importlib to reload modules and sys and os to add the path for other imports\n",
    "import importlib\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Append the parent directory to the path to import the necessary modules\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "# Import the utilities and the dataloader\n",
    "from utils import selfutil, saffuutil \n",
    "from classes import TestRNN\n",
    "\n",
    "# Now reload the modules to ensure they are up-to-date\n",
    "importlib.reload(selfutil)\n",
    "importlib.reload(saffuutil)\n",
    "importlib.reload(TestRNN)\n",
    "\n",
    "# Import the funcs needed from utils\n",
    "from utils.saffuutil import load_saffutok, dir2convos, get_saffuloader, saffutok_traindata\n",
    "\n",
    "# Import the SAFFUDataLoader class\n",
    "from classes.TestRNN import TestRNN\n",
    "\n",
    "# Other regular imports\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import gc\n",
    "import os\n",
    "import pandas as pd\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2082ec2",
   "metadata": {},
   "source": [
    "# Tokenizer \n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c15b3a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "# Read and execute saffu files for using functionality\n",
    "exec(open(\"../saffu/configuration_saffu.py\").read())\n",
    "exec(open(\"../saffu/tokenization_saffu.py\").read())\n",
    "exec(open(\"../saffu/utilities_saffu.py\").read())\n",
    "exec(open(\"../saffu/data_saffu.py\").read())\n",
    "exec(open(\"../saffu/modeling_saffu.py\").read())\n",
    "exec(open(\"../saffu/training_saffu.py\").read())\n",
    "exec(open(\"../saffu/inference_saffu.py\").read())\n",
    "exec(open(\"../saffu/tuning_saffu.py\").read())\n",
    "exec(open(\"../saffu/load_data.py\").read())\n",
    "\n",
    "## Set environment variables\n",
    "# Creates logger object named __main__ for debug messages\n",
    "logger = logging.get_logger(__name__)\n",
    "\n",
    "# Doesn't split memory chunks of more than 256 MB\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:256\"\n",
    "\n",
    "# Makes code synchronous meaning GPU finishes running then CPU rund\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "# Enable dynamic shape allocation of tensor sizes without predefining them\n",
    "os.environ['TORCH_USE_CUDA_DSA'] = \"1\"\n",
    "\n",
    "# Set the gpu or cpu device\n",
    "devstr = \"cuda:1\" # \"cpu\" \n",
    "gpu = False if (devstr == 'cpu') else True\n",
    "device = 'cpu' if (devstr == 'cpu') else (torch.device(devstr if torch.cuda.is_available() else 'cpu') \n",
    "                                          if devstr else torch.cuda.current_device())\n",
    "# Observe the device\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6863665",
   "metadata": {},
   "source": [
    "## Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b644ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer: train_big-tiny\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the dataset being used, can also combine different ones with a +\n",
    "data_set = \"train_big\" # +harmless-base+babylm_10M+babylm_100M+BWB\n",
    "\n",
    "# Define model size from tiny, micro, small, medium, big\n",
    "model_size = \"tiny\"\n",
    "\n",
    "# Size of different datasets in millions of word tokens\n",
    "training_sizes = {\"helpful-base\": 5, \"harmless-base\": 5, \"babylm_10M\": 10, \"babylm_100M\": 100, \"BWB\": 1000,\n",
    "                 \"train\":2.1877, \"train_big\":5} \n",
    "\n",
    "# Define the % of data held out for development so 1/10 of total available below\n",
    "devsample = 10 \n",
    "\n",
    "# Total size of all datasets in millions, currently 2.1877 million should be\n",
    "dataset_size =  sum([training_sizes[data_subset] for data_subset in data_set.split(\"+\")])\n",
    "\n",
    "# Get downsample size which would be 1 = 1 million below\n",
    "downsample = max(int(dataset_size / 5), 1) # roughly 5 million word-tokens per split\n",
    "\n",
    "# Hyperparameter for learning rate probably\n",
    "eta = 0.05 # 0.05\n",
    "\n",
    "# Empty lists to store document or conversation level data for normal, dev and test\n",
    "docs, ddocs, tdocs = [], [], []\n",
    "convos, dconvos, tconvos = [], [], []\n",
    "\n",
    "# Get the configuration params for current model medium\n",
    "config = get_config(model_size = model_size)\n",
    "\n",
    "# Name the current tokenizer combo of dataset+model names\n",
    "tokenizer_name = f\"{data_set}-{model_size}\" # helpful-base-medium\n",
    "\n",
    "# Create the tokenizer object inherited from HF PreTrainedTokenizer class therefore init params not in custom\n",
    "tokenizer = SAFFUTokenizer(config)\n",
    "\n",
    "# Determine the directory where you wanna retreive tokenizer from\n",
    "tokenizer_directory = \"./cache/\"\n",
    "\n",
    "# Determine the directory where you wanna store tokenizer\n",
    "save_directory = './cache/'\n",
    "\n",
    "# Form the vocab file with a of directory, model path in tokenization_saffu.py, and name if given\n",
    "vocab_file = os.path.join(tokenizer_directory, tokenizer._model_path,\n",
    "                          (tokenizer_name + \"-\" if tokenizer_name else \"\") + \"vocab.json\")\n",
    "\n",
    "# True if retraining the tokenizer, False to load an existing one available\n",
    "reload = False\n",
    "\n",
    "# Now call load func to setup tokenizer\n",
    "load_saffutok(reload, vocab_file, tokenizer, tokenizer_name, tokenizer_directory, train_dir = '../data/train_big/')\n",
    "\n",
    "\n",
    "# Name the data_file path\n",
    "data_file = os.path.join(tokenizer_directory, tokenizer._model_path,\n",
    "                         (tokenizer_name + \"-\" if tokenizer_name else \"\") + \n",
    "                         f\"data-space_{tokenizer.config._space}-r_{tokenizer.config._r}-b_{tokenizer.config._b}-heads_{tokenizer.config._heads}-N_{tokenizer.config._N}.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eccec9d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size for experiment:  7206\n"
     ]
    }
   ],
   "source": [
    "# Print new vocab size for this experiment after BPE\n",
    "print(\"Vocabulary size for experiment: \", len(tokenizer._vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d4badc5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Th', 'ese', ' ca', 'ss', 'er', 'ol', 'es', ' di', 's', 'gu', 'st', ' K', 'ay', 'la', '.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'\\n': 360,\n",
       " '\\n ': 6432,\n",
       " ' ': 924,\n",
       " ' \\t': 7013,\n",
       " ' \\t3': 6242,\n",
       " ' \\n': 1963,\n",
       " '  ': 207,\n",
       " '  \\n': 2097,\n",
       " '   ': 2032,\n",
       " '    ': 2382,\n",
       " '     ': 1934,\n",
       " '      ': 2387,\n",
       " '       ': 2389,\n",
       " '        ': 1861,\n",
       " '         ': 1910,\n",
       " '          ': 2393,\n",
       " '           ': 2407,\n",
       " '            ': 2365,\n",
       " '             ': 2420,\n",
       " '              ': 2628,\n",
       " '               ': 2658,\n",
       " '                ': 2832,\n",
       " '                 ': 2903,\n",
       " '                  ': 2838,\n",
       " '                   ': 3167,\n",
       " '                    ': 3295,\n",
       " '                     ': 3392,\n",
       " '                      ': 3594,\n",
       " '                       ': 3508,\n",
       " '                        ': 3795,\n",
       " '                         ': 3750,\n",
       " '                          ': 4197,\n",
       " '                           ': 4196,\n",
       " '                            ': 4847,\n",
       " '                             ': 6342,\n",
       " '                              ': 5347,\n",
       " '                               ': 5077,\n",
       " '                                ': 5038,\n",
       " '                                 ': 6067,\n",
       " '                                  ': 6446,\n",
       " '                                     ': 6281,\n",
       " '                                            ': 6521,\n",
       " '                                             ': 6408,\n",
       " '                                                ': 6343,\n",
       " '                                                   ': 6964,\n",
       " '                                                     ': 5094,\n",
       " '                                                       ': 6701,\n",
       " '                                                                  ': 5064,\n",
       " '                                                                     ': 6218,\n",
       " '                                                                                   ': 6247,\n",
       " '                                                                                                                                                                                                                                                               ': 6977,\n",
       " '  \"': 4524,\n",
       " '  #1': 6299,\n",
       " '  #2': 6298,\n",
       " '  $': 5847,\n",
       " '  $2': 7139,\n",
       " '  $5': 6525,\n",
       " '  $7': 7198,\n",
       " '  %': 6037,\n",
       " '  &': 5375,\n",
       " '  & ': 6731,\n",
       " '  (': 2935,\n",
       " '  ($': 5549,\n",
       " '  *': 4807,\n",
       " '  +': 3786,\n",
       " '  .': 6574,\n",
       " '  /': 5281,\n",
       " '  / ': 6632,\n",
       " '  0': 4272,\n",
       " '  01': 6079,\n",
       " '  07': 6179,\n",
       " '  1': 4174,\n",
       " '  1/': 3951,\n",
       " '  10': 5950,\n",
       " '  10/': 6815,\n",
       " '  11': 5179,\n",
       " '  114': 6716,\n",
       " '  12': 4643,\n",
       " '  13': 6069,\n",
       " '  135': 7186,\n",
       " '  14': 6671,\n",
       " '  149': 6309,\n",
       " '  14:': 6639,\n",
       " '  15': 5452,\n",
       " '  16': 4917,\n",
       " '  17': 4833,\n",
       " '  179': 6323,\n",
       " '  1800': 5680,\n",
       " '  199': 6461,\n",
       " '  2': 4214,\n",
       " '  2\"': 5989,\n",
       " '  2/': 3952,\n",
       " '  20': 6226,\n",
       " '  200': 4277,\n",
       " '  201': 6010,\n",
       " '  2020': 4445,\n",
       " '  2021': 5453,\n",
       " '  2023': 7068,\n",
       " '  21': 5500,\n",
       " '  22': 5837,\n",
       " '  23': 6585,\n",
       " '  25': 6861,\n",
       " '  250': 6176,\n",
       " '  26': 7153,\n",
       " '  27': 6008,\n",
       " '  29': 6075,\n",
       " '  3': 5215,\n",
       " '  3/': 3916,\n",
       " '  33': 6404,\n",
       " '  4': 4639,\n",
       " '  4\"': 4818,\n",
       " '  4/': 4068,\n",
       " '  400': 5732,\n",
       " '  402': 6120,\n",
       " '  403': 6121,\n",
       " '  48': 6003,\n",
       " '  5': 4998,\n",
       " '  5/': 3988,\n",
       " '  50': 5541,\n",
       " '  54': 5962,\n",
       " '  55': 6111,\n",
       " '  56': 6965,\n",
       " '  6': 4641,\n",
       " '  6\"': 5602,\n",
       " '  6/': 4036,\n",
       " '  600': 6734,\n",
       " '  602': 6423,\n",
       " '  61': 6865,\n",
       " '  64': 7027,\n",
       " '  646': 6578,\n",
       " '  66': 6360,\n",
       " '  67': 6591,\n",
       " '  68': 6757,\n",
       " '  7': 4830,\n",
       " '  7/': 4491,\n",
       " '  70': 6597,\n",
       " '  74': 7102,\n",
       " '  75': 6537,\n",
       " '  750': 6601,\n",
       " '  76': 6318,\n",
       " '  77': 7162,\n",
       " '  79': 7074,\n",
       " '  8': 4794,\n",
       " '  8/': 4144,\n",
       " '  80': 5900,\n",
       " '  82': 5048,\n",
       " '  83': 6586,\n",
       " '  84': 6655,\n",
       " '  88': 5686,\n",
       " '  89': 6962,\n",
       " '  9': 5883,\n",
       " '  9/': 3989,\n",
       " '  91': 5454,\n",
       " '  913': 6879,\n",
       " '  93': 6264,\n",
       " '  96': 6722,\n",
       " '  97': 5918,\n",
       " '  99': 5677,\n",
       " '  :': 6261,\n",
       " '  =': 5157,\n",
       " '  [': 5576,\n",
       " '  _': 5941,\n",
       " '  __': 4146,\n",
       " ' !': 6460,\n",
       " ' \"': 2295,\n",
       " ' \"#': 6792,\n",
       " ' \",': 6603,\n",
       " ' \"[': 6567,\n",
       " ' \"]': 6625,\n",
       " ' #': 2523,\n",
       " ' # ': 5266,\n",
       " ' ##': 5524,\n",
       " ' #,': 7062,\n",
       " ' #1': 3622,\n",
       " ' #2': 3684,\n",
       " ' #2 ': 6969,\n",
       " ' #3': 3709,\n",
       " ' #4': 3818,\n",
       " ' #5': 4557,\n",
       " ' #6': 4316,\n",
       " ' #6 ': 6646,\n",
       " ' #7': 5289,\n",
       " ' #8': 4981,\n",
       " ' #9': 5426,\n",
       " ' #:': 4973,\n",
       " ' $': 2281,\n",
       " ' $)': 6725,\n",
       " ' $.': 7160,\n",
       " ' $/': 4590,\n",
       " ' $0': 4179,\n",
       " ' $1': 2569,\n",
       " ' $2': 3052,\n",
       " ' $3': 3449,\n",
       " ' $4': 4101,\n",
       " ' $5': 3661,\n",
       " ' $6': 4053,\n",
       " ' $7': 4403,\n",
       " ' $8': 4180,\n",
       " ' $9': 6068,\n",
       " ' %': 3711,\n",
       " ' &': 311,\n",
       " ' & ': 5717,\n",
       " ' &1': 6340,\n",
       " ' &5': 6869,\n",
       " \" '\": 3313,\n",
       " \" 'A\": 5691,\n",
       " \" 'B\": 5304,\n",
       " \" 'C\": 5518,\n",
       " \" 'F\": 6596,\n",
       " \" 'G\": 5741,\n",
       " \" 'M\": 5384,\n",
       " \" 'N\": 5670,\n",
       " \" 'P\": 4959,\n",
       " \" 'S\": 5417,\n",
       " \" 'T\": 5428,\n",
       " \" 'W\": 6480,\n",
       " \" 'Y\": 7060,\n",
       " \" 'm\": 6459,\n",
       " \" 's\": 6484,\n",
       " ' (': 78,\n",
       " ' (\"': 4687,\n",
       " ' (#': 6395,\n",
       " ' ($': 3588,\n",
       " ' (%': 5278,\n",
       " ' ((': 4321,\n",
       " ' (+': 5433,\n",
       " ' (.': 6312,\n",
       " ' (<': 5122,\n",
       " ' (>': 5702,\n",
       " ' (?': 4944,\n",
       " ' ([': 5001,\n",
       " ' ({': 4975,\n",
       " ' (“': 5682,\n",
       " ' (≤': 4280,\n",
       " ' (≥': 5676,\n",
       " ' )': 3929,\n",
       " ' ):': 7036,\n",
       " ' );': 7016,\n",
       " ' *': 3969,\n",
       " ' * ': 5313,\n",
       " ' **': 4347,\n",
       " ' +': 771,\n",
       " ' + ': 6588,\n",
       " ' +0': 6748,\n",
       " ' +1': 7142,\n",
       " ' +6': 6787,\n",
       " ' +8': 6733,\n",
       " ' ,': 3370,\n",
       " ' -': 303,\n",
       " ' - ': 4429,\n",
       " ' --': 4045,\n",
       " ' -B': 6703,\n",
       " ' -C': 5392,\n",
       " ' -E': 5446,\n",
       " ' -F': 5277,\n",
       " ' -G': 5759,\n",
       " ' -M': 5783,\n",
       " ' -N': 6080,\n",
       " ' -O': 5840,\n",
       " ' -P': 6349,\n",
       " ' -S': 6292,\n",
       " ' -U': 5773,\n",
       " ' -W': 6753,\n",
       " ' -c': 5617,\n",
       " ' -d': 6558,\n",
       " ' -f': 6442,\n",
       " ' -κ': 6392,\n",
       " ' .': 3345,\n",
       " ' .\"': 6553,\n",
       " ' ..': 5209,\n",
       " ' /': 2839,\n",
       " ' / ': 7096,\n",
       " ' /2': 6290,\n",
       " ' 0': 1638,\n",
       " ' 0%': 7043,\n",
       " ' 00': 158,\n",
       " ' 0011': 4341,\n",
       " ' 0012': 6341,\n",
       " ' 005': 7092,\n",
       " ' 006': 6875,\n",
       " ' 009': 6982,\n",
       " ' 00:': 5224,\n",
       " ' 01': 1788,\n",
       " ' 013': 6670,\n",
       " ' 014': 6576,\n",
       " ' 02': 1825,\n",
       " ' 020': 6330,\n",
       " ' 021': 6331,\n",
       " ' 022': 6332,\n",
       " ' 024': 6863,\n",
       " ' 029': 6824,\n",
       " ' 03': 1878,\n",
       " ' 036': 6837,\n",
       " ' 038': 5894,\n",
       " ' 039': 5899,\n",
       " ' 04': 1278,\n",
       " ' 0406': 1525,\n",
       " ' 042': 6862,\n",
       " ' 043': 7175,\n",
       " ' 044': 6637,\n",
       " ' 047': 6931,\n",
       " ' 048': 7179,\n",
       " ' 05': 1987,\n",
       " ' 056': 6260,\n",
       " ' 059': 6892,\n",
       " ' 06': 1954,\n",
       " ' 066': 6364,\n",
       " ' 067': 6737,\n",
       " ' 069': 7150,\n",
       " ' 07': 1836,\n",
       " ' 071': 5380,\n",
       " ' 073': 6994,\n",
       " ' 075': 6830,\n",
       " ' 076': 7164,\n",
       " ' 078': 6918,\n",
       " ' 07:': 2952,\n",
       " ' 08': 1052,\n",
       " ' 085': 6528,\n",
       " ' 08:': 2991,\n",
       " ' 09': 1970,\n",
       " ' 09:': 2392,\n",
       " ' 0=': 6420,\n",
       " ' 0˚': 5268,\n",
       " ' 1': 460,\n",
       " ' 1\"': 5291,\n",
       " ' 1%': 5162,\n",
       " ' 1&': 5949,\n",
       " ' 1/': 3742,\n",
       " ' 10': 876,\n",
       " ' 10 ': 6970,\n",
       " ' 10/': 3639,\n",
       " ' 100': 2269,\n",
       " ' 101': 3740,\n",
       " ' 102': 3895,\n",
       " ' 1025': 6286,\n",
       " ' 103': 3986,\n",
       " ' 104': 4229,\n",
       " ' 105': 4255,\n",
       " ' 106': 4019,\n",
       " ' 107': 4257,\n",
       " ' 108': 4050,\n",
       " ' 109': 4388,\n",
       " ' 10:': 2160,\n",
       " ' 11': 1384,\n",
       " ' 110': 3573,\n",
       " ' 1100': 5438,\n",
       " ' 111': 4274,\n",
       " ' 112': 3903,\n",
       " ' 1129': 6845,\n",
       " ' 113': 4551,\n",
       " ' 114': 3871,\n",
       " ' 115': 4910,\n",
       " ' 116': 5017,\n",
       " ' 117': 4464,\n",
       " ' 118': 4268,\n",
       " ' 119': 3856,\n",
       " ' 119 ': 6544,\n",
       " ' 11:': 2477,\n",
       " ' 12': 1061,\n",
       " ' 120': 2958,\n",
       " ' 1200': 4514,\n",
       " ' 121': 4337,\n",
       " ' 122': 4142,\n",
       " ' 123': 4131,\n",
       " ' 124': 4172,\n",
       " ' 125': 3626,\n",
       " ' 126': 4553,\n",
       " ' 127': 3848,\n",
       " ' 128': 4252,\n",
       " ' 128 ': 6749,\n",
       " ' 129': 4395,\n",
       " ' 12:': 2485,\n",
       " ' 12: ': 6973,\n",
       " ' 13': 1385,\n",
       " ' 130': 3803,\n",
       " ' 1300': 6531,\n",
       " ' 131': 4409,\n",
       " ' 132': 4402,\n",
       " ' 133': 4026,\n",
       " ' 134': 4160,\n",
       " ' 135': 4171,\n",
       " ' 136': 4137,\n",
       " ' 137': 3975,\n",
       " ' 138': 4318,\n",
       " ' 139': 4473,\n",
       " ' 13:': 2343,\n",
       " ' 14': 1463,\n",
       " ' 14 ': 6786,\n",
       " ' 140': 4520,\n",
       " ' 1400': 6606,\n",
       " ' 141': 4322,\n",
       " ' 142': 3998,\n",
       " ' 1428': 5206,\n",
       " ' 143': 4570,\n",
       " ' 144': 4537,\n",
       " ' 145': 4931,\n",
       " ' 146': 4245,\n",
       " ' 147': 4319,\n",
       " ' 148': 4996,\n",
       " ' 149': 4016,\n",
       " ' 14:': 2300,\n",
       " ' 15': 363,\n",
       " ' 150': 3092,\n",
       " ' 1500': 4902,\n",
       " ' 151': 4619,\n",
       " ' 152': 545,\n",
       " ' 1520': 5619,\n",
       " ' 1522': 6712,\n",
       " ' 153': 4465,\n",
       " ' 154': 4892,\n",
       " ' 155': 4572,\n",
       " ' 156': 5584,\n",
       " ' 157': 4786,\n",
       " ' 158': 4413,\n",
       " ' 159': 5386,\n",
       " ' 15:': 2406,\n",
       " ' 16': 1165,\n",
       " ' 16 ': 7114,\n",
       " ' 160': 3933,\n",
       " ' 161': 5559,\n",
       " ' 162': 4381,\n",
       " ' 163': 4336,\n",
       " ' 164': 4755,\n",
       " ' 165': 4085,\n",
       " ' 166': 4385,\n",
       " ' 167': 4412,\n",
       " ' 168': 4798,\n",
       " ' 169': 4559,\n",
       " ' 16:': 2837,\n",
       " ' 17': 1312,\n",
       " ' 170': 3999,\n",
       " ' 1701': 3020,\n",
       " ' 1702': 3053,\n",
       " ' 171': 4613,\n",
       " ' 172': 4540,\n",
       " ' 173': 5193,\n",
       " ' 174': 4153,\n",
       " ' 175': 4797,\n",
       " ' 176': 5480,\n",
       " ' 177': 4363,\n",
       " ' 178': 4768,\n",
       " ' 179': 4511,\n",
       " ' 18': 1439,\n",
       " ' 180': 3966,\n",
       " ' 1806': 1930,\n",
       " ' 181': 6222,\n",
       " ' 1818': 7197,\n",
       " ' 182': 4809,\n",
       " ' 183': 4569,\n",
       " ' 184': 4156,\n",
       " ' 185': 4457,\n",
       " ' 186': 4759,\n",
       " ' 187': 4987,\n",
       " ' 188': 4630,\n",
       " ' 189': 4898,\n",
       " ' 19': 969,\n",
       " ' 190': 4009,\n",
       " ' 1900': 6206,\n",
       " ' 1901': 2359,\n",
       " ' 1904': 7020,\n",
       " ' 1905': 6023,\n",
       " ' 191': 5418,\n",
       " ' 192': 5830,\n",
       " ' 193': 5516,\n",
       " ' 194': 4383,\n",
       " ' 195': 4796,\n",
       " ' 196': 6193,\n",
       " ' 197': 5303,\n",
       " ' 198': 4708,\n",
       " ' 199': 3412,\n",
       " ' 1:': 3777,\n",
       " ' 1=': 5165,\n",
       " ' 2': 458,\n",
       " ' 2 ': 4680,\n",
       " ' 2\"': 4283,\n",
       " ' 2%': 4452,\n",
       " ' 2/': 3132,\n",
       " ' 20': 1081,\n",
       " ' 200': 1198,\n",
       " ' 201': 1701,\n",
       " ' 202': 3859,\n",
       " ' 2020': 3078,\n",
       " ' 2020 ': 6161,\n",
       " ' 2021': 3572,\n",
       " ' 2021 ': 6575,\n",
       " ' 2022': 3765,\n",
       " ' 2023': 2590,\n",
       " ' 2023 ': 5287,\n",
       " ' 203': 4431,\n",
       " ' 204': 4635,\n",
       " ' 205': 4716,\n",
       " ' 206': 5970,\n",
       " ' 207': 4952,\n",
       " ' 208': 4562,\n",
       " ' 209': 5481,\n",
       " ' 21': 1598,\n",
       " ' 210': 4203,\n",
       " ' 2100': 7045,\n",
       " ' 211': 4475,\n",
       " ' 212': 4479,\n",
       " ' 213': 5210,\n",
       " ' 214': 4460,\n",
       " ' 215': 4386,\n",
       " ' 216': 4801,\n",
       " ' 217': 4749,\n",
       " ' 218': 4784,\n",
       " ' 219': 4719,\n",
       " ' 22': 1747,\n",
       " ' 220': 4298,\n",
       " ' 221': 4542,\n",
       " ' 222': 5363,\n",
       " ' 223': 4640,\n",
       " ' 224': 5150,\n",
       " ' 225': 4155,\n",
       " ' 226': 4735,\n",
       " ' 227': 4310,\n",
       " ' 228': 4903,\n",
       " ' 229': 4888,\n",
       " ' 23': 1759,\n",
       " ' 230': 4744,\n",
       " ' 231': 6044,\n",
       " ' 232': 4595,\n",
       " ' 233': 6265,\n",
       " ' 234': 5878,\n",
       " ' 235': 4644,\n",
       " ' 236': 5082,\n",
       " ' 237': 4757,\n",
       " ' 238': 5494,\n",
       " ' 239': 4790,\n",
       " ' 24': 2670,\n",
       " ' 240': 4355,\n",
       " ' 241': 4894,\n",
       " ' 242': 4989,\n",
       " ' 243': 6245,\n",
       " ' 244': 5366,\n",
       " ' 245': 5389,\n",
       " ' 246': 5750,\n",
       " ' 247': 5565,\n",
       " ' 248': 4727,\n",
       " ' 249': 4907,\n",
       " ' 25': 2424,\n",
       " ' 250': 3618,\n",
       " ' 2500': 5423,\n",
       " ' 251': 6463,\n",
       " ' 252': 4764,\n",
       " ' 253': 6310,\n",
       " ' 254': 4605,\n",
       " ' 255': 5030,\n",
       " ' 256': 5059,\n",
       " ' 257': 4960,\n",
       " ' 258': 5236,\n",
       " ' 259': 4923,\n",
       " ' 26': 3074,\n",
       " ' 260': 4800,\n",
       " ' 261': 5581,\n",
       " ' 262': 5274,\n",
       " ' 263': 5880,\n",
       " ' 264': 5442,\n",
       " ' 265': 5118,\n",
       " ' 266': 5548,\n",
       " ' 267': 4932,\n",
       " ' 268': 5169,\n",
       " ' 269': 4851,\n",
       " ' 269 ': 6439,\n",
       " ' 27': 2827,\n",
       " ' 271': 5093,\n",
       " ' 272': 4863,\n",
       " ' 273': 5211,\n",
       " ' 274': 4913,\n",
       " ' 275': 6381,\n",
       " ' 276': 5523,\n",
       " ' 277': 5378,\n",
       " ' 278': 5542,\n",
       " ' 279': 4456,\n",
       " ' 28': 2608,\n",
       " ' 280': 4617,\n",
       " ' 281': 5973,\n",
       " ' 282': 4765,\n",
       " ' 283': 5519,\n",
       " ' 284': 5238,\n",
       " ' 285': 4448,\n",
       " ' 286': 5136,\n",
       " ' 287': 5959,\n",
       " ' 288': 4678,\n",
       " ' 289': 4953,\n",
       " ' 29': 1406,\n",
       " ' 290': 4206,\n",
       " ' 291': 5927,\n",
       " ' 292': 4681,\n",
       " ' 293': 5069,\n",
       " ' 2933': 2743,\n",
       " ' 294': 6386,\n",
       " ' 295': 4384,\n",
       " ' 296': 5544,\n",
       " ' 297': 5074,\n",
       " ' 298': 5182,\n",
       " ' 299': 5897,\n",
       " ' 2:': 4058,\n",
       " ' 2: ': 6981,\n",
       " ' 2=': 4164,\n",
       " ' 2_': 6197,\n",
       " ' 3': 556,\n",
       " ' 3 ': 5031,\n",
       " ' 3\"': 5156,\n",
       " ' 3%': 4240,\n",
       " ' 3&': 5381,\n",
       " ' 3/': 3744,\n",
       " ' 30': 2185,\n",
       " ' 300': 3153,\n",
       " ' 301': 4778,\n",
       " ' 302': 5134,\n",
       " ' 303': 4478,\n",
       " ' 304': 6078,\n",
       " ' 305': 4519,\n",
       " ' 306': 4782,\n",
       " ' 307': 6467,\n",
       " ' 308': 6649,\n",
       " ' 309': 5760,\n",
       " ' 31': 2917,\n",
       " ' 310': 4561,\n",
       " ' 311': 4474,\n",
       " ' 312': 5201,\n",
       " ' 313': 4940,\n",
       " ' 314': 4967,\n",
       " ' 315': 4831,\n",
       " ' 316': 6783,\n",
       " ' 317': 5084,\n",
       " ' 318': 5826,\n",
       " ' 319': 5648,\n",
       " ' 32': 3261,\n",
       " ' 320': 4856,\n",
       " ' 321': 5491,\n",
       " ' 322': 5180,\n",
       " ' 322 ': 6968,\n",
       " ' 323': 6478,\n",
       " ' 324': 4638,\n",
       " ' 325': 4631,\n",
       " ' 326': 5807,\n",
       " ' 327': 6689,\n",
       " ' 328': 6025,\n",
       " ' 329': 5762,\n",
       " ' 33': 3191,\n",
       " ' 330': 4223,\n",
       " ' 3300': 7205,\n",
       " ' 331': 5589,\n",
       " ' 332': 5387,\n",
       " ' 333': 5264,\n",
       " ' 334': 5944,\n",
       " ' 335': 5482,\n",
       " ' 336': 5574,\n",
       " ' 337': 6039,\n",
       " ' 338': 4854,\n",
       " ' 339': 6660,\n",
       " ' 34': 3274,\n",
       " ' 340': 4598,\n",
       " ' 3400': 6417,\n",
       " ' 341': 6049,\n",
       " ' 342': 5345,\n",
       " ' 343': 5334,\n",
       " ' 344': 6469,\n",
       " ' 345': 4904,\n",
       " ' 346': 6617,\n",
       " ' 347': 6036,\n",
       " ' 348': 6472,\n",
       " ' 349': 6926,\n",
       " ' 35': 2663,\n",
       " ' 350': 4815,\n",
       " ' 3500': 5623,\n",
       " ' 351': 5333,\n",
       " ' 352': 5547,\n",
       " ' 353': 6893,\n",
       " ' 354': 6801,\n",
       " ' 355': 4305,\n",
       " ' 356': 5073,\n",
       " ' 357': 4648,\n",
       " ' 358': 5477,\n",
       " ' 359': 5468,\n",
       " ' 36': 2953,\n",
       " ' 360': 3554,\n",
       " ' 3600': 5642,\n",
       " ' 362': 5588,\n",
       " ' 363': 4868,\n",
       " ' 364': 6390,\n",
       " ' 364 ': 7138,\n",
       " ' 365': 5159,\n",
       " ' 366': 6035,\n",
       " ' 367': 5178,\n",
       " ' 368': 6569,\n",
       " ' 369': 6526,\n",
       " ' 37': 3197,\n",
       " ' 3700': 7073,\n",
       " ' 371': 6645,\n",
       " ' 372': 4926,\n",
       " ' 373': 4502,\n",
       " ' 374': 6326,\n",
       " ' 375': 4288,\n",
       " ' 376': 6028,\n",
       " ' 377': 5681,\n",
       " ' 378': 5968,\n",
       " ' 379': 7196,\n",
       " ' 38': 2918,\n",
       " ' 380': 4965,\n",
       " ' 381': 5299,\n",
       " ' 382': 4607,\n",
       " ' 383': 6279,\n",
       " ' 384': 5097,\n",
       " ' 385': 5908,\n",
       " ' 386': 6085,\n",
       " ' 387': 4852,\n",
       " ' 388': 6560,\n",
       " ' 389': 5111,\n",
       " ' 39': 2528,\n",
       " ' 390': 6704,\n",
       " ' 391': 6665,\n",
       " ' 392': 5085,\n",
       " ' 393': 5125,\n",
       " ' 394': 4776,\n",
       " ' 395': 4415,\n",
       " ' 396': 4895,\n",
       " ' 397': 4941,\n",
       " ' 398': 6034,\n",
       " ' 399': 6620,\n",
       " ' 3:': 3806,\n",
       " ' 3=': 4293,\n",
       " ' 3_': 7015,\n",
       " ' 3¢': 7106,\n",
       " ' 3’': 6268,\n",
       " ' 4': 962,\n",
       " ' 4 ': 6675,\n",
       " ' 4\"': 4238,\n",
       " ' 4%': 4939,\n",
       " ' 4/': 3983,\n",
       " ' 40': 2886,\n",
       " ' 400': 3219,\n",
       " ' 401': 3785,\n",
       " ' 402': 5636,\n",
       " ' 403': 5637,\n",
       " ' 404': 5531,\n",
       " ' 405': 3953,\n",
       " ' 406': 3994,\n",
       " ' 407': 6947,\n",
       " ' 408': 4705,\n",
       " ' 409': 6956,\n",
       " ' 41': 3649,\n",
       " ' 410': 5484,\n",
       " ' 411': 4912,\n",
       " ' 412': 4729,\n",
       " ' 413': 5167,\n",
       " ' 414': 5398,\n",
       " ' 415': 4483,\n",
       " ' 416': 4925,\n",
       " ' 417': 5436,\n",
       " ' 418': 5641,\n",
       " ' 419': 7129,\n",
       " ' 42': 3408,\n",
       " ' 420': 4626,\n",
       " ' 421': 5340,\n",
       " ' 422': 5402,\n",
       " ' 423': 4928,\n",
       " ' 424': 5431,\n",
       " ' 425': 4878,\n",
       " ' 426': 7136,\n",
       " ' 427': 5243,\n",
       " ' 428': 6053,\n",
       " ' 429': 7171,\n",
       " ' 43': 3183,\n",
       " ' 43 ': 6153,\n",
       " ' 430': 6327,\n",
       " ' 432': 6901,\n",
       " ' 433': 5395,\n",
       " ' 434': 6900,\n",
       " ' 435': 5256,\n",
       " ' 436': 5088,\n",
       " ' 437': 7008,\n",
       " ' 438': 6486,\n",
       " ' 439': 5285,\n",
       " ' 44': 3363,\n",
       " ' 440': 7134,\n",
       " ' 442': 7105,\n",
       " ' 443': 5796,\n",
       " ' 444': 6144,\n",
       " ' 445': 4736,\n",
       " ' 446': 7144,\n",
       " ' 447': 4855,\n",
       " ' 448': 5751,\n",
       " ' 449': 4731,\n",
       " ' 45': 2756,\n",
       " ' 450': 4750,\n",
       " ' 4500': 4840,\n",
       " ' 452': 5754,\n",
       " ' 453': 4929,\n",
       " ' 454': 7040,\n",
       " ' 455': 5218,\n",
       " ' 456': 5284,\n",
       " ' 457': 5372,\n",
       " ' 458': 6919,\n",
       " ' 459': 6988,\n",
       " ' 46': 3512,\n",
       " ' 460': 6653,\n",
       " ' 463': 5148,\n",
       " ' 464': 5039,\n",
       " ' 465': 6479,\n",
       " ' 466': 5435,\n",
       " ' 467': 5321,\n",
       " ' 468': 5546,\n",
       " ' 469': 5311,\n",
       " ' 47': 3511,\n",
       " ' 472': 5520,\n",
       " ' 473': 5744,\n",
       " ' 474': 6984,\n",
       " ' 475': 4853,\n",
       " ' 476': 5109,\n",
       " ' 477': 5735,\n",
       " ' 478': 5293,\n",
       " ' 479': 7193,\n",
       " ' 48': 3122,\n",
       " ' 480': 4930,\n",
       " ' 481': 6428,\n",
       " ' 482': 5804,\n",
       " ' 483': 6802,\n",
       " ' 484': 7123,\n",
       " ' 485': 6104,\n",
       " ' 486': 5306,\n",
       " ' 487': 6235,\n",
       " ' 488': 6789,\n",
       " ' 489': 5631,\n",
       " ' 49': 3601,\n",
       " ' 490': 4844,\n",
       " ' 492': 7166,\n",
       " ' 493': 6500,\n",
       " ' 494': 6174,\n",
       " ' 495': 5906,\n",
       " ' 496': 5663,\n",
       " ' 497': 6041,\n",
       " ' 498': 7112,\n",
       " ' 499': 5316,\n",
       " ' 4:': 4218,\n",
       " ' 4: ': 6909,\n",
       " ' 4=': 4377,\n",
       " ' 4”': 5793,\n",
       " ' 5': 963,\n",
       " ' 5 ': 6320,\n",
       " ' 5%': 3997,\n",
       " ' 5+': 4432,\n",
       " ' 5/': 3888,\n",
       " ' 50': 2201,\n",
       " ' 500': 3310,\n",
       " ' 501': 4080,\n",
       " ' 502': 3821,\n",
       " ' 503': 4722,\n",
       " ' 504': 4081,\n",
       " ' 505': 4544,\n",
       " ' 506': 5474,\n",
       " ' 507': 4775,\n",
       " ' 508': 4897,\n",
       " ' 509': 5853,\n",
       " ' 51': 3666,\n",
       " ' 510': 4787,\n",
       " ' 511': 4834,\n",
       " ' 512': 4927,\n",
       " ' 513': 4450,\n",
       " ' 514': 6902,\n",
       " ' 515': 6046,\n",
       " ' 516': 4924,\n",
       " ' 517': 4920,\n",
       " ' 518': 5204,\n",
       " ' 519': 5447,\n",
       " ' 52': 3193,\n",
       " ' 520': 4596,\n",
       " ' 522': 5029,\n",
       " ' 523': 5898,\n",
       " ' 524': 5687,\n",
       " ' 525': 4724,\n",
       " ' 526': 4885,\n",
       " ' 527': 4715,\n",
       " ' 528': 6051,\n",
       " ' 529': 5932,\n",
       " ' 53': 3606,\n",
       " ' 530': 6709,\n",
       " ' 5319': 6097,\n",
       " ' 532': 5829,\n",
       " ' 533': 5175,\n",
       " ' 534': 5068,\n",
       " ' 535': 5250,\n",
       " ' 536': 5945,\n",
       " ' 537': 4770,\n",
       " ' 538': 5975,\n",
       " ' 539': 6088,\n",
       " ' 54': 3518,\n",
       " ' 540': 4942,\n",
       " ' 542': 6697,\n",
       " ' 544': 5888,\n",
       " ' 545': 5561,\n",
       " ' 546': 6109,\n",
       " ' 547': 4774,\n",
       " ' 548': 4988,\n",
       " ' 549': 5339,\n",
       " ' 55': 3048,\n",
       " ' 550': 4150,\n",
       " ' 5504': 4295,\n",
       " ' 551': 7063,\n",
       " ' 552': 5235,\n",
       " ' 553': 4702,\n",
       " ' 554': 5462,\n",
       " ' 555': 6289,\n",
       " ' 556': 6538,\n",
       " ' 557': 5419,\n",
       " ' 558': 5292,\n",
       " ' 559': 5638,\n",
       " ' 56': 3308,\n",
       " ' 560': 5879,\n",
       " ' 563': 5408,\n",
       " ' 564': 5821,\n",
       " ' 565': 6421,\n",
       " ' 566': 5626,\n",
       " ' 567': 6333,\n",
       " ' 568': 5337,\n",
       " ' 569': 6759,\n",
       " ' 57': 3425,\n",
       " ' 572': 5290,\n",
       " ' 573': 5437,\n",
       " ' 574': 6490,\n",
       " ' 575': 5343,\n",
       " ' 576': 6212,\n",
       " ' 577': 5755,\n",
       " ' 578': 5956,\n",
       " ' 579': 5892,\n",
       " ' 58': 3465,\n",
       " ' 580': 4706,\n",
       " ' 581': 6216,\n",
       " ' 584': 4865,\n",
       " ' 585': 6074,\n",
       " ' 586': 5514,\n",
       " ' 587': 7190,\n",
       " ' 588': 6779,\n",
       " ' 589': 6980,\n",
       " ' 59': 3805,\n",
       " ' 59 ': 6158,\n",
       " ' 590': 5720,\n",
       " ' 5900': 7133,\n",
       " ' 592': 5054,\n",
       " ' 593': 7204,\n",
       " ' 594': 6507,\n",
       " ' 595': 5592,\n",
       " ' 596': 6961,\n",
       " ' 597': 4867,\n",
       " ' 598': 5358,\n",
       " ' 599': 4777,\n",
       " ' 5:': 6880,\n",
       " ' 5=': 4437,\n",
       " ' 5¢': 5725,\n",
       " ' 5‐': 6307,\n",
       " ' 6': 1229,\n",
       " ' 6 ': 6732,\n",
       " ' 6\"': 4372,\n",
       " ' 6\" ': 5788,\n",
       " ' 6%': 3844,\n",
       " ' 6/': 4418,\n",
       " ' 60': 2733,\n",
       " ' 600': 3121,\n",
       " ' 601': 5566,\n",
       " ' 602': 5860,\n",
       " ' 603': 6836,\n",
       " ' 604': 5866,\n",
       " ' 605': 5538,\n",
       " ' 606': 5656,\n",
       " ' 607': 5116,\n",
       " ' 608': 5130,\n",
       " ' 609': 5449,\n",
       " ' 61': 3477,\n",
       " ' 610': 4317,\n",
       " ' 611': 4105,\n",
       " ' 612': 4515,\n",
       " ' 614': 5346,\n",
       " ' 615': 5971,\n",
       " ' 616': 5893,\n",
       " ' 617': 5108,\n",
       " ' 618': 5917,\n",
       " ' 619': 5216,\n",
       " ' 62': 3374,\n",
       " ' 620': 3638,\n",
       " ' 622': 6295,\n",
       " ' 623': 6683,\n",
       " ' 624': 6098,\n",
       " ' 625': 5926,\n",
       " ' 626': 5805,\n",
       " ' 627': 6149,\n",
       " ' 628': 5954,\n",
       " ' 629': 7127,\n",
       " ' 63': 3347,\n",
       " ' 630': 5327,\n",
       " ' 632': 7095,\n",
       " ' 633': 5220,\n",
       " ' 634': 5586,\n",
       " ' 635': 5246,\n",
       " ' 636': 5262,\n",
       " ' 637': 5369,\n",
       " ' 638': 5361,\n",
       " ' 639': 5258,\n",
       " ' 64': 2884,\n",
       " ...}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(tokenizer._tokenize(\"These casseroles disgust Kayla.\"))\n",
    "tokenizer._vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3328d1cf",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9283d9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the tokenizer and create Encoder then use that to create decoder and full model\n",
    "model = SAFFUDecoder(config, SAFFUEncoder(config, tokenizer)).to(device)\n",
    "\n",
    "# Define the current stage of the model initial\n",
    "stage = \"init\"\n",
    "\n",
    "# Set to determine whether we are reloading or not\n",
    "reload = False\n",
    "\n",
    "# If in reload mode or the path doesnt exist for this dataset-model-stage combo then save_model\n",
    "if reload or (not os.path.exists(f\"./models_to_test/{data_set}-{model_size}-{stage}.state\")):\n",
    "    \n",
    "    \"\"\"\n",
    "    Saves the following information about current dataset-model_size-stage combo of the model\n",
    "    \n",
    "    1. state - Weights/params of the model which can be loaded later for resuming training or inference\n",
    "    2. losses - Training losses over epochs\n",
    "    3. counts - Frequency of words/subwords important for BPE\n",
    "    4. vocabulary - Mapping of words to indices to form vocab with keys as words and index as value\n",
    "    5. raw_td - Merge pairs dictating how subwords were combined to form new tokens, important for BPE\n",
    "    6. subtoken_reference - Maps text to its subwords, important for mapping output to og format\n",
    "    7. docsizes - Sizes of docs or number of tokens per doc\n",
    "    8. reference - Metadata related to training data or model perhaps\n",
    "    \"\"\"\n",
    "    save_model(model, data_set, model_size, stage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e503fc57",
   "metadata": {},
   "source": [
    "Step by step explanation of model:\n",
    "\n",
    "**Encoder**\n",
    "- 1. logsoft (LogSoftmax)\n",
    "    - a. Converts input tokens to log-probability representation for smoothing, preventing over/underflow, normalizing. \n",
    "    - b. Could be that the input tokens are treated as if they already carry certain relationships and LogSoftmax helps the model understand them probabilistically before passing them to Embeding layer _V\n",
    "- 2. _V (Embedding Layer)\n",
    "    - a. Is of dim: vocab_size x embed_size and converts each incoming word into embed_size vector\n",
    "    - b. Frozen during warm start and explicitly initialized to avoid changing during early training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb39234f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Model:\n",
      "SAFFUDecoder(\n",
      "  (encoder): SAFFUEncoder(\n",
      "    (logsoft): LogSoftmax(dim=0)\n",
      "    (_V): Embedding(7206, 128)\n",
      "    (BS): ModuleList(\n",
      "      (0): SAFFULayer(\n",
      "        (activate): LogSoftmax(dim=0)\n",
      "        (logsoft): LogSoftmax(dim=0)\n",
      "        (_W): Linear(in_features=256, out_features=256, bias=False)\n",
      "        (_U): Linear(in_features=128, out_features=64, bias=False)\n",
      "      )\n",
      "    )\n",
      "    (RS): ModuleList(\n",
      "      (0): SAFFULayer(\n",
      "        (activate): LogSoftmax(dim=0)\n",
      "        (logsoft): LogSoftmax(dim=0)\n",
      "        (_W): Linear(in_features=2, out_features=2, bias=False)\n",
      "        (_U): Linear(in_features=256, out_features=64, bias=False)\n",
      "      )\n",
      "    )\n",
      "    (_W): FFULayer(\n",
      "      (activate): LogSoftmax(dim=0)\n",
      "      (_U): Linear(in_features=160, out_features=160, bias=False)\n",
      "    )\n",
      "    (_D): FFULayer(\n",
      "      (activate): LogSoftmax(dim=0)\n",
      "      (_U): Linear(in_features=128, out_features=32, bias=False)\n",
      "    )\n",
      "  )\n",
      "  (_Uc): FFULayer(\n",
      "    (activate): LogSoftmax(dim=0)\n",
      "    (_U): Linear(in_features=160, out_features=7206, bias=False)\n",
      "  )\n",
      "  (_Ud): Linear(in_features=32, out_features=28825, bias=False)\n",
      "  (logsoft): LogSoftmax(dim=0)\n",
      ")\n",
      "\n",
      "Encoder Part to Use:\n",
      "SAFFUEncoder(\n",
      "  (logsoft): LogSoftmax(dim=0)\n",
      "  (_V): Embedding(7206, 128)\n",
      "  (BS): ModuleList(\n",
      "    (0): SAFFULayer(\n",
      "      (activate): LogSoftmax(dim=0)\n",
      "      (logsoft): LogSoftmax(dim=0)\n",
      "      (_W): Linear(in_features=256, out_features=256, bias=False)\n",
      "      (_U): Linear(in_features=128, out_features=64, bias=False)\n",
      "    )\n",
      "  )\n",
      "  (RS): ModuleList(\n",
      "    (0): SAFFULayer(\n",
      "      (activate): LogSoftmax(dim=0)\n",
      "      (logsoft): LogSoftmax(dim=0)\n",
      "      (_W): Linear(in_features=2, out_features=2, bias=False)\n",
      "      (_U): Linear(in_features=256, out_features=64, bias=False)\n",
      "    )\n",
      "  )\n",
      "  (_W): FFULayer(\n",
      "    (activate): LogSoftmax(dim=0)\n",
      "    (_U): Linear(in_features=160, out_features=160, bias=False)\n",
      "  )\n",
      "  (_D): FFULayer(\n",
      "    (activate): LogSoftmax(dim=0)\n",
      "    (_U): Linear(in_features=128, out_features=32, bias=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(f'Full Model:\\n{model}')\n",
    "print(f'\\nEncoder Part to Use:\\n{model.encoder}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e187265-f3ed-4f8a-83e2-398862e63802",
   "metadata": {},
   "source": [
    "# CHecker to Clear Parsing Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198f0265-3bca-4103-84fb-b2bd37a32049",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0fd75b-8af0-4f79-b198-39e3fee2ae9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239bfd42-1be7-45ce-ba25-170bb7c14053",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92bc5b2-97a7-4c4b-9fd3-24c330b9354a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54cc5ba-a3ca-4194-acdf-57048507b8f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa109b05-cc67-4980-9868-2255a7eec561",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e5eb69-ab6c-49cc-a3bf-5b5af1df0300",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9855bb3-5813-4416-b7c0-cdcad88428d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87034dfb-cf12-488f-b855-134c52ee86d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e091bc70",
   "metadata": {},
   "source": [
    "# Data Setup for SAFFU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e611f9e-e57f-4aba-82fa-b25156d51b4a",
   "metadata": {},
   "source": [
    "## Create Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "371d1419",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Files: 100%|█████████████████████████| 10/10 [00:22<00:00,  2.20s/it]\n"
     ]
    }
   ],
   "source": [
    "# Define the training directory and get loader\n",
    "train_dir = '../data/train_big/'\n",
    "train_loader = get_saffuloader(train_dir, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "51c32668-1edb-4dc6-a0db-d64cd88dd161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the validation directory and get loader\n",
    "# val_dir = '../data/train_small/'\n",
    "# val_loader = get_saffuloader(val_dir, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2cd49d42-1351-4af6-aa08-539827666903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Code to observe loaders if required\n",
    "# print(train_loader.file_paths[0])\n",
    "# print(train_loader.x_tok[0][17,1,:])\n",
    "# print(train_loader.y_tok[0][17,1,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96a78e0-63cb-4892-9758-97a0f96b0d0e",
   "metadata": {},
   "source": [
    "## Generate Docs and Convos/Dconvos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d69a207-b53e-4196-a0c0-217637ab568a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.014459371566772461,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 20,
       "postfix": null,
       "prefix": "PARA - Generating Docs",
       "rate": null,
       "total": 1240,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c474f6807eb34300b0250863b8909605",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PARA - Generating Docs:   0%|          | 0/1240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Docs length (8115697), first 50 elems:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the docs list and observe\n",
    "docs = saffutok_traindata(train_dir)\n",
    "\n",
    "# Code to observe docs\n",
    "print(f'\\nDocs length ({len(docs)}), first 50 elems:\\n{docs[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2883e17-a603-4418-8047-4324c93a4d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2967113/2147056673.py:2: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  convos = [[doc] for i, doc in tqdm(enumerate(docs), desc=\"Generating convos\") if (i % 5) and doc]\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0056972503662109375,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 20,
       "postfix": null,
       "prefix": "Generating convos",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "527a5de9f7bb4aaf8913b14c0ac19e21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating convos: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2967113/2147056673.py:3: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  dconvos = [[doc] for i, doc in tqdm(enumerate(docs), desc=\"Generating dconvos\") if (not i % 5) and doc]\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0036194324493408203,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 20,
       "postfix": null,
       "prefix": "Generating dconvos",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fbd070c3f2c411390356fd45ee26811",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dconvos: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Convos length (1884116), first 10 elems:\n",
      "[['TRANSWESTERN PIPELINE COMPANY'], ['Rate calculation is based on the spread of two indices less variable charges (fuel/usage) less fixed rate or spread.  PG&E to provide index price calc.'], ['Settlement Based Max Reservation Rates and TCR Surcharges changed eff 11/1/00; GRD rate changed eff 1/1/01.'], ['DEALS ABOVE MAX TARIFF RATE'], ['RLSE'], ['REPLACEMENT'], ['REPLACEMENT'], ['OFFER'], ['REPLACEMENT'], ['REPLACEMENT']]\n",
      "\n",
      "DConvos length (469624), first 10 elems:\n",
      "[['CAPACITY RELEASE REPORT'], ['                                                                                                                                                                                                                                                               '], ['CREDIT TO'], ['RE-'], ['Rate'], ['RLSE SHIPPER'], ['DELIVERY POI'], ['VOL'], ['MAX RATE**'], ['ARR']]\n"
     ]
    }
   ],
   "source": [
    "# Put every integer divisible by 5 in dconvos and rest in convos essentially splitting it into 80-20 train-val split\n",
    "convos = [[doc] for i, doc in tqdm(enumerate(docs), desc=\"Generating convos\") if (i % 5) and doc]\n",
    "dconvos = [[doc] for i, doc in tqdm(enumerate(docs), desc=\"Generating dconvos\") if (not i % 5) and doc]\n",
    "\n",
    "# Code to observe convos and dconvos\n",
    "print(f'\\nConvos length ({len(convos)}), first 10 elems:\\n{convos[:10]}')\n",
    "print(f'\\nDConvos length ({len(dconvos)}), first 10 elems:\\n{dconvos[:10]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd2e292-cffc-40a3-80b9-9ca38519e0bd",
   "metadata": {},
   "source": [
    "# Tuning\n",
    "\n",
    "## Warm Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ad01a7b-f9f3-4dc0-a287-585cf88f06bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:414: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004055500030517578,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 20,
       "postfix": null,
       "prefix": "Warming V-matrix",
       "rate": null,
       "total": 10,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07842a378e7448469e9ed873e1590dfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Warming V-matrix:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated data from 22255515 token pieces.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "sparse tensors do not have strides",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 27\u001b[0m\n\u001b[1;32m     23\u001b[0m tuner \u001b[38;5;241m=\u001b[39m SAFFUTuner(ignore_case, ignore_space, devstr, warm_vecs, identity_ratio \u001b[38;5;241m=\u001b[39m identity_ratio, \n\u001b[1;32m     24\u001b[0m                    label_iterations \u001b[38;5;241m=\u001b[39m label_iterations, log_label \u001b[38;5;241m=\u001b[39m log_label, nlabels \u001b[38;5;241m=\u001b[39m nlabels, centroids \u001b[38;5;241m=\u001b[39m centroids, icf \u001b[38;5;241m=\u001b[39m icf)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Initiate warm start\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m \u001b[43mtuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwarm_start\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdconvos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownsample\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevsample\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdevsample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_file\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mwarm_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreload\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mreload\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<string>:760\u001b[0m, in \u001b[0;36mwarm_start\u001b[0;34m(self, model, docs, ddocs, downsample, seed, epochs, patience, devsample, model_file, reload, verbose, training_targets, development_targets, combined_loss)\u001b[0m\n",
      "File \u001b[0;32m<string>:441\u001b[0m, in \u001b[0;36mset_embeddings\u001b[0;34m(self, model, splits, splits_dis, splits_targets, model_file, V_sum_1, p)\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: sparse tensors do not have strides"
     ]
    }
   ],
   "source": [
    "# Set grad to false to freeze embedding layer since we are warm starting\n",
    "model.encoder._V.weight.requires_grad = False\n",
    "\n",
    "# Define params\n",
    "seed = 691; ignore_space = False; ignore_case = False; warm_start = True; verbose = True; \n",
    "warm_vecs = 1*(2**0 + 0.99999); identity_ratio = 2**(-1); icf = True \n",
    "log_label = False; nlabels = 1*(2**0); centroids = False; label_iterations = 1*(2**10) # None \n",
    "epochs = int(np.max([int(downsample/5), 1]))*(2**5)\n",
    "#epochs = int(np.max([int(downsample/5), 1]))\n",
    "patience = 2**1\n",
    "\n",
    "# Decide if new run\n",
    "reload = False\n",
    "\n",
    "# Generate warm file\n",
    "warm_file = \"\".join([data_file[:-5] + \"-\", \n",
    "                     f\"b_{tokenizer.config._bits}-hb_{tokenizer.config._hidden}-\",\n",
    "                     f\"we_{int(tokenizer.config._wave_encode)}-oa_{tokenizer.config._o_agg}-ra_{tokenizer.config._r_agg}-ba_{tokenizer.config._b_agg}-\",\n",
    "                     f\"mr_{int(tokenizer.config._mask_r)}-mb_{int(tokenizer.config._mask_b)}-md_{tokenizer.config._model_documents}-\",\n",
    "                     f\"is_{int(ignore_space)}-ic_{int(ignore_case)}-ws_{int(warm_start)}-wv_{int(warm_vecs)}-ds_{downsample}-seed_{seed}\"])\n",
    "\n",
    "# Create the tuner\n",
    "tuner = SAFFUTuner(ignore_case, ignore_space, devstr, warm_vecs, identity_ratio = identity_ratio, \n",
    "                   label_iterations = label_iterations, log_label = log_label, nlabels = nlabels, centroids = centroids, icf = icf)\n",
    "\n",
    "# Initiate warm start\n",
    "tuner.warm_start(model, convos, dconvos, downsample*10, seed, epochs, patience, devsample = devsample, model_file = warm_file, reload = reload, verbose = verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4de544a3-c265-47a5-896c-7fa6b02f96d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "467653d2-b18f-495d-8b9f-a03baee1eb3c",
   "metadata": {},
   "source": [
    "tune_loss = model._losses; del tuner\n",
    "tune_loss"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f2fdc922-cb94-4829-94d8-652c9475ea64",
   "metadata": {},
   "source": [
    "model.encoder._V.weight.requires_grad = False\n",
    "\n",
    "total_params, total_learnable = 0, 0\n",
    "for name, param in model.named_parameters():\n",
    "    total_params += int(np.exp(sum(np.log(param.shape))))\n",
    "    if param.requires_grad:\n",
    "        total_learnable += int(np.exp(sum(np.log(param.shape)))) # param.shape[0]*param.shape[1]\n",
    "        # print(name, param.shape[0]*param.shape[1])\n",
    "\n",
    "print(f\"Total numbers of learnable/all parameters: {total_learnable}/{total_params}\")\n",
    "\n",
    "reload = True\n",
    "downsamp = downsample*10\n",
    "# epochs = downsamp*(2**5)\n",
    "epochs = 1\n",
    "patience = 2**4\n",
    "batch = 2**0; print_every = 0\n",
    "beta = 1.0; embeddings = True\n",
    "model_file = (warm_file + f\"-pat_{patience}-lr_{int(0.5 + 1/eta)}-ds_{downsample}-b_{batch}-s_{seed}-be_{beta}\" + \n",
    "              (f\"-e_{len(tune_loss) - 1}\"  if len(tune_loss) - 1 else \"\"))\n",
    "train_model(model, convos, dconvos, epochs, eta, patience, downsamp, batch, devsample = devsample, seed = seed, print_every = print_every, \n",
    "            model_file = model_file, reload = reload, verbose = verbose)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f241ceb0-9f82-4a80-a918-0996c949810e",
   "metadata": {},
   "source": [
    "model.encoder._V.weight.requires_grad = True\n",
    "\n",
    "parameters = [] \n",
    "if model.encoder._V.weight.requires_grad:\n",
    "    for name, param in model.named_parameters():\n",
    "        if name == 'encoder._V.weight': \n",
    "            print(\"Setting separate learning rate for the embedding layer.\")\n",
    "            lr = config._batch_size*eta/(config._b*config._bits) # /10 # dataset_size*2**9\n",
    "        else:\n",
    "            lr = config._batch_size*eta/config._b\n",
    "        parameters += [{'params': [p for n, p in model.named_parameters() if n == name and p.requires_grad], 'lr': lr}]\n",
    "\n",
    "total_params, total_learnable = 0, 0\n",
    "for name, param in model.named_parameters():\n",
    "    total_params += int(np.exp(sum(np.log(param.shape))))\n",
    "    if param.requires_grad:\n",
    "        total_learnable += int(np.exp(sum(np.log(param.shape)))) # param.shape[0]*param.shape[1]\n",
    "        # print(name, param.shape[0]*param.shape[1])\n",
    "\n",
    "print(f\"Total numbers of learnable/all parameters: {total_learnable}/{total_params}\")\n",
    "downsamp = downsample*10\n",
    "# epochs = downsamp*(2**5)\n",
    "epochs = 1\n",
    "reload = True\n",
    "patience = 2**2\n",
    "batch = 2**0; print_every = 0\n",
    "end_file =  model_file + f\"-dds_{downsamp}\"\n",
    "train_model(model, convos, dconvos, epochs, eta, patience, downsamp, batch, devsample = devsample, seed = seed, print_every = print_every, \n",
    "            model_file = end_file, reload = reload, epoch_start = 0, verbose = verbose, parameters = parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "c5fac822",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestRNN2(nn.Module):\n",
    "\n",
    "    # Constructor of the RNN_LM class, initializing the layers and weights\n",
    "    def __init__(self, saffu_model, dropout_rate=0.0, nonlinearity='relu'): # hidden_state_dim, rnn_layers, embedding_matrix\n",
    "\n",
    "        # Ensures functions of parent class nn.Module are called in subclass RNN_LM\n",
    "        super(TestRNN2, self).__init__()\n",
    "\n",
    "        # Rows of embed matrix = Each word in the vocabulary\n",
    "        # self.vocab_size = embedding_matrix.shape[0]  # vocab_size = 34057\n",
    "        self.vocab_size = len(saffu_model.encoder.tokenizer._vocabulary)\n",
    "\n",
    "        # Cols of embed matrix = Length of each embedding vector\n",
    "        # self.embedding_dim = embedding_matrix.shape[1]  # embed_dim = 50\n",
    "        self.embedding_dim = saffu_model.encoder.config._bits\n",
    "\n",
    "        # The dimension of the hidden state vector 'h' for each step/token\n",
    "        # self.hidden_dim = hidden_state_dim  # hid_dim = 100\n",
    "        self.hidden_dim = saffu_model.encoder.config._encoder_dim\n",
    "\n",
    "        # Number of recurrent layers we will use\n",
    "        # self.rnn_layers = rnn_layers  # rnn_layers = 2\n",
    "        self.saffu_model = saffu_model\n",
    "\n",
    "        # Creates an embedding layer from the pre-trained embedding matrix that maps input tokens to their corresponding word vectors\n",
    "        # If freezing then embeddings don't change during training, we need False because we need them to finetune to our task\n",
    "        # self._embed = nn.Embedding.from_pretrained(embedding_matrix, freeze=False)\n",
    "\n",
    "        # Randomly zeroes out a percentage of input units determined by dropout_rate for each update during training\n",
    "        self._drop = nn.Dropout(dropout_rate)\n",
    "\n",
    "        # RNN layer with 'relu' nonlinearity but not managing exploding gradients, dropout and multiple recurrent layers\n",
    "        # self._rnn = nn.RNN(\n",
    "        #     self.embedding_dim,\n",
    "        #     self.hidden_dim,\n",
    "        #     self.rnn_layers,\n",
    "        #     nonlinearity=nonlinearity,\n",
    "        #     dropout=dropout_rate\n",
    "        # )\n",
    "\n",
    "        # Linear layer to map the concatenated hidden states to logits (1 to predict bold or not)\n",
    "        self._pred = nn.Linear(2 * self.hidden_dim, 1)\n",
    "\n",
    "    def cell_hs(self, x):\n",
    "\n",
    "        # Set the manual seed for reproducibility\n",
    "        torch.manual_seed(0)\n",
    "\n",
    "        # Initialize H_local as a zero tensor with the appropriate shape (num_cells, hidden_dim)\n",
    "        # H_local = torch.zeros(x.shape[1] * x.shape[2], self.hidden_dim, device=x.device) # cells x hidden_dim\n",
    "        H_local = torch.zeros(x.shape[0], x.shape[1] * x.shape[2], self.hidden_dim, device=x.device) # batch x cells x hidden_dim\n",
    "        \n",
    "#         # DEBUG PRINT\n",
    "#         print(f'Input x: {x.shape}')\n",
    "#         print(f'\\nH_local before {H_local.shape}:\\n{H_local}')\n",
    "\n",
    "        # Iterate over each cell\n",
    "        for cell in tqdm(range(x.shape[1] * x.shape[2]),desc=\"Getting Cells\"):\n",
    "            \n",
    "            # Get the current row and col\n",
    "            row = cell // x.shape[2]\n",
    "            col = cell % x.shape[2]\n",
    "            \n",
    "            # Extract cell tokens across batches for current cell\n",
    "            celltoks_across_batch = x[:, row, col, :] # batch_size x tokens equivalent to 'blocks', except it is missing leading pad tokens\n",
    "\n",
    "            # Get tokens in embedding dim and apply dropout\n",
    "            # embedded_toks = self._drop(self._embed(celltoks_across_batch)) # batch_size x tokens x embed_dim\n",
    "\n",
    "            # Now run RNN on dropout\n",
    "            # _, h = self._rnn(embedded_toks)\n",
    "            _, h, _ = self.saffu_model.encoder(self.saffu_model.encoder.inflate(celltoks_across_batch), celltoks_across_batch, False, \n",
    "                                               range(celltoks_across_batch.shape[0]), range(celltoks_across_batch.shape[1] - (self.saffu_model.encoder.config._r + 1))).to_tuple() # (batch_size * tokens) x hidden\n",
    "            h = torch.reshape(h, (celltoks_across_batch.shape[0], celltoks_across_batch.shape[1] - (self.saffu_model.encoder.config._r + 1), -1)) # batch_size x tokens x hidden\n",
    "            \n",
    "            # Store hidden state from last rnn layer for last token in H_local tensor\n",
    "            # H_local[cell] = h[-1, -1, :]\n",
    "            H_local[:, cell, :] = h[:,-1,:]\n",
    "            \n",
    "#             # DEBUG PRINT\n",
    "#             if cell == 0:\n",
    "#                 print(f'\\nInside Cell {cell}\\nRow {row}, Col {col}')\n",
    "#                 print(f'\\nCell Across {celltoks_across_batch.shape}:\\n{celltoks_across_batch}')\n",
    "#                 print(f'\\nCell Embedded Toks {embedded_toks.shape}:\\n{embedded_toks}')\n",
    "#                 print(f'\\nRNN H {h.shape}:\\n{h}')\n",
    "#                 print(f'\\nLast RNN Layer Last Token HS {H_local[cell].shape}:\\n{H_local[cell]}')\n",
    "\n",
    "            # Delete intermediate tensors to free up memory\n",
    "            del celltoks_across_batch\n",
    "            # del embedded_toks\n",
    "            del h\n",
    "\n",
    "\n",
    "        # Now get the sum of all the HS in size cells x hidden_dim and subtract individual HS\n",
    "        # ans = H_local.sum(dim=0, keepdim=True) - H_local # cells x hidden_dim\n",
    "        ans = H_local.sum(dim=1, keepdim=True) - H_local # batch x cells x hidden_dim\n",
    "        \n",
    "#         # DEBUG PRINT\n",
    "#         print(f'\\nFinal H_local {H_local.shape}:\\n{H_local}')\n",
    "#         print(f'\\nFinal Returned Tensor {ans.shape}:\\n{ans}')\n",
    "\n",
    "        # Delete the H_local \n",
    "        del H_local\n",
    "        \n",
    "        # Calculate the global sum and return the adjusted tensor\n",
    "        return ans\n",
    "    \n",
    "    # Forward function\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Set the manual seed\n",
    "        torch.manual_seed(0)\n",
    "\n",
    "        # Global hidden states containing info around current cell already on gpu\n",
    "        H_global = self.cell_hs(x) # cells x hidden_dim\n",
    "\n",
    "        # Tensor to store the full macro cube of size batch x rows x cols\n",
    "        S_cube = torch.zeros((x.shape[0], x.shape[1], x.shape[2]), device=x.device)\n",
    "        \n",
    "#         # DEBUG PRINT\n",
    "#         print(f'\\nInput x {x.shape}')\n",
    "#         print(f'\\nInitial H_global {H_global.shape}:\\n{H_global}')\n",
    "#         print(f'\\nInitial S_cube {S_cube.shape}:\\n{S_cube}')\n",
    "\n",
    "        # Loop through all rows x cols cells\n",
    "        for cell in range(x.shape[1] * x.shape[2]):\n",
    "            \n",
    "            # Get the current row and col\n",
    "            row = cell // x.shape[2]\n",
    "            col = cell % x.shape[2]\n",
    "            \n",
    "            # Extract cell tokens across batches for current cell\n",
    "            celltoks_across_batch = x[:, row, col, :] # batch_size x tokens\n",
    "            \n",
    "            # Get tokens in embedding dim and apply dropout\n",
    "            # embedded_toks = self._drop(self._embed(celltoks_across_batch)) # batch_size x tokens x embed_dim\n",
    "\n",
    "            # Now run RNN on embedded toks\n",
    "            # z, _ = self._rnn(embedded_toks) # batch_size x tokens x hidden_dim\n",
    "            _, h, _ = self.saffu_model.encoder(self.saffu_model.encoder.inflate(celltoks_across_batch), celltoks_across_batch, False, \n",
    "                                               range(celltoks_across_batch.shape[0]), range(celltoks_across_batch.shape[1] - (self.saffu_model.encoder.config._r + 1))).to_tuple() # (batch_size * tokens) x hidden\n",
    "            h = torch.reshape(h, (celltoks_across_batch.shape[0], celltoks_across_batch.shape[1] - (self.saffu_model.encoder.config._r + 1), -1)) # batch_size x tokens x hidden\n",
    "            \n",
    "            # Get z for last token across all batches and hidden dim\n",
    "            # z_lasttok = z[:, -1, :] # batch_size x hidden_dim\n",
    "            \n",
    "            # Extract H_global for current cell and introduce first dimension, then expand first dim to batch_size\n",
    "            # H_cell = H_global[cell].unsqueeze(0).expand(x.shape[0], -1) # batch_size x hidden_dim\n",
    "\n",
    "            # Concatenate global/local context of cell along first dim batch_size then apply dropout\n",
    "            # concat_hs = self._drop(torch.cat((z_lasttok, H_cell), dim = 1)) # batch_size x (2 * hidden_dim)\n",
    "\n",
    "            concat_hs = self._drop(torch.cat((h[:, -1, :], H_global[:, cell, :]), dim = 2)) # batch_size x (2 * hidden_dim)\n",
    "            \n",
    "            # Make preds using this HS and adjust to be batch_size, set to current location in S_cube\n",
    "            S_cube[:, row, col] = self._pred(concat_hs).view(-1) # batch_size\n",
    "            \n",
    "#             # DEBUG PRINT\n",
    "#             if cell == 0:\n",
    "#                 print(f'\\nInside Cell {cell}\\nRow {row}, Col {col}')\n",
    "#                 print(f'\\nCell Across {celltoks_across_batch.shape}:\\n{celltoks_across_batch}')\n",
    "#                 print(f'\\nCell Embedded Toks {embedded_toks.shape}:\\n{embedded_toks}')\n",
    "#                 print(f'\\nRNN Z {z.shape}:\\n{z}')\n",
    "#                 print(f'\\nRNN Z Last Token {z_lasttok.shape}:\\n{z_lasttok}')\n",
    "#                 print(f'\\nH_cell global HS for cell {H_cell.shape}:\\n{H_cell}')\n",
    "#                 print(f'\\nConcatenated HS {concat_hs.shape}:\\n{concat_hs}')\n",
    "#                 print(f'\\nPredictions {S_cube[:, row, col].shape}:\\n{S_cube[:, row, col]}')\n",
    "\n",
    "\n",
    "            # Delete intermediate tensors to free up memory\n",
    "            del celltoks_across_batch\n",
    "            # del embedded_toks\n",
    "            # del z\n",
    "            # del z_lasttok\n",
    "            # del H_cell\n",
    "            del concat_hs\n",
    "        \n",
    "        \n",
    "#         # DEBUG PRINT\n",
    "#         print(f'\\nFinal S_cube {S_cube.shape}:\\n{S_cube}')\n",
    "        \n",
    "        # Delete H_global finally\n",
    "        del H_global\n",
    "        \n",
    "        # Return the final S_cube\n",
    "        return S_cube\n",
    "        \n",
    "                \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1674036f",
   "metadata": {},
   "source": [
    "# Trying New Model with SAFFU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "a8020785-facc-4c15-b78d-68fbecac7fe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TestRNN2(\n",
       "  (saffu_model): SAFFUDecoder(\n",
       "    (encoder): SAFFUEncoder(\n",
       "      (logsoft): LogSoftmax(dim=0)\n",
       "      (_V): Embedding(6130, 128)\n",
       "      (BS): ModuleList(\n",
       "        (0): SAFFULayer(\n",
       "          (activate): LogSoftmax(dim=0)\n",
       "          (logsoft): LogSoftmax(dim=0)\n",
       "          (_W): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (_U): Linear(in_features=128, out_features=64, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (RS): ModuleList(\n",
       "        (0): SAFFULayer(\n",
       "          (activate): LogSoftmax(dim=0)\n",
       "          (logsoft): LogSoftmax(dim=0)\n",
       "          (_W): Linear(in_features=2, out_features=2, bias=False)\n",
       "          (_U): Linear(in_features=256, out_features=64, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (_W): FFULayer(\n",
       "        (activate): LogSoftmax(dim=0)\n",
       "        (_U): Linear(in_features=160, out_features=160, bias=False)\n",
       "      )\n",
       "      (_D): FFULayer(\n",
       "        (activate): LogSoftmax(dim=0)\n",
       "        (_U): Linear(in_features=128, out_features=32, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (_Uc): FFULayer(\n",
       "      (activate): LogSoftmax(dim=0)\n",
       "      (_U): Linear(in_features=160, out_features=6130, bias=False)\n",
       "    )\n",
       "    (_Ud): Linear(in_features=32, out_features=24521, bias=False)\n",
       "    (logsoft): LogSoftmax(dim=0)\n",
       "  )\n",
       "  (_drop): Dropout(p=0.0, inplace=False)\n",
       "  (_pred): Linear(in_features=320, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_model2 = TestRNN2(model).to(device)\n",
    "rnn_model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "e25c688d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single x_tok tensor from val_loader torch.Size([100, 100, 35])\n",
      "\n",
      "Tokens for first cell shaped torch.Size([35]):\n",
      "tensor([0, 0, 2, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# CUDA Vars to avoid randomization\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Create a DataLoader from your check_loader\n",
    "# test_loader = torch.utils.data.DataLoader(val_loader, batch_size=2, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(train_loader, batch_size=2, shuffle=False)\n",
    "\n",
    "# Get one batch from the DataLoader\n",
    "batch = next(iter(test_loader))\n",
    "\n",
    "# Extract single x_tok example from batch\n",
    "ex_input = batch['x_tok'][0]\n",
    "\n",
    "# Extract single cell's tokens\n",
    "cell_tokens = ex_input[0,0,:]\n",
    "#cell_tokens = cell_tokens.unsqueeze(0)\n",
    "\n",
    "# Observe shape and tensor\n",
    "print(f'Single x_tok tensor from val_loader {ex_input.shape}')\n",
    "print(f'\\nTokens for first cell shaped {cell_tokens.shape}:\\n{cell_tokens}')\n",
    "\n",
    "# # Pass the single tensor through SAFFU model\n",
    "# one_pass = model.forward(cell_tokens, cell_tokens.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "63ac1d34-1745-4737-804a-2fd1d1d12a49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 100, 100, 35]) cuda:1\n"
     ]
    }
   ],
   "source": [
    "print(batch['x_tok'].shape, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "794fce86-db87-4aa1-a8cd-e4a9d09ddace",
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 14.00 MiB. GPU 1 has a total capacity of 11.77 GiB of which 12.25 MiB is free. Process 1307884 has 1.54 GiB memory in use. Including non-PyTorch memory, this process has 10.21 GiB memory in use. Of the allocated memory 9.82 GiB is allocated by PyTorch, and 24.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[122], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrnn_model2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mx_tok\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/cephfs/code/transcription/torch_nightly/lib/python3.8/site-packages/torch/nn/modules/module.py:1519\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1517\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1518\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1519\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/cephfs/code/transcription/torch_nightly/lib/python3.8/site-packages/torch/nn/modules/module.py:1528\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1525\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1527\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1528\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1530\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1531\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[118], line 115\u001b[0m, in \u001b[0;36mTestRNN2.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    112\u001b[0m torch\u001b[38;5;241m.\u001b[39mmanual_seed(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;66;03m# Global hidden states containing info around current cell already on gpu\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m H_global \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcell_hs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# cells x hidden_dim\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;66;03m# Tensor to store the full macro cube of size batch x rows x cols\u001b[39;00m\n\u001b[1;32m    118\u001b[0m S_cube \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros((x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]), device\u001b[38;5;241m=\u001b[39mx\u001b[38;5;241m.\u001b[39mdevice)\n",
      "Cell \u001b[0;32mIn[118], line 51\u001b[0m, in \u001b[0;36mTestRNN2.cell_hs\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     47\u001b[0m         torch\u001b[38;5;241m.\u001b[39mmanual_seed(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     49\u001b[0m         \u001b[38;5;66;03m# Initialize H_local as a zero tensor with the appropriate shape (num_cells, hidden_dim)\u001b[39;00m\n\u001b[1;32m     50\u001b[0m         \u001b[38;5;66;03m# H_local = torch.zeros(x.shape[1] * x.shape[2], self.hidden_dim, device=x.device) # cells x hidden_dim\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m         H_local \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhidden_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# batch x cells x hidden_dim\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m#         # DEBUG PRINT\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m#         print(f'Input x: {x.shape}')\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m#         print(f'\\nH_local before {H_local.shape}:\\n{H_local}')\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \n\u001b[1;32m     57\u001b[0m         \u001b[38;5;66;03m# Iterate over each cell\u001b[39;00m\n\u001b[1;32m     58\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m cell \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]),desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGetting Cells\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     59\u001b[0m             \n\u001b[1;32m     60\u001b[0m             \u001b[38;5;66;03m# Get the current row and col\u001b[39;00m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 1 has a total capacity of 11.77 GiB of which 12.25 MiB is free. Process 1307884 has 1.54 GiB memory in use. Including non-PyTorch memory, this process has 10.21 GiB memory in use. Of the allocated memory 9.82 GiB is allocated by PyTorch, and 24.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "rnn_model2(batch['x_tok'].to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d0010476",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "forward() missing 4 required positional arguments: 'blocks', 'is_inference', 'bis', and 'ms'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Checking input with single cell tokens in encoder\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcell_tokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m output\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "\u001b[0;31mTypeError\u001b[0m: forward() missing 4 required positional arguments: 'blocks', 'is_inference', 'bis', and 'ms'"
     ]
    }
   ],
   "source": [
    "# Checking input with single cell tokens in encoder\n",
    "output = model.encoder(cell_tokens)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2276854",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033768ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3dcf98c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae6d14f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68e8a0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adbcd7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ad3b243",
   "metadata": {},
   "source": [
    "# Tuning\n",
    "\n",
    "## Setup params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db65cb2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total numbers of learnable/all parameters: 2670335/2703611\n"
     ]
    }
   ],
   "source": [
    "# Total params in the model so the number of elements for each param name all together\n",
    "total_params = 0\n",
    "\n",
    "# Total learnable params\n",
    "total_learnable = 0\n",
    "\n",
    "# Iterate through each macro param in model's params like Psi_b, _V.weight, RS.0._U.weight etc.   \n",
    "for name, param in model.named_parameters():\n",
    "    \n",
    "    # Current param count is product of tensor dims (log-exp avoids overflow -> one less than actual)\n",
    "    curr_params = int(np.exp(sum(np.log(param.shape))))\n",
    "    \n",
    "    # Add curr_params to learnable params if curr_param requires grad\n",
    "    total_learnable += curr_params if param.requires_grad else 0\n",
    "    \n",
    "    # Add curr_params to total_params\n",
    "    total_params += curr_params\n",
    "\n",
    "# Print the ratio of learnable to all params\n",
    "print(f\"Total numbers of learnable/all parameters: {total_learnable}/{total_params}\")\n",
    "\n",
    "# Set grad to false to freeze embedding layer since we are warm starting\n",
    "model.encoder._V.weight.requires_grad = False\n",
    "\n",
    "# Set seed for reproducibility\n",
    "seed = 691\n",
    "\n",
    "# Define whether warm starting or not\n",
    "warm_start = True\n",
    "\n",
    "# Determine if verbose output needed when running tuner.warm_start()\n",
    "verbose = True\n",
    "\n",
    "# Adds spaces with tokens if set to False else removes them if True\n",
    "ignore_space = False\n",
    "\n",
    "# Case sensitive if False and lowercases everything if True\n",
    "ignore_case = False\n",
    "\n",
    "# Used for initializating _V (embeddings) matrix during the warm start. Higher = Richer init repr for each token\n",
    "warm_vecs = 1*(2**0 + 0.99999) # = 2\n",
    "\n",
    "# Do-nothing transform, sets part embeddings to identity stabilizing over-aggressive/random init states\n",
    "identity_ratio = 2**(-1) # = 0.5\n",
    "\n",
    "# Inverse Context Freq: co-occurrence counts reweight words based on rarity/importance\n",
    "# Highlights contextually significant words leading to better differentiation if set to True\n",
    "icf = True \n",
    "\n",
    "# Indicates if token labels are log/linear. Log reduces impact of high freq elements, linear simpler \n",
    "log_label = False\n",
    "\n",
    "# Number of distinct clusters to assign to tokens during training\n",
    "nlabels = 1*(2**0) # = 1 = No subdivision cluster of toks\n",
    "\n",
    "# Should model consider centroids during clustering/quantization process\n",
    "centroids = False\n",
    "\n",
    "# Iterations to refine label assignments in training. Higher = Reclusturing more for each token getting more accurate groups\n",
    "label_iterations = 1*(2**10) # = 1024\n",
    "\n",
    "# Determine epochs and scale by factor of 1024 to account for smaller datasets\n",
    "epochs = int(np.max([int(downsample/5), 1]))*(2**10)\n",
    "\n",
    "# Determine if reloading or new\n",
    "reload = False\n",
    "\n",
    "# Determine patience to of observing no loss reduction\n",
    "patience = 2**1\n",
    "\n",
    "# Finally name the file used for warm start\n",
    "warm_file = \"\".join([data_file[:-5] + \"-\", \n",
    "                     f\"b_{tokenizer.config._bits}-hb_{tokenizer.config._hidden}-\",\n",
    "                     f\"we_{int(tokenizer.config._wave_encode)}-oa_{tokenizer.config._o_agg}-ra_{tokenizer.config._r_agg}-ba_{tokenizer.config._b_agg}-\",\n",
    "                     f\"mr_{int(tokenizer.config._mask_r)}-mb_{int(tokenizer.config._mask_b)}-md_{tokenizer.config._model_documents}-\",\n",
    "                     f\"is_{int(ignore_space)}-ic_{int(ignore_case)}-ws_{int(warm_start)}-wv_{int(warm_vecs)}-ds_{downsample}-seed_{seed}\"])\n",
    "\n",
    "# Define traning and dev directories\n",
    "train_dir = '../data/train/'; dev_dir = '../data/train_small'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "757fed1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting convos list:  26%|█████               | 159/623 [00:05<00:13, 33.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR ../data/train/randall_gay_000_1_1.pst.21.xls: Error tokenizing data. C error: Expected 1 fields in line 39, saw 3\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting convos list: 100%|████████████████████| 623/623 [00:25<00:00, 24.63it/s]\n",
      "Getting convos list: 100%|██████████████████████| 10/10 [00:01<00:00,  7.68it/s]\n"
     ]
    }
   ],
   "source": [
    "# Update the convos lists required for tuner\n",
    "convos = dir2convos(train_dir)\n",
    "dconvos = dir2convos(dev_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "841dba40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Cell', ''],\n",
       " ['Cell', 'TRANSWESTERN PIPELINE COMPANY'],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell',\n",
       "  'Rate calculation is based on the spread of two indices less variable charges (fuel/usage) less fixed rate or spread.  PG&E to provide index price calc.'],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', 'CAPACITY RELEASE REPORT'],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell',\n",
       "  'Settlement Based Max Reservation Rates and TCR Surcharges changed eff 11/1/00; GRD rate changed eff 1/1/01.'],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', 'DEALS ABOVE MAX TARIFF RATE'],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell',\n",
       "  '                                                                                                                                                                                                                                                               '],\n",
       " ['Cell', ''],\n",
       " ['Cell', 'RLSE'],\n",
       " ['Cell', ''],\n",
       " ['Cell', 'REPLACEMENT'],\n",
       " ['Cell', ''],\n",
       " ['Cell', 'REPLACEMENT'],\n",
       " ['Cell', ''],\n",
       " ['Cell', 'OFFER'],\n",
       " ['Cell', 'REPLACEMENT'],\n",
       " ['Cell', ''],\n",
       " ['Cell', 'REPLACEMENT'],\n",
       " ['Cell', '1-PART'],\n",
       " ['Cell', 'MINIMUM'],\n",
       " ['Cell', ''],\n",
       " ['Cell', 'CREDIT TO'],\n",
       " ['Cell', 'APPLICABLE'],\n",
       " ['Cell', 'VALUE OVER'],\n",
       " ['Cell', 'TERM'],\n",
       " ['Cell', 'TERM'],\n",
       " ['Cell', 'RE-'],\n",
       " ['Cell', 'PRE-'],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', 'Rate'],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', 'REL #'],\n",
       " ['Cell', 'RLSE SHIPPER'],\n",
       " ['Cell', 'CTRC#'],\n",
       " ['Cell', 'VOLUME'],\n",
       " ['Cell', 'RECEIPT POI'],\n",
       " ['Cell', ''],\n",
       " ['Cell', 'DELIVERY POI'],\n",
       " ['Cell', ''],\n",
       " ['Cell', 'RATE'],\n",
       " ['Cell', 'ENTITY'],\n",
       " ['Cell', 'CTRC#'],\n",
       " ['Cell', 'VOL'],\n",
       " ['Cell', '% VOL COM'],\n",
       " ['Cell', 'AWARD RATE*'],\n",
       " ['Cell', ''],\n",
       " ['Cell', 'RELEASER'],\n",
       " ['Cell', 'MAX RATE**'],\n",
       " ['Cell', 'MAX RATE'],\n",
       " ['Cell', 'START'],\n",
       " ['Cell', 'END'],\n",
       " ['Cell', 'CALL'],\n",
       " ['Cell', 'ARR'],\n",
       " ['Cell', 'STATUS'],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', 'Sched'],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', '3044'],\n",
       " ['Cell', 'southern california gas company'],\n",
       " ['Cell', '8255'],\n",
       " ['Cell', '3057'],\n",
       " ['Cell', '58646'],\n",
       " ['Cell', 'west texas pool'],\n",
       " ['Cell', '10487'],\n",
       " ['Cell', 'socal needles'],\n",
       " ['Cell', '0.4006'],\n",
       " ['Cell', 'enron energy services, inc.'],\n",
       " ['Cell', '27471'],\n",
       " ['Cell', '3057'],\n",
       " ['Cell', ''],\n",
       " ['Cell', '1.0015'],\n",
       " ['Cell', '28'],\n",
       " ['Cell', '85724.39'],\n",
       " ['Cell', '0.4006'],\n",
       " ['Cell', '51434.64'],\n",
       " ['Cell', '2001-02-01 00:00:00'],\n",
       " ['Cell', '2001-02-28 00:00:00'],\n",
       " ['Cell', 'N'],\n",
       " ['Cell', 'Y'],\n",
       " ['Cell', 'Awarded'],\n",
       " ['Cell', '0'],\n",
       " ['Cell', '250'],\n",
       " ['Cell', 'FTS-1'],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', '3042'],\n",
       " ['Cell', 'southern california gas company'],\n",
       " ['Cell', '8255'],\n",
       " ['Cell', '2004'],\n",
       " ['Cell', '58649'],\n",
       " ['Cell', 'central pool'],\n",
       " ['Cell', '10487'],\n",
       " ['Cell', 'socal needles'],\n",
       " ['Cell', '0.4006'],\n",
       " ['Cell', 'sempra energy solutions, llc'],\n",
       " ['Cell', '27486'],\n",
       " ['Cell', '2004'],\n",
       " ['Cell', ''],\n",
       " ['Cell', '0.7011'],\n",
       " ['Cell', '28'],\n",
       " ['Cell', '39340.12'],\n",
       " ['Cell', '0.4006'],\n",
       " ['Cell', '16861.66'],\n",
       " ['Cell', '2001-02-01 00:00:00'],\n",
       " ['Cell', '2001-02-28 00:00:00'],\n",
       " ['Cell', 'N'],\n",
       " ['Cell', 'Y'],\n",
       " ['Cell', 'Awarded'],\n",
       " ['Cell', '0'],\n",
       " ['Cell', '175'],\n",
       " ['Cell', 'FTS-1'],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ...]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convos[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96580e62",
   "metadata": {},
   "source": [
    "## Warm Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a14b8320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the tuner\n",
    "tuner = SAFFUTuner(ignore_case, ignore_space, devstr, warm_vecs, identity_ratio = identity_ratio,\n",
    "                   label_iterations = label_iterations, log_label = log_label, nlabels = nlabels,\n",
    "                   centroids = centroids, icf = icf)\n",
    "\n",
    "# Warm start with params\n",
    "tuner.warm_start(model, convos, dconvos, downsample*10, seed, epochs, \n",
    "                 patience, devsample = devsample, model_file = warm_file,\n",
    "                 reload = reload, verbose = verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e18eb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_params, total_learnable = 0, 0\n",
    "# for name, param in model.named_parameters():\n",
    "#     total_params += int(np.exp(sum(np.log(param.shape))))\n",
    "#     if param.requires_grad:\n",
    "#         total_learnable += int(np.exp(sum(np.log(param.shape)))) # param.shape[0]*param.shape[1]\n",
    "#         # print(name, param.shape[0]*param.shape[1])\n",
    "\n",
    "# print(f\"Total numbers of learnable/all parameters: {total_learnable}/{total_params}\")\n",
    "\n",
    "# model.encoder._V.weight.requires_grad = False\n",
    "\n",
    "# seed = 691; ignore_space = False; ignore_case = False; warm_start = True; verbose = True; \n",
    "# warm_vecs = 1*(2**0 + 0.99999); identity_ratio = 2**(-1); icf = True \n",
    "# log_label = False; nlabels = 1*(2**0); centroids = False; label_iterations = 1*(2**10) # None \n",
    "# epochs = int(np.max([int(downsample/5), 1]))*(2**5)\n",
    "# patience = 2**1\n",
    "# reload = False\n",
    "# warm_file = \"\".join([data_file[:-5] + \"-\", \n",
    "#                      f\"b_{tokenizer.config._bits}-hb_{tokenizer.config._hidden}-\",\n",
    "#                      f\"we_{int(tokenizer.config._wave_encode)}-oa_{tokenizer.config._o_agg}-ra_{tokenizer.config._r_agg}-ba_{tokenizer.config._b_agg}-\",\n",
    "#                      f\"mr_{int(tokenizer.config._mask_r)}-mb_{int(tokenizer.config._mask_b)}-md_{tokenizer.config._model_documents}-\",\n",
    "#                      f\"is_{int(ignore_space)}-ic_{int(ignore_case)}-ws_{int(warm_start)}-wv_{int(warm_vecs)}-ds_{downsample}-seed_{seed}\"])\n",
    "# tuner = SAFFUTuner(ignore_case, ignore_space, devstr, warm_vecs, identity_ratio = identity_ratio, \n",
    "#                    label_iterations = label_iterations, log_label = log_label, nlabels = nlabels, centroids = centroids, icf = icf)\n",
    "# tuner.warm_start(model, convos, dconvos, downsample*10, seed, epochs, patience, devsample = devsample, model_file = warm_file, reload = reload, verbose = verbose"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
