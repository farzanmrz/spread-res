{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc980c87",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "## Notebook formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90dd9021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "Jupyter.notebook.get_cells().map(function(c) {\n",
       "    if (c.cell_type === 'code') {\n",
       "        c.code_mirror.setOption('lineWrapping', true);\n",
       "    }\n",
       "});\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "Jupyter.notebook.get_cells().map(function(c) {\n",
    "    if (c.cell_type === 'code') {\n",
    "        c.code_mirror.setOption('lineWrapping', true);\n",
    "    }\n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5765f20",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "id": "1d28dae5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T21:04:34.291305Z",
     "start_time": "2025-01-03T21:04:25.302012Z"
    }
   },
   "source": [
    "# Import importlib to reload modules and sys and os to add the path for other imports\n",
    "import importlib\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Append the parent directory to the path to import the necessary modules\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "# Import the utilities and the dataloader\n",
    "from utils import selfutil, saffuutil\n",
    "from classes import TestRNN\n",
    "\n",
    "# Now reload the modules to ensure they are up-to-date\n",
    "importlib.reload(selfutil)\n",
    "importlib.reload(saffuutil)\n",
    "importlib.reload(TestRNN)\n",
    "\n",
    "# Import the funcs needed from utils\n",
    "from utils.saffuutil import load_saffutok, dir2convos, get_saffuloader\n",
    "\n",
    "# Import the SAFFUDataLoader class\n",
    "from classes.TestRNN import TestRNN\n",
    "\n",
    "# Other regular imports\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import os\n",
    "import pandas as pd\n",
    "import math\n",
    "import time"
   ],
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'saffuutil' from 'utils' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 10\u001B[0m\n\u001B[1;32m      7\u001B[0m sys\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mappend(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mabspath(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(os\u001B[38;5;241m.\u001B[39mgetcwd(), \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m..\u001B[39m\u001B[38;5;124m'\u001B[39m)))\n\u001B[1;32m      9\u001B[0m \u001B[38;5;66;03m# Import the utilities and the dataloader\u001B[39;00m\n\u001B[0;32m---> 10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m selfutil, saffuutil\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mclasses\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m TestRNN\n\u001B[1;32m     13\u001B[0m \u001B[38;5;66;03m# Now reload the modules to ensure they are up-to-date\u001B[39;00m\n",
      "\u001B[0;31mImportError\u001B[0m: cannot import name 'saffuutil' from 'utils' (unknown location)"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "b2082ec2",
   "metadata": {},
   "source": [
    "# Tokenizer \n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c15b3a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "# Read and execute saffu files for using functionality\n",
    "exec(open(\"../saffu/configuration_saffu.py\").read())\n",
    "exec(open(\"../saffu/tokenization_saffu.py\").read())\n",
    "exec(open(\"../saffu/utilities_saffu.py\").read())\n",
    "exec(open(\"../saffu/data_saffu.py\").read())\n",
    "exec(open(\"../saffu/modeling_saffu.py\").read())\n",
    "exec(open(\"../saffu/training_saffu.py\").read())\n",
    "exec(open(\"../saffu/inference_saffu.py\").read())\n",
    "exec(open(\"../saffu/tuning_saffu.py\").read())\n",
    "exec(open(\"../saffu/load_data.py\").read())\n",
    "\n",
    "## Set environment variables\n",
    "# Creates logger object named __main__ for debug messages\n",
    "logger = logging.get_logger(__name__)\n",
    "\n",
    "# Doesn't split memory chunks of more than 256 MB\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:256\"\n",
    "\n",
    "# Makes code synchronous meaning GPU finishes running then CPU rund\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "# Enable dynamic shape allocation of tensor sizes without predefining them\n",
    "os.environ['TORCH_USE_CUDA_DSA'] = \"1\"\n",
    "\n",
    "# Set the gpu or cpu device\n",
    "devstr = \"cuda:1\" # \"cpu\" \n",
    "gpu = False if (devstr == 'cpu') else True\n",
    "device = 'cpu' if (devstr == 'cpu') else (torch.device(devstr if torch.cuda.is_available() else 'cpu') \n",
    "                                          if devstr else torch.cuda.current_device())\n",
    "# Observe the device\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6863665",
   "metadata": {},
   "source": [
    "## Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b644ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer: train-tiny\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the dataset being used, can also combine different ones with a +\n",
    "data_set = \"train\" # +harmless-base+babylm_10M+babylm_100M+BWB\n",
    "\n",
    "# Define model size from tiny, micro, small, medium, big\n",
    "model_size = \"tiny\"\n",
    "\n",
    "# Size of different datasets in millions of word tokens\n",
    "training_sizes = {\"helpful-base\": 5, \"harmless-base\": 5, \"babylm_10M\": 10, \"babylm_100M\": 100, \"BWB\": 1000,\n",
    "                 \"train\":2.1877} \n",
    "\n",
    "# Define the % of data held out for development so 1/10 of total available below\n",
    "devsample = 10 \n",
    "\n",
    "# Total size of all datasets in millions, currently 2.1877 million should be\n",
    "dataset_size =  sum([training_sizes[data_subset] for data_subset in data_set.split(\"+\")])\n",
    "\n",
    "# Get downsample size which would be 1 = 1 million below\n",
    "downsample = max(int(dataset_size / 5), 1) # roughly 5 million word-tokens per split\n",
    "\n",
    "# Hyperparameter for learning rate probably\n",
    "eta = 0.05 # 0.05\n",
    "\n",
    "# Empty lists to store document or conversation level data for normal, dev and test\n",
    "docs, ddocs, tdocs = [], [], []\n",
    "convos, dconvos, tconvos = [], [], []\n",
    "\n",
    "# Get the configuration params for current model medium\n",
    "config = get_config(model_size = model_size)\n",
    "\n",
    "# Name the current tokenizer combo of dataset+model names\n",
    "tokenizer_name = f\"{data_set}-{model_size}\" # helpful-base-medium\n",
    "\n",
    "# Create the tokenizer object inherited from HF PreTrainedTokenizer class therefore init params not in custom\n",
    "tokenizer = SAFFUTokenizer(config)\n",
    "\n",
    "# Determine the directory where you wanna retreive tokenizer from\n",
    "tokenizer_directory = \"./cache/\"\n",
    "\n",
    "# Determine the directory where you wanna store tokenizer\n",
    "save_directory = './cache/'\n",
    "\n",
    "# Form the vocab file with a of directory, model path in tokenization_saffu.py, and name if given\n",
    "vocab_file = os.path.join(tokenizer_directory, tokenizer._model_path,\n",
    "                          (tokenizer_name + \"-\" if tokenizer_name else \"\") + \"vocab.json\")\n",
    "\n",
    "# True if retraining the tokenizer, False to load an existing one available\n",
    "reload = False\n",
    "\n",
    "# Now call load func to setup tokenizer\n",
    "load_saffutok(reload, vocab_file, tokenizer, tokenizer_name, tokenizer_directory, train_dir = '../data/train/')\n",
    "\n",
    "#tokenizer.augment_vocabulary([\"Cell\"])\n",
    "\n",
    "# Name the data_file path\n",
    "data_file = os.path.join(tokenizer_directory, tokenizer._model_path,\n",
    "                         (tokenizer_name + \"-\" if tokenizer_name else \"\") + \n",
    "                         f\"data-space_{tokenizer.config._space}-r_{tokenizer.config._r}-b_{tokenizer.config._b}-heads_{tokenizer.config._heads}-N_{tokenizer.config._N}.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eccec9d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size for experiment:  6130\n"
     ]
    }
   ],
   "source": [
    "# Print new vocab size for this experiment after BPE\n",
    "print(\"Vocabulary size for experiment: \", len(tokenizer._vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d4badc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Th', 'ese', ' cas', 'ser', 'ol', 'es', ' dis', 'gu', 'st', ' K', 'ay', 'la', '.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'\\n': 424,\n",
       " '\\n ': 5080,\n",
       " ' ': 19,\n",
       " ' \\n': 2231,\n",
       " '  ': 91,\n",
       " '  \\n': 751,\n",
       " '   ': 279,\n",
       " '    ': 657,\n",
       " '     ': 208,\n",
       " '      ': 1560,\n",
       " '       ': 1151,\n",
       " '        ': 216,\n",
       " '         ': 1359,\n",
       " '          ': 247,\n",
       " '           ': 2062,\n",
       " '            ': 3727,\n",
       " '             ': 3272,\n",
       " '              ': 3340,\n",
       " '               ': 3843,\n",
       " '                ': 3509,\n",
       " '                 ': 482,\n",
       " '                  ': 236,\n",
       " '                   ': 3066,\n",
       " '                    ': 809,\n",
       " '                     ': 4249,\n",
       " '                      ': 2921,\n",
       " '                       ': 3750,\n",
       " '                        ': 5279,\n",
       " '                          ': 4697,\n",
       " '                           ': 3882,\n",
       " '                            ': 3029,\n",
       " '                             ': 4171,\n",
       " '                              ': 5482,\n",
       " '                               ': 2715,\n",
       " '                                ': 4170,\n",
       " '                                 ': 3064,\n",
       " '                                     ': 6034,\n",
       " '                                            ': 2197,\n",
       " '                                                     ': 5720,\n",
       " '                                                       ': 5717,\n",
       " '                                                                     ': 5697,\n",
       " '                                                                                                                                                                                                                                                               ': 3709,\n",
       " '  \"': 4976,\n",
       " '  #1': 6118,\n",
       " '  #2': 6117,\n",
       " '  $': 5686,\n",
       " '  $2': 5757,\n",
       " '  $5': 5076,\n",
       " '  $7': 5708,\n",
       " '  &': 4958,\n",
       " '  & ': 5484,\n",
       " '  (': 982,\n",
       " '  ($': 3530,\n",
       " '  *': 4065,\n",
       " '  +': 3676,\n",
       " '  ,': 4860,\n",
       " '  .': 5541,\n",
       " '  /': 4869,\n",
       " '  / ': 5480,\n",
       " '  0': 3424,\n",
       " '  01': 5914,\n",
       " '  01/': 5088,\n",
       " '  07': 5472,\n",
       " '  1': 3338,\n",
       " '  1/': 3279,\n",
       " '  10': 3725,\n",
       " '  10/': 4179,\n",
       " '  100': 5500,\n",
       " '  101': 5434,\n",
       " '  102': 5999,\n",
       " '  103': 5062,\n",
       " '  104': 4342,\n",
       " '  107': 4346,\n",
       " '  108': 4827,\n",
       " '  109': 5206,\n",
       " '  11': 4794,\n",
       " '  1100': 4232,\n",
       " '  111': 4766,\n",
       " '  112': 4538,\n",
       " '  113': 4371,\n",
       " '  114': 4657,\n",
       " '  115': 5288,\n",
       " '  117': 4394,\n",
       " '  118': 4817,\n",
       " '  12': 3032,\n",
       " '  12/': 2627,\n",
       " '  121': 4815,\n",
       " '  122': 5435,\n",
       " '  125': 5443,\n",
       " '  126': 5433,\n",
       " '  127': 5995,\n",
       " '  129': 4972,\n",
       " '  13': 3907,\n",
       " '  135': 5362,\n",
       " '  136': 5121,\n",
       " '  139': 4348,\n",
       " '  14': 4449,\n",
       " '  141': 5430,\n",
       " '  144': 4746,\n",
       " '  149': 3118,\n",
       " '  1497': 4879,\n",
       " '  15': 3119,\n",
       " '  150': 5449,\n",
       " '  151': 4816,\n",
       " '  1512': 2622,\n",
       " '  152': 4539,\n",
       " '  153': 4637,\n",
       " '  154': 4880,\n",
       " '  157': 6002,\n",
       " '  159': 6005,\n",
       " '  16': 4537,\n",
       " '  160': 4563,\n",
       " '  1603': 3151,\n",
       " '  164': 4121,\n",
       " '  165': 6000,\n",
       " '  166': 3897,\n",
       " '  168': 4728,\n",
       " '  17': 2142,\n",
       " '  171': 1822,\n",
       " '  175': 4206,\n",
       " '  176': 4370,\n",
       " '  178': 4768,\n",
       " '  18': 4425,\n",
       " '  1800': 5117,\n",
       " '  184': 4770,\n",
       " '  187': 6009,\n",
       " '  19': 4364,\n",
       " '  192': 5438,\n",
       " '  193': 4769,\n",
       " '  194': 4639,\n",
       " '  196': 4923,\n",
       " '  199': 5276,\n",
       " '  2': 3407,\n",
       " '  2\"': 5368,\n",
       " '  2/': 3494,\n",
       " '  20': 5294,\n",
       " '  200': 4439,\n",
       " '  206': 4767,\n",
       " '  21': 4405,\n",
       " '  210': 5442,\n",
       " '  213': 4806,\n",
       " '  216': 4729,\n",
       " '  22': 5361,\n",
       " '  222': 4643,\n",
       " '  223': 4832,\n",
       " '  23': 4831,\n",
       " '  234': 4995,\n",
       " '  237': 5503,\n",
       " '  239': 5178,\n",
       " '  24': 4139,\n",
       " '  245': 4771,\n",
       " '  25': 4250,\n",
       " '  250': 4667,\n",
       " '  261': 5992,\n",
       " '  262': 4802,\n",
       " '  263': 4823,\n",
       " '  27': 3799,\n",
       " '  273': 5432,\n",
       " '  28': 4274,\n",
       " '  288': 4772,\n",
       " '  289': 5240,\n",
       " '  29': 5018,\n",
       " '  290': 4749,\n",
       " '  292': 3884,\n",
       " '  293': 5250,\n",
       " '  3': 3566,\n",
       " '  3/': 3534,\n",
       " '  30': 5514,\n",
       " '  308': 5246,\n",
       " '  312': 4421,\n",
       " '  316': 5322,\n",
       " '  32': 4612,\n",
       " '  320': 5063,\n",
       " '  326': 6001,\n",
       " '  327': 4826,\n",
       " '  328': 6012,\n",
       " '  34': 5236,\n",
       " '  346': 5237,\n",
       " '  35': 4611,\n",
       " '  36': 5119,\n",
       " '  3600': 4724,\n",
       " '  364': 5120,\n",
       " '  37': 4138,\n",
       " '  372': 5179,\n",
       " '  376': 4515,\n",
       " '  38': 5293,\n",
       " '  380': 4803,\n",
       " '  388': 5990,\n",
       " '  39': 4270,\n",
       " '  394': 4480,\n",
       " '  4': 4049,\n",
       " '  4\"': 4556,\n",
       " '  4/': 3838,\n",
       " '  4/30': 2628,\n",
       " '  400': 4819,\n",
       " '  402': 6120,\n",
       " '  403': 6121,\n",
       " '  409': 4829,\n",
       " '  414': 4387,\n",
       " '  42': 5249,\n",
       " '  424': 4918,\n",
       " '  427': 5429,\n",
       " '  43': 5436,\n",
       " '  45': 4996,\n",
       " '  454': 4590,\n",
       " '  458': 4198,\n",
       " '  47': 4610,\n",
       " '  48': 5360,\n",
       " '  482': 5506,\n",
       " '  49': 3994,\n",
       " '  4920': 4478,\n",
       " '  495': 5287,\n",
       " '  5': 3999,\n",
       " '  5/': 2417,\n",
       " '  50': 5023,\n",
       " '  502': 5938,\n",
       " '  51': 4327,\n",
       " '  52': 4789,\n",
       " '  53': 5448,\n",
       " '  54': 4367,\n",
       " '  547': 4804,\n",
       " '  55': 5116,\n",
       " '  56': 4205,\n",
       " '  58': 3214,\n",
       " '  588': 4062,\n",
       " '  59': 4268,\n",
       " '  6': 5385,\n",
       " '  6\"': 5168,\n",
       " '  6/': 3677,\n",
       " '  60': 5444,\n",
       " '  600': 5705,\n",
       " '  602': 4164,\n",
       " '  61': 4644,\n",
       " '  612': 3957,\n",
       " '  62': 5239,\n",
       " '  629': 5290,\n",
       " '  633': 5224,\n",
       " '  64': 4714,\n",
       " '  641': 5251,\n",
       " '  646': 5475,\n",
       " '  65': 4546,\n",
       " '  654': 5974,\n",
       " '  66': 4277,\n",
       " '  67': 5445,\n",
       " '  68': 4144,\n",
       " '  69': 5497,\n",
       " '  696': 5498,\n",
       " '  7': 5387,\n",
       " '  7/': 3993,\n",
       " '  7/1': 2629,\n",
       " '  70': 5038,\n",
       " '  71': 6007,\n",
       " '  717': 4824,\n",
       " '  72': 4788,\n",
       " '  73': 4562,\n",
       " '  74': 5027,\n",
       " '  75': 5323,\n",
       " '  750': 5679,\n",
       " '  7500': 5991,\n",
       " '  76': 4665,\n",
       " '  77': 5790,\n",
       " '  78': 4809,\n",
       " '  788': 5509,\n",
       " '  789': 4924,\n",
       " '  79': 3989,\n",
       " '  8': 2579,\n",
       " '  8/': 3337,\n",
       " '  8/1': 3174,\n",
       " '  80': 4374,\n",
       " '  809': 5248,\n",
       " '  81': 4564,\n",
       " '  817': 4985,\n",
       " '  82': 4662,\n",
       " '  84': 4373,\n",
       " '  85': 5993,\n",
       " '  86': 5501,\n",
       " '  865': 6006,\n",
       " '  878': 4925,\n",
       " '  89': 4666,\n",
       " '  9': 3529,\n",
       " '  9/': 3564,\n",
       " '  90': 4090,\n",
       " '  93': 4775,\n",
       " '  937': 5238,\n",
       " '  94': 5181,\n",
       " '  95': 4345,\n",
       " '  96': 4134,\n",
       " '  97': 3167,\n",
       " '  98': 5289,\n",
       " '  986': 4591,\n",
       " '  :': 4681,\n",
       " '  <': 133,\n",
       " '  </': 1012,\n",
       " '  =': 4636,\n",
       " '  _': 5273,\n",
       " '  ____': 3940,\n",
       " ' !': 5964,\n",
       " ' \"': 3260,\n",
       " ' #': 2139,\n",
       " ' # ': 4928,\n",
       " ' #,': 6024,\n",
       " ' #1': 3638,\n",
       " ' #2': 3577,\n",
       " ' #3': 3141,\n",
       " ' #4': 3310,\n",
       " ' #5': 4112,\n",
       " ' #6': 4316,\n",
       " ' #6 ': 4871,\n",
       " ' #7': 5043,\n",
       " ' #8': 5464,\n",
       " ' #:': 4431,\n",
       " ' $': 2904,\n",
       " ' $,': 3771,\n",
       " ' $.': 5780,\n",
       " ' $/': 4284,\n",
       " ' $0': 4041,\n",
       " ' $1': 3648,\n",
       " ' $2': 4368,\n",
       " ' $3': 4276,\n",
       " ' $4': 6016,\n",
       " ' $5': 3757,\n",
       " ' $6': 5399,\n",
       " ' $7': 4939,\n",
       " ' $8': 5451,\n",
       " ' %': 4059,\n",
       " ' &': 263,\n",
       " ' & ': 4870,\n",
       " ' &1': 6115,\n",
       " ' &5': 4875,\n",
       " \" '\": 3571,\n",
       " \" 'N\": 4717,\n",
       " ' (': 191,\n",
       " ' (\"': 4013,\n",
       " ' ($': 3244,\n",
       " ' (+': 4161,\n",
       " ' )': 4220,\n",
       " ' *': 4002,\n",
       " ' * ': 4103,\n",
       " ' **': 4283,\n",
       " ' +': 3977,\n",
       " ' ,': 3514,\n",
       " ' -': 232,\n",
       " ' - ': 3461,\n",
       " ' --': 4004,\n",
       " ' -B': 4166,\n",
       " ' -C': 3744,\n",
       " ' -E': 3761,\n",
       " ' -F': 3588,\n",
       " ' -G': 3745,\n",
       " ' -M': 4115,\n",
       " ' -N': 4023,\n",
       " ' -O': 5300,\n",
       " ' -St': 4167,\n",
       " ' -U': 4022,\n",
       " ' .': 4099,\n",
       " ' .\"': 5529,\n",
       " ' ..': 4169,\n",
       " ' /': 2113,\n",
       " ' / ': 5481,\n",
       " ' 0': 2170,\n",
       " ' 0 ': 359,\n",
       " ' 00': 16,\n",
       " ' 009': 5784,\n",
       " ' 00:': 4518,\n",
       " ' 01': 1127,\n",
       " ' 01/': 3693,\n",
       " ' 0100': 5453,\n",
       " ' 01:': 1030,\n",
       " ' 01:0': 2206,\n",
       " ' 02': 570,\n",
       " ' 02/': 4867,\n",
       " ' 02:': 3258,\n",
       " ' 03': 523,\n",
       " ' 03/': 5056,\n",
       " ' 038': 5113,\n",
       " ' 039': 5114,\n",
       " ' 03:': 3443,\n",
       " ' 04': 1458,\n",
       " ' 04/': 5226,\n",
       " ' 042': 5557,\n",
       " ' 044': 5558,\n",
       " ' 04:': 3565,\n",
       " ' 05': 1442,\n",
       " ' 05/': 4252,\n",
       " ' 05:': 3495,\n",
       " ' 06': 1431,\n",
       " ' 06/': 3901,\n",
       " ' 069': 5559,\n",
       " ' 06:': 3254,\n",
       " ' 07': 993,\n",
       " ' 07/': 3578,\n",
       " ' 071': 5560,\n",
       " ' 072': 4658,\n",
       " ' 07:': 2583,\n",
       " ' 08': 331,\n",
       " ' 08/': 3559,\n",
       " ' 08:': 1358,\n",
       " ' 09': 722,\n",
       " ' 09/': 4219,\n",
       " ' 098': 5040,\n",
       " ' 09:': 752,\n",
       " ' 1': 389,\n",
       " ' 1\"': 5057,\n",
       " ' 1&': 5138,\n",
       " ' 1/': 2488,\n",
       " ' 10': 1036,\n",
       " ' 10/': 3116,\n",
       " ' 100': 4360,\n",
       " ' 101': 3153,\n",
       " ' 102': 5141,\n",
       " ' 103': 5263,\n",
       " ' 104': 5726,\n",
       " ' 107': 5740,\n",
       " ' 10:': 2433,\n",
       " ' 11': 781,\n",
       " ' 11/': 2725,\n",
       " ' 1100': 3568,\n",
       " ' 113': 6093,\n",
       " ' 119 ': 5492,\n",
       " ' 11:': 3182,\n",
       " ' 12': 724,\n",
       " ' 12/': 2853,\n",
       " ' 120': 4649,\n",
       " ' 1200': 4686,\n",
       " ' 123': 5944,\n",
       " ' 125': 5320,\n",
       " ' 127': 5513,\n",
       " ' 129': 5912,\n",
       " ' 12:': 2109,\n",
       " ' 13': 822,\n",
       " ' 13:': 4632,\n",
       " ' 14': 864,\n",
       " ' 141': 4054,\n",
       " ' 143': 3152,\n",
       " ' 147': 5727,\n",
       " ' 149': 3154,\n",
       " ' 14:': 4028,\n",
       " ' 15': 944,\n",
       " ' 150': 4865,\n",
       " ' 1500': 4597,\n",
       " ' 151': 3919,\n",
       " ' 152': 5370,\n",
       " ' 157': 4966,\n",
       " ' 16': 308,\n",
       " ' 160': 4629,\n",
       " ' 1603': 3155,\n",
       " ' 162': 5371,\n",
       " ' 163': 6095,\n",
       " ' 165': 4447,\n",
       " ' 167': 4577,\n",
       " ' 168': 4391,\n",
       " ' 16:': 5264,\n",
       " ' 17': 884,\n",
       " ' 170': 5372,\n",
       " ' 171': 2630,\n",
       " ' 17:': 5396,\n",
       " ' 18': 938,\n",
       " ' 187': 6089,\n",
       " ' 188': 5984,\n",
       " ' 18:': 5364,\n",
       " ' 19': 1069,\n",
       " ' 190': 4535,\n",
       " ' 1900': 6028,\n",
       " ' 193': 5742,\n",
       " ' 199': 2011,\n",
       " ' 1:': 5283,\n",
       " ' 2': 519,\n",
       " ' 2\"': 4720,\n",
       " ' 2/': 3864,\n",
       " ' 20': 2103,\n",
       " ' 200': 575,\n",
       " ' 202': 5712,\n",
       " ' 204': 5743,\n",
       " ' 205': 5257,\n",
       " ' 206': 5744,\n",
       " ' 20:': 5266,\n",
       " ' 21': 1070,\n",
       " ' 210': 5752,\n",
       " ' 211': 5745,\n",
       " ' 212': 5746,\n",
       " ' 213': 5688,\n",
       " ' 217': 2878,\n",
       " ' 219': 5452,\n",
       " ' 22': 1078,\n",
       " ' 220': 6129,\n",
       " ' 227': 5748,\n",
       " ' 23': 931,\n",
       " ' 231': 5713,\n",
       " ' 237': 4889,\n",
       " ' 238': 5714,\n",
       " ' 239': 5386,\n",
       " ' 23:': 4280,\n",
       " ' 24': 3386,\n",
       " ' 241': 5715,\n",
       " ' 25': 3034,\n",
       " ' 250': 4203,\n",
       " ' 2500': 5735,\n",
       " ' 26': 3562,\n",
       " ' 260': 4953,\n",
       " ' 27': 3767,\n",
       " ' 271': 5563,\n",
       " ' 274': 4909,\n",
       " ' 28': 3870,\n",
       " ' 280': 5367,\n",
       " ' 286': 5689,\n",
       " ' 29': 4137,\n",
       " ' 290': 5691,\n",
       " ' 293': 5693,\n",
       " ' 2:': 5285,\n",
       " ' 3': 728,\n",
       " ' 3 ': 5962,\n",
       " ' 3\"': 4954,\n",
       " ' 3%': 5139,\n",
       " ' 3&': 3742,\n",
       " ' 3+': 5516,\n",
       " ' 3/': 3542,\n",
       " ' 30': 2817,\n",
       " ' 300': 3905,\n",
       " ' 301': 5107,\n",
       " ' 303': 5695,\n",
       " ' 305': 6035,\n",
       " ' 306': 5165,\n",
       " ' 31': 2834,\n",
       " ' 3100': 5772,\n",
       " ' 311': 5657,\n",
       " ' 312': 6026,\n",
       " ' 313': 6040,\n",
       " ' 314': 6021,\n",
       " ' 32': 6092,\n",
       " ' 320': 5769,\n",
       " ' 321': 5696,\n",
       " ' 324': 5271,\n",
       " ' 327': 5180,\n",
       " ' 33': 4464,\n",
       " ' 330': 4926,\n",
       " ' 3300': 4162,\n",
       " ' 34': 5024,\n",
       " ' 340': 5719,\n",
       " ' 35': 2016,\n",
       " ' 350': 5543,\n",
       " ' 355': 5463,\n",
       " ' 36': 3130,\n",
       " ' 361': 5268,\n",
       " ' 364 ': 5493,\n",
       " ' 37': 3684,\n",
       " ' 371': 5505,\n",
       " ' 374': 5939,\n",
       " ' 375': 6099,\n",
       " ' 38': 5021,\n",
       " ' 389': 6102,\n",
       " ' 394': 5170,\n",
       " ' 398': 5047,\n",
       " ' 4': 1174,\n",
       " ' 4 ': 5924,\n",
       " ' 4\"': 4325,\n",
       " ' 4/': 3641,\n",
       " ' 4/30': 5392,\n",
       " ' 40': 2768,\n",
       " ' 400': 4410,\n",
       " ' 401': 3696,\n",
       " ' 402': 4108,\n",
       " ' 403': 4109,\n",
       " ' 406': 6054,\n",
       " ' 408': 5698,\n",
       " ' 41': 5192,\n",
       " ' 415': 6106,\n",
       " ' 417': 6023,\n",
       " ' 42': 4398,\n",
       " ' 420': 5042,\n",
       " ' 423': 5259,\n",
       " ' 43': 3670,\n",
       " ' 43 ': 5470,\n",
       " ' 44': 5711,\n",
       " ' 445': 5699,\n",
       " ' 448': 5511,\n",
       " ' 45': 4848,\n",
       " ' 450': 4404,\n",
       " ' 468': 5722,\n",
       " ' 47': 5383,\n",
       " ' 472': 5701,\n",
       " ' 480': 5166,\n",
       " ' 49': 5942,\n",
       " ' 490': 4981,\n",
       " ' 4:': 5537,\n",
       " ' 5': 1416,\n",
       " ' 5%': 5819,\n",
       " ' 5/': 3706,\n",
       " ' 50': 2052,\n",
       " ' 500': 3552,\n",
       " ' 502': 4600,\n",
       " ' 504': 6032,\n",
       " ' 507': 5702,\n",
       " ' 510': 5703,\n",
       " ' 513': 6025,\n",
       " ' 517': 5255,\n",
       " ' 523': 5975,\n",
       " ' 525': 5369,\n",
       " ' 527': 5457,\n",
       " ' 532': 5115,\n",
       " ' 533': 6087,\n",
       " ' 535': 5736,\n",
       " ' 54': 4437,\n",
       " ' 546': 5791,\n",
       " ' 548': 4956,\n",
       " ' 55': 2537,\n",
       " ' 550': 4299,\n",
       " ' 554': 5379,\n",
       " ' 56': 5994,\n",
       " ' 563': 5172,\n",
       " ' 565': 5937,\n",
       " ' 57': 5817,\n",
       " ' 571': 5291,\n",
       " ' 573': 5461,\n",
       " ' 579': 5460,\n",
       " ' 58': 5728,\n",
       " ' 59': 4463,\n",
       " ' 59 ': 5490,\n",
       " ' 596': 5064,\n",
       " ' 6': 1578,\n",
       " ' 6\"': 4024,\n",
       " ' 6\" ': 5169,\n",
       " ' 6/': 4081,\n",
       " ' 60': 2129,\n",
       " ' 600': 4904,\n",
       " ' 601': 5512,\n",
       " ' 602': 5467,\n",
       " ' 605': 5852,\n",
       " ' 606': 5191,\n",
       " ' 608': 4957,\n",
       " ' 61': 5829,\n",
       " ' 6100': 6098,\n",
       " ' 614': 5253,\n",
       " ' 621': 5382,\n",
       " ' 63': 4853,\n",
       " ' 632': 5729,\n",
       " ' 637': 5455,\n",
       " ' 640': 4540,\n",
       " ' 646': 5282,\n",
       " ' 65': 5211,\n",
       " ' 650': 5739,\n",
       " ' 6500': 6104,\n",
       " ' 651': 5504,\n",
       " ' 652': 5182,\n",
       " ' 668': 5731,\n",
       " ' 67': 5213,\n",
       " ' 671': 4524,\n",
       " ' 672': 5540,\n",
       " ' 685': 5732,\n",
       " ' 69': 5741,\n",
       " ' 693': 5173,\n",
       " ' 6:': 5106,\n",
       " ' 7': 1445,\n",
       " ' 7/': 4456,\n",
       " ' 70': 2873,\n",
       " ' 700': 4906,\n",
       " ' 704': 6029,\n",
       " ' 705': 5733,\n",
       " ' 71': 5738,\n",
       " ' 710': 5734,\n",
       " ' 713': 5730,\n",
       " ' 719': 5749,\n",
       " ' 720': 5770,\n",
       " ' 721': 5439,\n",
       " ' 723': 5188,\n",
       " ' 728': 5750,\n",
       " ' 73': 4930,\n",
       " ' 734': 6039,\n",
       " ' 74': 5707,\n",
       " ' 742': 5751,\n",
       " ' 75': 2708,\n",
       " ' 750': 5292,\n",
       " ' 755': 5207,\n",
       " ' 759': 6097,\n",
       " ' 76': 2892,\n",
       " ' 762': 6111,\n",
       " ' 767': 5456,\n",
       " ' 768': 5753,\n",
       " ' 77': 4627,\n",
       " ' 774': 5754,\n",
       " ' 775': 6101,\n",
       " ' 778': 4859,\n",
       " ' 78': 4917,\n",
       " ' 781': 5756,\n",
       " ' 785': 5388,\n",
       " ' 786': 2864,\n",
       " ' 787': 5758,\n",
       " ' 79': 5709,\n",
       " ' 7: ': 5775,\n",
       " ' 8': 1981,\n",
       " ' 8 ': 4579,\n",
       " ' 8\"': 3817,\n",
       " ' 8/': 3068,\n",
       " ' 80': 2739,\n",
       " ' 800': 5384,\n",
       " ' 801': 5759,\n",
       " ' 803': 5256,\n",
       " ' 804': 5260,\n",
       " ' 807': 5760,\n",
       " ' 809': 4737,\n",
       " ' 812': 6051,\n",
       " ' 813': 5258,\n",
       " ' 821': 5761,\n",
       " ' 83': 5298,\n",
       " ' 838': 5762,\n",
       " ' 840': 5389,\n",
       " ' 843': 6048,\n",
       " ' 844': 5763,\n",
       " ' 847': 5710,\n",
       " ' 85': 2781,\n",
       " ' 850': 4990,\n",
       " ' 853': 5485,\n",
       " ' 855': 5764,\n",
       " ' 858': 5923,\n",
       " ' 859': 6030,\n",
       " ' 866': 5765,\n",
       " ' 868': 5766,\n",
       " ' 87': 2874,\n",
       " ' 875': 5135,\n",
       " ' 877': 5767,\n",
       " ' 88': 2888,\n",
       " ' 89': 3945,\n",
       " ' 89 ': 5491,\n",
       " ' 893': 4892,\n",
       " ' 8:': 4618,\n",
       " ' 9': 2300,\n",
       " ' 9 ': 5041,\n",
       " ' 9/': 4323,\n",
       " ' 90': 2803,\n",
       " ' 900': 5049,\n",
       " ' 902': 5458,\n",
       " ' 903': 6090,\n",
       " ' 907': 5768,\n",
       " ' 910': 5771,\n",
       " ' 919': 5254,\n",
       " ' 93': 5935,\n",
       " ' 933': 5561,\n",
       " ' 935': 5562,\n",
       " ' 937': 6027,\n",
       " ' 944': 5161,\n",
       " ' 95': 4319,\n",
       " ' 9500': 4462,\n",
       " ' 96': 4390,\n",
       " ' 961': 5462,\n",
       " ' 963': 4465,\n",
       " ' 97': 4513,\n",
       " ' 98': 4514,\n",
       " ' 985': 2887,\n",
       " ' 986': 6103,\n",
       " ' 989': 5459,\n",
       " ' 99': 3831,\n",
       " ' 9:': 5144,\n",
       " ' :': 3264,\n",
       " ' : ': 4168,\n",
       " ' ;': 4935,\n",
       " ' <': 3718,\n",
       " ' </': 187,\n",
       " ' =': 2664,\n",
       " ' = ': 5489,\n",
       " ' =1': 4243,\n",
       " ' =2': 4942,\n",
       " ' >': 3834,\n",
       " ' >$': 4335,\n",
       " ' ><': 5643,\n",
       " ' ??': 5375,\n",
       " ' @': 3497,\n",
       " ' A': 706,\n",
       " ' A ': 5920,\n",
       " ' A-': 4694,\n",
       " ' AA': 5621,\n",
       " ' AB': 3689,\n",
       " ' AD': 3247,\n",
       " ' AE': 4521,\n",
       " ' AF': 2617,\n",
       " ' AFT': 5153,\n",
       " ' AG': 3262,\n",
       " ' AH': 5105,\n",
       " ' AL': 996,\n",
       " ' ALL': 5054,\n",
       " ' ALLO': 5517,\n",
       " ' ALOC': 1615,\n",
       " ' AM': 3612,\n",
       " ' AN': 4142,\n",
       " ' AND': 2889,\n",
       " ' ANNU': 5833,\n",
       " ' ANY': 4182,\n",
       " ' AP': 3662,\n",
       " ' APS': 5554,\n",
       " ' AR': 3436,\n",
       " ' ARC': 5747,\n",
       " ' AS': 3384,\n",
       " ' AT': 2084,\n",
       " ' AU': 5380,\n",
       " ' AV': 4086,\n",
       " ' AY': 4864,\n",
       " ' Ab': 5932,\n",
       " ' Ac': 1366,\n",
       " ' Acc': 1208,\n",
       " ' Act': 3099,\n",
       " ' Ad': 1124,\n",
       " ' Aff': 2644,\n",
       " ' Ag': 141,\n",
       " ' Agre': 2652,\n",
       " ' Ak': 5005,\n",
       " ' Al': 3037,\n",
       " ' Ala': 5947,\n",
       " ' All': 2741,\n",
       " ' Am': 1516,\n",
       " ' Amer': 2374,\n",
       " ' Amor': 2744,\n",
       " ' An': 1210,\n",
       " ' Anal': 4680,\n",
       " ' Ap': 3556,\n",
       " ' App': 4186,\n",
       " ' Apr': 2833,\n",
       " ' Ar': 4791,\n",
       " ' Are': 2613,\n",
       " ' Ark': 6114,\n",
       " ' As': 2592,\n",
       " ' Ass': 1188,\n",
       " ' Assi': 4224,\n",
       " ' At': 4016,\n",
       " ' Au': 934,\n",
       " ' Av': 3437,\n",
       " ' Az': 5606,\n",
       " ' B': 572,\n",
       " ' BA': 4085,\n",
       " ' BB': 3343,\n",
       " ' BE': 2718,\n",
       " ' BEN': 1548,\n",
       " ' BI': 5365,\n",
       " ' BK': 4060,\n",
       " ' BL': 3333,\n",
       " ' BL ': 4726,\n",
       " ' BO': 4836,\n",
       " ' BP': 4498,\n",
       " ' BR': 3605,\n",
       " ' BU': 3635,\n",
       " ' BV': 4385,\n",
       " ' BY': 3840,\n",
       " ' Ba': 3784,\n",
       " ' Bal': 3382,\n",
       " ' Ban': 2137,\n",
       " ' Bas': 4029,\n",
       " ' Be': 3526,\n",
       " ' Bi': 3422,\n",
       " ' Bid': 3608,\n",
       " ' Bl': 3525,\n",
       " ' Bo': 2839,\n",
       " ' Bon': 1535,\n",
       " ' Boo': 833,\n",
       " ' Br': 3663,\n",
       " ' Bre': 3191,\n",
       " ' Bri': 1791,\n",
       " ' Bro': 3508,\n",
       " ' Bu': 2849,\n",
       " ' Bus': 2058,\n",
       " ' By': 2498,\n",
       " ' C': 254,\n",
       " ' CA': 3827,\n",
       " ' CAT': 5997,\n",
       " ' CC': 4330,\n",
       " ' CC ': 6122,\n",
       " ' CE': 4351,\n",
       " ' CG': 5545,\n",
       " ' CH': 3001,\n",
       " ' CI': 3306,\n",
       " ' CL': 4275,\n",
       " ' CN': 5377,\n",
       " ' CO': 2490,\n",
       " ' COM': 3335,\n",
       " ' COMP': 2590,\n",
       " ' CON': 2673,\n",
       " ' CORP': 3355,\n",
       " ' CP': 4796,\n",
       " ' CR': 3241,\n",
       " ' CS': 2678,\n",
       " ' CT': 5381,\n",
       " ' CU': 4070,\n",
       " ' CV': 3810,\n",
       " ' CY': 3813,\n",
       " ' Ca': 2894,\n",
       " ' Cal': 893,\n",
       " ' Can': 3948,\n",
       " ' Cap': 1803,\n",
       " ' Car': 2209,\n",
       " ' Care': 1385,\n",
       " ' Cas': 5010,\n",
       " ' Ce': 5972,\n",
       " ' Cen': 3342,\n",
       " ' Ch': 2775,\n",
       " ' Chan': 981,\n",
       " ' Char': 2326,\n",
       " ' Chec': 1674,\n",
       " ' Cho': 4576,\n",
       " ' Ci': 3899,\n",
       " ' Cit': 4400,\n",
       " ' Cl': 433,\n",
       " ' Cle': 1956,\n",
       " ' Co': 730,\n",
       " ' Col': 3175,\n",
       " ' Coll': 2500,\n",
       " ' Comm': 1484,\n",
       " ' Comp': 238,\n",
       " ' Con': 271,\n",
       " ' Coop': 3288,\n",
       " ' Coor': 1444,\n",
       " ' Cor': 675,\n",
       " ' Cost': 2025,\n",
       " ' Cost ': 5524,\n",
       " ' Cou': 3193,\n",
       " ' Cp': 2124,\n",
       " ' Cpar': 3187,\n",
       " ' Cre': 4005,\n",
       " ' Ct': 5778,\n",
       " ' Cu': 2801,\n",
       " ' Cur': 2952,\n",
       " ' Cy': 6083,\n",
       " ' D': 544,\n",
       " ' DA': 3387,\n",
       " ' DAT': 4706,\n",
       " ' DC': 3951,\n",
       " ' DD': 2766,\n",
       " ' DE': 2954,\n",
       " ' DELI': 2520,\n",
       " ' DEN': 5017,\n",
       " ' DES': 4616,\n",
       " ' DEV': 2185,\n",
       " ' DI': 3441,\n",
       " ' DJ': 5231,\n",
       " ' DM': 4163,\n",
       " ' DO': 4986,\n",
       " ' DP': 2692,\n",
       " ' DPR': 2318,\n",
       " ' DR': 3915,\n",
       " ' DS': 5193,\n",
       " ' DT': 5194,\n",
       " ' DU': 4740,\n",
       " ' Da': 2013,\n",
       " ' Dat': 1360,\n",
       " ' Day': 2840,\n",
       " ' De': 2214,\n",
       " ' Deal': 701,\n",
       " ' Deb': 4185,\n",
       " ' Dec': 1265,\n",
       " ' Def': 2451,\n",
       " ' Dep': 2208,\n",
       " ' Des': 3927,\n",
       " ' Deve': 1949,\n",
       " ' Di': 3058,\n",
       " ' Dir': 2691,\n",
       " ' Dis': 2982,\n",
       " ' Dist': 1082,\n",
       " ' Do': 3346,\n",
       " ' Do ': 5968,\n",
       " ' Don': 5012,\n",
       " ' Dow': 4699,\n",
       " ' Dr': 3462,\n",
       " ' Dri': 2620,\n",
       " ' Dt': 3841,\n",
       " ' Du': 3855,\n",
       " ' Duke': 2920,\n",
       " ' Dy': 4687,\n",
       " ' Dé': 5175,\n",
       " ' E': 1749,\n",
       " ' E-': 3655,\n",
       " ' EA': 4380,\n",
       " ' EB': 4240,\n",
       " ' EBB': 2379,\n",
       " ' ED': 5085,\n",
       " ' EEI': 4583,\n",
       " ' EF': 3332,\n",
       " ' EG': 5700,\n",
       " ' EI': 4487,\n",
       " ' EL': 4409,\n",
       " ' EM': 3985,\n",
       " ' EN': 4077,\n",
       " ' ENA': 3716,\n",
       " ' ENE': 4907,\n",
       " ' ENER': 2719,\n",
       " ' ENT': 5692,\n",
       " ' EO': 4488,\n",
       " ' EP': 4571,\n",
       " ' EPMI': 3318,\n",
       " ' EQ': 5915,\n",
       " ' EQUI': 4965,\n",
       " ' ER': 5564,\n",
       " ' ERCO': 2916,\n",
       " ' ES': 4490,\n",
       " ' ESD': 1026,\n",
       " ' EST': 4506,\n",
       " ' ET': 2771,\n",
       " ' ETS': 3159,\n",
       " ' EV': 4752,\n",
       " ' EW': 5167,\n",
       " ' EX': 2820,\n",
       " ' Eas': 3887,\n",
       " ' Ec': 3888,\n",
       " ' Ed': 1800,\n",
       " ' Ei': 5571,\n",
       " ' El': 386,\n",
       " ...}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(tokenizer._tokenize(\"These casseroles disgust Kayla.\"))\n",
    "tokenizer._vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3328d1cf",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9283d9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the tokenizer and create Encoder then use that to create decoder and full model\n",
    "model = SAFFUDecoder(config, SAFFUEncoder(config, tokenizer)).to(device)\n",
    "\n",
    "# Define the current stage of the model initial\n",
    "stage = \"init\"\n",
    "\n",
    "# Set to determine whether we are reloading or not\n",
    "reload = False\n",
    "\n",
    "# If in reload mode or the path doesnt exist for this dataset-model-stage combo then save_model\n",
    "if reload or (not os.path.exists(f\"./models_to_test/{data_set}-{model_size}-{stage}.state\")):\n",
    "    \n",
    "    \"\"\"\n",
    "    Saves the following information about current dataset-model_size-stage combo of the model\n",
    "    \n",
    "    1. state - Weights/params of the model which can be loaded later for resuming training or inference\n",
    "    2. losses - Training losses over epochs\n",
    "    3. counts - Frequency of words/subwords important for BPE\n",
    "    4. vocabulary - Mapping of words to indices to form vocab with keys as words and index as value\n",
    "    5. raw_td - Merge pairs dictating how subwords were combined to form new tokens, important for BPE\n",
    "    6. subtoken_reference - Maps text to its subwords, important for mapping output to og format\n",
    "    7. docsizes - Sizes of docs or number of tokens per doc\n",
    "    8. reference - Metadata related to training data or model perhaps\n",
    "    \"\"\"\n",
    "    save_model(model, data_set, model_size, stage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e503fc57",
   "metadata": {},
   "source": [
    "Step by step explanation of model:\n",
    "\n",
    "**Encoder**\n",
    "- 1. logsoft (LogSoftmax)\n",
    "    - a. Converts input tokens to log-probability representation for smoothing, preventing over/underflow, normalizing. \n",
    "    - b. Could be that the input tokens are treated as if they already carry certain relationships and LogSoftmax helps the model understand them probabilistically before passing them to Embeding layer _V\n",
    "- 2. _V (Embedding Layer)\n",
    "    - a. Is of dim: vocab_size x embed_size and converts each incoming word into embed_size vector\n",
    "    - b. Frozen during warm start and explicitly initialized to avoid changing during early training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb39234f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SAFFUDecoder(\n",
       "  (encoder): SAFFUEncoder(\n",
       "    (logsoft): LogSoftmax(dim=0)\n",
       "    (_V): Embedding(6130, 128)\n",
       "    (BS): ModuleList(\n",
       "      (0): SAFFULayer(\n",
       "        (activate): LogSoftmax(dim=0)\n",
       "        (logsoft): LogSoftmax(dim=0)\n",
       "        (_W): Linear(in_features=256, out_features=256, bias=False)\n",
       "        (_U): Linear(in_features=128, out_features=64, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (RS): ModuleList(\n",
       "      (0): SAFFULayer(\n",
       "        (activate): LogSoftmax(dim=0)\n",
       "        (logsoft): LogSoftmax(dim=0)\n",
       "        (_W): Linear(in_features=2, out_features=2, bias=False)\n",
       "        (_U): Linear(in_features=256, out_features=64, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (_W): FFULayer(\n",
       "      (activate): LogSoftmax(dim=0)\n",
       "      (_U): Linear(in_features=160, out_features=160, bias=False)\n",
       "    )\n",
       "    (_D): FFULayer(\n",
       "      (activate): LogSoftmax(dim=0)\n",
       "      (_U): Linear(in_features=128, out_features=32, bias=False)\n",
       "    )\n",
       "  )\n",
       "  (_Uc): FFULayer(\n",
       "    (activate): LogSoftmax(dim=0)\n",
       "    (_U): Linear(in_features=160, out_features=6130, bias=False)\n",
       "  )\n",
       "  (_Ud): Linear(in_features=32, out_features=24521, bias=False)\n",
       "  (logsoft): LogSoftmax(dim=0)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c5e006a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SAFFUEncoder(\n",
       "  (logsoft): LogSoftmax(dim=0)\n",
       "  (_V): Embedding(6130, 128)\n",
       "  (BS): ModuleList(\n",
       "    (0): SAFFULayer(\n",
       "      (activate): LogSoftmax(dim=0)\n",
       "      (logsoft): LogSoftmax(dim=0)\n",
       "      (_W): Linear(in_features=256, out_features=256, bias=False)\n",
       "      (_U): Linear(in_features=128, out_features=64, bias=False)\n",
       "    )\n",
       "  )\n",
       "  (RS): ModuleList(\n",
       "    (0): SAFFULayer(\n",
       "      (activate): LogSoftmax(dim=0)\n",
       "      (logsoft): LogSoftmax(dim=0)\n",
       "      (_W): Linear(in_features=2, out_features=2, bias=False)\n",
       "      (_U): Linear(in_features=256, out_features=64, bias=False)\n",
       "    )\n",
       "  )\n",
       "  (_W): FFULayer(\n",
       "    (activate): LogSoftmax(dim=0)\n",
       "    (_U): Linear(in_features=160, out_features=160, bias=False)\n",
       "  )\n",
       "  (_D): FFULayer(\n",
       "    (activate): LogSoftmax(dim=0)\n",
       "    (_U): Linear(in_features=128, out_features=32, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e091bc70",
   "metadata": {},
   "source": [
    "# Dataloader Setup for SAFFU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "371d1419",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Files: 100%|█████████████████████████| 10/10 [00:27<00:00,  2.79s/it]\n"
     ]
    }
   ],
   "source": [
    "# Define the data directories\n",
    "#train_dir = '../data/train/'\n",
    "val_dir = '../data/train_small/'\n",
    "\n",
    "# Get the dataloaders\n",
    "#train_loader = get_saffuloader(train_dir, tokenizer)\n",
    "val_loader = get_saffuloader(val_dir, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "60f1ed1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total length of val_loader (number of batches): 10\n",
      "Number of elements in x_tok (validation tokens): 10\n",
      "Number of elements in y_tok (validation metadata): 10\n",
      "Number of file paths (corresponding to each element): 10\n",
      "Shape of the first x_tok example (input tensor): torch.Size([100, 100, 32])\n",
      "First x_tok tensor:\n",
      " tensor([[[   2,   10,    3,  ...,    0,    0,    0],\n",
      "         [   2,    7,    3,  ...,    0,    0,    0],\n",
      "         [   2,   15,    3,  ...,    0,    0,    0],\n",
      "         ...,\n",
      "         [   2,  159,    3,  ...,    0,    0,    0],\n",
      "         [   2,   93,    3,  ...,    0,    0,    0],\n",
      "         [   2,  229,    3,  ...,    0,    0,    0]],\n",
      "\n",
      "        [[   2,  182,    3,  ...,    0,    0,    0],\n",
      "         [   2,  536,    3,  ...,    0,    0,    0],\n",
      "         [   2,  486,    3,  ...,    0,    0,    0],\n",
      "         ...,\n",
      "         [   2,  577,    3,  ...,    0,    0,    0],\n",
      "         [   2,   31,    3,  ...,    0,    0,    0],\n",
      "         [   2,   11,    3,  ...,    0,    0,    0]],\n",
      "\n",
      "        [[   2,  479,    3,  ...,    0,    0,    0],\n",
      "         [   2,  477,    3,  ...,    0,    0,    0],\n",
      "         [   2,  681,    3,  ...,    0,    0,    0],\n",
      "         ...,\n",
      "         [   2,  767,    3,  ...,    0,    0,    0],\n",
      "         [   2, 1387,    3,  ...,    0,    0,    0],\n",
      "         [   2,  748,    3,  ...,    0,    0,    0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[   2,  178,   21,  ...,    0,    0,    0],\n",
      "         [   2,  178,   38,  ...,    0,    0,    0],\n",
      "         [   2,  178,   42,  ...,    0,    0,    0],\n",
      "         ...,\n",
      "         [   2,  178,  159,  ...,    0,    0,    0],\n",
      "         [   2,  178,   93,  ...,    0,    0,    0],\n",
      "         [   2,  159,  162,  ...,    0,    0,    0]],\n",
      "\n",
      "        [[   2,  159,   21,  ...,    0,    0,    0],\n",
      "         [   2,  159,   38,  ...,    0,    0,    0],\n",
      "         [   2,  159,   42,  ...,    0,    0,    0],\n",
      "         ...,\n",
      "         [   2,  159,  159,  ...,    0,    0,    0],\n",
      "         [   2,  159,   93,  ...,    0,    0,    0],\n",
      "         [   2, 3040,    3,  ...,    0,    0,    0]],\n",
      "\n",
      "        [[   2,   93,   21,  ...,    0,    0,    0],\n",
      "         [   2,   93,   38,  ...,    0,    0,    0],\n",
      "         [   2,   93,   42,  ...,    0,    0,    0],\n",
      "         ...,\n",
      "         [   2,  879,    3,  ...,    0,    0,    0],\n",
      "         [   2,   37,    3,  ...,    0,    0,    0],\n",
      "         [   2,   10,   22,  ...,    0,    0,    0]]])\n",
      "Shape of the first y_tok example (metadata tensor): torch.Size([100, 100, 17])\n",
      "First y_tok tensor:\n",
      " tensor([[[3, 0, 0,  ..., 0, 0, 0],\n",
      "         [3, 0, 0,  ..., 0, 0, 0],\n",
      "         [3, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [3, 0, 0,  ..., 0, 0, 0],\n",
      "         [3, 0, 0,  ..., 0, 0, 0],\n",
      "         [3, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[3, 0, 0,  ..., 0, 0, 0],\n",
      "         [3, 0, 0,  ..., 0, 0, 0],\n",
      "         [3, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [3, 0, 0,  ..., 0, 0, 0],\n",
      "         [3, 0, 0,  ..., 0, 0, 0],\n",
      "         [3, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[3, 0, 0,  ..., 0, 0, 0],\n",
      "         [3, 0, 0,  ..., 0, 0, 0],\n",
      "         [3, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [3, 0, 0,  ..., 0, 0, 0],\n",
      "         [3, 0, 0,  ..., 0, 0, 0],\n",
      "         [3, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[3, 0, 0,  ..., 0, 0, 0],\n",
      "         [3, 0, 0,  ..., 0, 0, 0],\n",
      "         [3, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [3, 0, 0,  ..., 0, 0, 0],\n",
      "         [3, 0, 0,  ..., 0, 0, 0],\n",
      "         [3, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[3, 0, 0,  ..., 0, 0, 0],\n",
      "         [3, 0, 0,  ..., 0, 0, 0],\n",
      "         [3, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [3, 0, 0,  ..., 0, 0, 0],\n",
      "         [3, 0, 0,  ..., 0, 0, 0],\n",
      "         [3, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[3, 0, 0,  ..., 0, 0, 0],\n",
      "         [3, 0, 0,  ..., 0, 0, 0],\n",
      "         [3, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [3, 0, 0,  ..., 0, 0, 0],\n",
      "         [3, 0, 0,  ..., 0, 0, 0],\n",
      "         [3, 0, 0,  ..., 0, 0, 0]]])\n",
      "First file path: ../data/train_small/f7.xlsx\n"
     ]
    }
   ],
   "source": [
    "# print(len(train_loader))\n",
    "# print(len(train_loader.x_tok))\n",
    "# print(len(train_loader.y_tok))\n",
    "# print(len(train_loader.file_paths))\n",
    "# print(train_loader.x_tok[0].shape)\n",
    "# print(train_loader.y_tok[0].shape)\n",
    "# print(train_loader.file_paths[0])\n",
    "\n",
    "# Print the total length of the validation loader\n",
    "print(\"Total length of val_loader (number of batches):\", len(val_loader))\n",
    "\n",
    "# Print the number of elements in val_loader.x_tok\n",
    "print(\"Number of elements in x_tok (validation tokens):\", len(val_loader.x_tok))\n",
    "\n",
    "# Print the number of elements in val_loader.y_tok\n",
    "print(\"Number of elements in y_tok (validation metadata):\", len(val_loader.y_tok))\n",
    "\n",
    "# Print the number of file paths in val_loader.file_paths\n",
    "print(\"Number of file paths (corresponding to each element):\", len(val_loader.file_paths))\n",
    "\n",
    "# Print the shape of the first example from x_tok\n",
    "print(\"Shape of the first x_tok example (input tensor):\", val_loader.x_tok[0].shape)\n",
    "\n",
    "# Print the full tensor of the first x_tok example\n",
    "print(\"First x_tok tensor:\\n\", val_loader.x_tok[0])\n",
    "\n",
    "# Print the shape of the first example from y_tok\n",
    "print(\"Shape of the first y_tok example (metadata tensor):\", val_loader.y_tok[0].shape)\n",
    "\n",
    "# Print the full tensor of the first y_tok example\n",
    "print(\"First y_tok tensor:\\n\", val_loader.y_tok[0])\n",
    "\n",
    "# Print the first file path in val_loader.file_paths\n",
    "print(\"First file path:\", val_loader.file_paths[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f86ead",
   "metadata": {},
   "source": [
    "# Streamline TestRNN class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "56885960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import importlib to reload modules and sys and os to add the path for other imports\n",
    "# import importlib\n",
    "# import sys\n",
    "# import os\n",
    "\n",
    "# # Append the parent directory to the path to import the necessary modules\n",
    "# sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "# # Import the utilities and the dataloader\n",
    "# from utils import selfutil\n",
    "# from classes import SpreadsheetDataLoader, TestRNN\n",
    "\n",
    "# # Now reload the modules to ensure they are up-to-date\n",
    "# importlib.reload(selfutil)\n",
    "# importlib.reload(SpreadsheetDataLoader)\n",
    "# importlib.reload(TestRNN)\n",
    "\n",
    "# # Import the funcs needed from utils\n",
    "# from utils.selfutil import get_vocabulary, create_embeddings, to_gpu\n",
    "\n",
    "# # Import the SpreadsheetDataLoader class\n",
    "# from classes.SpreadsheetDataLoader import SpreadsheetDataLoader\n",
    "# from classes.TestRNN import TestRNN\n",
    "\n",
    "# # Other regular imports\n",
    "# import torch.nn as nn\n",
    "# import torch\n",
    "# from tqdm import tqdm\n",
    "# import gc\n",
    "# import os\n",
    "# import pandas as pd\n",
    "# import math\n",
    "# import time\n",
    "\n",
    "# # Set the directory containing the spreadsheets\n",
    "# data_dir = '../data/train_small/'\n",
    "\n",
    "# # Get the list of file paths\n",
    "# spreadsheet_vocab,file_paths = get_vocabulary(data_dir)\n",
    "\n",
    "# # Print info\n",
    "# print(f'\\n\\nVocabulary size: {len(spreadsheet_vocab._word2idx)}')\n",
    "# print(f'Files Processed: {len(file_paths)}')\n",
    "\n",
    "# # Create the embeddings for each word in the vocabulary and view info\n",
    "# spreadsheet_wvs = create_embeddings(spreadsheet_vocab)\n",
    "# print(f'Word Embeddings Shape: {spreadsheet_wvs.shape}')\n",
    "# print(f'\\nExample Embedding for <unk> at index 0:\\n{spreadsheet_wvs[0]}')\n",
    "\n",
    "# # Create the SpreadsheetDataLoader object with the vocabulary and file paths and view\n",
    "# check_loader = SpreadsheetDataLoader(file_paths, spreadsheet_vocab)\n",
    "# print(f'Spreadsheets Processed: {len(check_loader)}')\n",
    "# print(f'x_tok Tensor Shape: {check_loader.x_tok[0].shape}')\n",
    "# print(f'y_tok Tensor Shape: {check_loader.y_tok[0].shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f9a6aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available objects for config:\n",
      "    AliasManager\n",
      "    DisplayFormatter\n",
      "    HistoryManager\n",
      "    IPCompleter\n",
      "    IPKernelApp\n",
      "    LoggingMagics\n",
      "    MagicsManager\n",
      "    OSMagics\n",
      "    PrefilterManager\n",
      "    ScriptMagics\n",
      "    StoreMagics\n",
      "    ZMQInteractiveShell\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5fac822",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestRNN2(nn.Module):\n",
    "\n",
    "    # Constructor of the RNN_LM class, initializing the layers and weights\n",
    "    def __init__(self, hidden_state_dim, rnn_layers, embedding_matrix, dropout_rate=0.0, nonlinearity='relu'):\n",
    "\n",
    "        # Ensures functions of parent class nn.Module are called in subclass RNN_LM\n",
    "        super(TestRNN2, self).__init__()\n",
    "\n",
    "        # Rows of embed matrix = Each word in the vocabulary\n",
    "        self.vocab_size = embedding_matrix.shape[0]  # vocab_size = 34057\n",
    "\n",
    "        # Cols of embed matrix = Length of each embedding vector\n",
    "        self.embedding_dim = embedding_matrix.shape[1]  # embed_dim = 50\n",
    "\n",
    "        # The dimension of the hidden state vector 'h' for each step/token\n",
    "        self.hidden_dim = hidden_state_dim  # hid_dim = 100\n",
    "\n",
    "        # Number of recurrent layers we will use\n",
    "        self.rnn_layers = rnn_layers  # rnn_layers = 2\n",
    "\n",
    "        # Creates an embedding layer from the pre-trained embedding matrix that maps input tokens to their corresponding word vectors\n",
    "        # If freezing then embeddings don't change during training, we need False because we need them to finetune to our task\n",
    "        self._embed = nn.Embedding.from_pretrained(embedding_matrix, freeze=False)\n",
    "\n",
    "        # Randomly zeroes out a percentage of input units determined by dropout_rate for each update during training\n",
    "        self._drop = nn.Dropout(dropout_rate)\n",
    "\n",
    "        # RNN layer with 'relu' nonlinearity but not managing exploding gradients, dropout and multiple recurrent layers\n",
    "        self._rnn = nn.RNN(\n",
    "            self.embedding_dim,\n",
    "            self.hidden_dim,\n",
    "            self.rnn_layers,\n",
    "            nonlinearity=nonlinearity,\n",
    "            dropout=dropout_rate\n",
    "        )\n",
    "\n",
    "        # Linear layer to map the concatenated hidden states to logits (1 to predict bold or not)\n",
    "        self._pred = nn.Linear(2 * self.hidden_dim, 1)\n",
    "\n",
    "    def cell_hs(self, x):\n",
    "\n",
    "        # Set the manual seed for reproducibility\n",
    "        torch.manual_seed(0)\n",
    "\n",
    "        # Initialize H_local as a zero tensor with the appropriate shape (num_cells, hidden_dim)\n",
    "        H_local = torch.zeros(x.shape[1] * x.shape[2], self.hidden_dim, device=x.device) # cells x hidden_dim\n",
    "        \n",
    "#         # DEBUG PRINT\n",
    "#         print(f'Input x: {x.shape}')\n",
    "#         print(f'\\nH_local before {H_local.shape}:\\n{H_local}')\n",
    "\n",
    "        # Iterate over each cell\n",
    "        for cell in tqdm(range(x.shape[1] * x.shape[2]),desc=\"Getting Cells\"):\n",
    "            \n",
    "            # Get the current row and col\n",
    "            row = cell // x.shape[2]\n",
    "            col = cell % x.shape[2]\n",
    "            \n",
    "            # Extract cell tokens across batches for current cell\n",
    "            celltoks_across_batch = x[:, row, col, :] # batch_size x tokens\n",
    "\n",
    "            # Get tokens in embedding dim and apply dropout\n",
    "            embedded_toks = self._drop(self._embed(celltoks_across_batch)) # batch_size x tokens x embed_dim\n",
    "\n",
    "            # Now run RNN on dropout\n",
    "            _, h = self._rnn(embedded_toks)\n",
    "            \n",
    "            # Store hidden state from last rnn layer for last token in H_local tensor\n",
    "            H_local[cell] = h[-1, -1, :]\n",
    "            \n",
    "#             # DEBUG PRINT\n",
    "#             if cell == 0:\n",
    "#                 print(f'\\nInside Cell {cell}\\nRow {row}, Col {col}')\n",
    "#                 print(f'\\nCell Across {celltoks_across_batch.shape}:\\n{celltoks_across_batch}')\n",
    "#                 print(f'\\nCell Embedded Toks {embedded_toks.shape}:\\n{embedded_toks}')\n",
    "#                 print(f'\\nRNN H {h.shape}:\\n{h}')\n",
    "#                 print(f'\\nLast RNN Layer Last Token HS {H_local[cell].shape}:\\n{H_local[cell]}')\n",
    "\n",
    "            # Delete intermediate tensors to free up memory\n",
    "            del celltoks_across_batch\n",
    "            del embedded_toks\n",
    "            del h\n",
    "\n",
    "\n",
    "        # Now get the sum of all the HS in size cells x hidden_dim and subtract individual HS\n",
    "        ans = H_local.sum(dim=0, keepdim=True) - H_local # cells x hidden_dim\n",
    "        \n",
    "#         # DEBUG PRINT\n",
    "#         print(f'\\nFinal H_local {H_local.shape}:\\n{H_local}')\n",
    "#         print(f'\\nFinal Returned Tensor {ans.shape}:\\n{ans}')\n",
    "\n",
    "        # Delete the H_local \n",
    "        del H_local\n",
    "        \n",
    "        # Calculate the global sum and return the adjusted tensor\n",
    "        return ans\n",
    "    \n",
    "    # Forward function\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Set the manual seed\n",
    "        torch.manual_seed(0)\n",
    "\n",
    "        # Global hidden states containing info around current cell already on gpu\n",
    "        H_global = self.cell_hs(x) # cells x hidden_dim\n",
    "\n",
    "        # Tensor to store the full macro cube of size batch x rows x cols\n",
    "        S_cube = torch.zeros((x.shape[0], x.shape[1], x.shape[2]), device=x.device)\n",
    "        \n",
    "#         # DEBUG PRINT\n",
    "#         print(f'\\nInput x {x.shape}')\n",
    "#         print(f'\\nInitial H_global {H_global.shape}:\\n{H_global}')\n",
    "#         print(f'\\nInitial S_cube {S_cube.shape}:\\n{S_cube}')\n",
    "\n",
    "        # Loop through all rows x cols cells\n",
    "        for cell in range(x.shape[1] * x.shape[2]):\n",
    "            \n",
    "            # Get the current row and col\n",
    "            row = cell // x.shape[2]\n",
    "            col = cell % x.shape[2]\n",
    "            \n",
    "            # Extract cell tokens across batches for current cell\n",
    "            celltoks_across_batch = x[:, row, col, :] # batch_size x tokens\n",
    "            \n",
    "            # Get tokens in embedding dim and apply dropout\n",
    "            embedded_toks = self._drop(self._embed(celltoks_across_batch)) # batch_size x tokens x embed_dim\n",
    "\n",
    "            # Now run RNN on embedded toks\n",
    "            z, _ = self._rnn(embedded_toks) # batch_size x tokens x hidden_dim\n",
    "            \n",
    "            # Get z for last token across all batches and hidden dim\n",
    "            z_lasttok = z[:, -1, :] # batch_size x hidden_dim\n",
    "            \n",
    "            # Extract H_global for current cell and introduce first dimension, then expand first dim to batch_size\n",
    "            H_cell = H_global[cell].unsqueeze(0).expand(x.shape[0], -1) # batch_size x hidden_dim\n",
    "\n",
    "            # Concatenate global/local context of cell along first dim batch_size then apply dropout\n",
    "            concat_hs = self._drop(torch.cat((z_lasttok, H_cell), dim = 1)) # batch_size x (2 * hidden_dim)\n",
    "            \n",
    "            # Make preds using this HS and adjust to be batch_size, set to current location in S_cube\n",
    "            S_cube[:, row, col] = self._pred(concat_hs).view(-1) # batch_size\n",
    "            \n",
    "#             # DEBUG PRINT\n",
    "#             if cell == 0:\n",
    "#                 print(f'\\nInside Cell {cell}\\nRow {row}, Col {col}')\n",
    "#                 print(f'\\nCell Across {celltoks_across_batch.shape}:\\n{celltoks_across_batch}')\n",
    "#                 print(f'\\nCell Embedded Toks {embedded_toks.shape}:\\n{embedded_toks}')\n",
    "#                 print(f'\\nRNN Z {z.shape}:\\n{z}')\n",
    "#                 print(f'\\nRNN Z Last Token {z_lasttok.shape}:\\n{z_lasttok}')\n",
    "#                 print(f'\\nH_cell global HS for cell {H_cell.shape}:\\n{H_cell}')\n",
    "#                 print(f'\\nConcatenated HS {concat_hs.shape}:\\n{concat_hs}')\n",
    "#                 print(f'\\nPredictions {S_cube[:, row, col].shape}:\\n{S_cube[:, row, col]}')\n",
    "\n",
    "\n",
    "            # Delete intermediate tensors to free up memory\n",
    "            del celltoks_across_batch\n",
    "            del embedded_toks\n",
    "            del z\n",
    "            del z_lasttok\n",
    "            del H_cell\n",
    "            del concat_hs\n",
    "        \n",
    "        \n",
    "#         # DEBUG PRINT\n",
    "#         print(f'\\nFinal S_cube {S_cube.shape}:\\n{S_cube}')\n",
    "        \n",
    "        # Delete H_global finally\n",
    "        del H_global\n",
    "        \n",
    "        # Return the final S_cube\n",
    "        return S_cube\n",
    "        \n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73433aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUDA Vars to avoid randomization\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Create a DataLoader from your check_loader\n",
    "test_loader = torch.utils.data.DataLoader(check_loader, batch_size=4, shuffle=False)\n",
    "\n",
    "# Get one batch from the DataLoader\n",
    "batch = next(iter(test_loader))\n",
    "\n",
    "# Move batch to current gpu device\n",
    "exfile = batch['x_tok'].to(device)\n",
    "\n",
    "# Define NN Params\n",
    "hidden_state_dim = 100\n",
    "rnn_layers = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0956b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TestRNN2(\n",
      "  (_embed): Embedding(10010, 50)\n",
      "  (_drop): Dropout(p=0.0, inplace=False)\n",
      "  (_rnn): RNN(50, 100, num_layers=2)\n",
      "  (_pred): Linear(in_features=200, out_features=1, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting Cells: 100%|████████████████████| 10000/10000 [00:06<00:00, 1504.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cell_hs2 shape: torch.Size([4, 100, 100])\n"
     ]
    }
   ],
   "source": [
    "# Define the model and print\n",
    "rnn_model2 = TestRNN2(hidden_state_dim, rnn_layers, spreadsheet_wvs).to(device)\n",
    "print(rnn_model2)\n",
    "\n",
    "# Run the forward method\n",
    "out2 = rnn_model2.forward(exfile)\n",
    "\n",
    "# Print the shape of S_cube\n",
    "print(\"RNN2 Output shape:\", out2.shape)\n",
    "\n",
    "# # Calculate the absolute difference between the two tensors\n",
    "# absolute_diff = torch.abs(out - out2)\n",
    "\n",
    "# # Calculate the mean of the absolute differences\n",
    "# mean_absolute_diff = torch.mean(absolute_diff)\n",
    "\n",
    "# print(f\"Mean absolute difference: {mean_absolute_diff.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1674036f",
   "metadata": {},
   "source": [
    "# Trying New Model with SAFFU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e25c688d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single x_tok tensor from val_loader torch.Size([100, 100, 32])\n",
      "\n",
      "Tokens for first cell shaped torch.Size([32]):\n",
      "tensor([ 2, 10,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n"
     ]
    }
   ],
   "source": [
    "# CUDA Vars to avoid randomization\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Create a DataLoader from your check_loader\n",
    "test_loader = torch.utils.data.DataLoader(val_loader, batch_size=2, shuffle=False)\n",
    "\n",
    "# Get one batch from the DataLoader\n",
    "batch = next(iter(test_loader))\n",
    "\n",
    "# Extract single x_tok example from batch\n",
    "ex_input = batch['x_tok'][0]\n",
    "\n",
    "# Extract single cell's tokens\n",
    "cell_tokens = ex_input[0,0,:]\n",
    "#cell_tokens = cell_tokens.unsqueeze(0)\n",
    "\n",
    "# Observe shape and tensor\n",
    "print(f'Single x_tok tensor from val_loader {ex_input.shape}')\n",
    "print(f'\\nTokens for first cell shaped {cell_tokens.shape}:\\n{cell_tokens}')\n",
    "\n",
    "# # Pass the single tensor through SAFFU model\n",
    "# one_pass = model.forward(cell_tokens, cell_tokens.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d0010476",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "forward() missing 4 required positional arguments: 'blocks', 'is_inference', 'bis', and 'ms'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[18], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Checking input with single cell tokens in encoder\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoder\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcell_tokens\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      3\u001B[0m output\n",
      "File \u001B[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1102\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1098\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1099\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1100\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1101\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1102\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1103\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1104\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "\u001B[0;31mTypeError\u001B[0m: forward() missing 4 required positional arguments: 'blocks', 'is_inference', 'bis', and 'ms'"
     ]
    }
   ],
   "source": [
    "# Checking input with single cell tokens in encoder\n",
    "output = model.encoder(cell_tokens)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2276854",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033768ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3dcf98c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae6d14f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68e8a0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adbcd7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ad3b243",
   "metadata": {},
   "source": [
    "# Tuning\n",
    "\n",
    "## Setup params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db65cb2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total numbers of learnable/all parameters: 2670335/2703611\n"
     ]
    }
   ],
   "source": [
    "# Total params in the model so the number of elements for each param name all together\n",
    "total_params = 0\n",
    "\n",
    "# Total learnable params\n",
    "total_learnable = 0\n",
    "\n",
    "# Iterate through each macro param in model's params like Psi_b, _V.weight, RS.0._U.weight etc.   \n",
    "for name, param in model.named_parameters():\n",
    "    \n",
    "    # Current param count is product of tensor dims (log-exp avoids overflow -> one less than actual)\n",
    "    curr_params = int(np.exp(sum(np.log(param.shape))))\n",
    "    \n",
    "    # Add curr_params to learnable params if curr_param requires grad\n",
    "    total_learnable += curr_params if param.requires_grad else 0\n",
    "    \n",
    "    # Add curr_params to total_params\n",
    "    total_params += curr_params\n",
    "\n",
    "# Print the ratio of learnable to all params\n",
    "print(f\"Total numbers of learnable/all parameters: {total_learnable}/{total_params}\")\n",
    "\n",
    "# Set grad to false to freeze embedding layer since we are warm starting\n",
    "model.encoder._V.weight.requires_grad = False\n",
    "\n",
    "# Set seed for reproducibility\n",
    "seed = 691\n",
    "\n",
    "# Define whether warm starting or not\n",
    "warm_start = True\n",
    "\n",
    "# Determine if verbose output needed when running tuner.warm_start()\n",
    "verbose = True\n",
    "\n",
    "# Adds spaces with tokens if set to False else removes them if True\n",
    "ignore_space = False\n",
    "\n",
    "# Case sensitive if False and lowercases everything if True\n",
    "ignore_case = False\n",
    "\n",
    "# Used for initializating _V (embeddings) matrix during the warm start. Higher = Richer init repr for each token\n",
    "warm_vecs = 1*(2**0 + 0.99999) # = 2\n",
    "\n",
    "# Do-nothing transform, sets part embeddings to identity stabilizing over-aggressive/random init states\n",
    "identity_ratio = 2**(-1) # = 0.5\n",
    "\n",
    "# Inverse Context Freq: co-occurrence counts reweight words based on rarity/importance\n",
    "# Highlights contextually significant words leading to better differentiation if set to True\n",
    "icf = True \n",
    "\n",
    "# Indicates if token labels are log/linear. Log reduces impact of high freq elements, linear simpler \n",
    "log_label = False\n",
    "\n",
    "# Number of distinct clusters to assign to tokens during training\n",
    "nlabels = 1*(2**0) # = 1 = No subdivision cluster of toks\n",
    "\n",
    "# Should model consider centroids during clustering/quantization process\n",
    "centroids = False\n",
    "\n",
    "# Iterations to refine label assignments in training. Higher = Reclusturing more for each token getting more accurate groups\n",
    "label_iterations = 1*(2**10) # = 1024\n",
    "\n",
    "# Determine epochs and scale by factor of 1024 to account for smaller datasets\n",
    "epochs = int(np.max([int(downsample/5), 1]))*(2**10)\n",
    "\n",
    "# Determine if reloading or new\n",
    "reload = False\n",
    "\n",
    "# Determine patience to of observing no loss reduction\n",
    "patience = 2**1\n",
    "\n",
    "# Finally name the file used for warm start\n",
    "warm_file = \"\".join([data_file[:-5] + \"-\", \n",
    "                     f\"b_{tokenizer.config._bits}-hb_{tokenizer.config._hidden}-\",\n",
    "                     f\"we_{int(tokenizer.config._wave_encode)}-oa_{tokenizer.config._o_agg}-ra_{tokenizer.config._r_agg}-ba_{tokenizer.config._b_agg}-\",\n",
    "                     f\"mr_{int(tokenizer.config._mask_r)}-mb_{int(tokenizer.config._mask_b)}-md_{tokenizer.config._model_documents}-\",\n",
    "                     f\"is_{int(ignore_space)}-ic_{int(ignore_case)}-ws_{int(warm_start)}-wv_{int(warm_vecs)}-ds_{downsample}-seed_{seed}\"])\n",
    "\n",
    "# Define traning and dev directories\n",
    "train_dir = '../data/train/'; dev_dir = '../data/train_small'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "757fed1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting convos list:  26%|█████               | 159/623 [00:05<00:13, 33.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR ../data/train/randall_gay_000_1_1.pst.21.xls: Error tokenizing data. C error: Expected 1 fields in line 39, saw 3\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting convos list: 100%|████████████████████| 623/623 [00:25<00:00, 24.63it/s]\n",
      "Getting convos list: 100%|██████████████████████| 10/10 [00:01<00:00,  7.68it/s]\n"
     ]
    }
   ],
   "source": [
    "# Update the convos lists required for tuner\n",
    "convos = dir2convos(train_dir)\n",
    "dconvos = dir2convos(dev_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "841dba40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Cell', ''],\n",
       " ['Cell', 'TRANSWESTERN PIPELINE COMPANY'],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell',\n",
       "  'Rate calculation is based on the spread of two indices less variable charges (fuel/usage) less fixed rate or spread.  PG&E to provide index price calc.'],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', 'CAPACITY RELEASE REPORT'],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell',\n",
       "  'Settlement Based Max Reservation Rates and TCR Surcharges changed eff 11/1/00; GRD rate changed eff 1/1/01.'],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', 'DEALS ABOVE MAX TARIFF RATE'],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell',\n",
       "  '                                                                                                                                                                                                                                                               '],\n",
       " ['Cell', ''],\n",
       " ['Cell', 'RLSE'],\n",
       " ['Cell', ''],\n",
       " ['Cell', 'REPLACEMENT'],\n",
       " ['Cell', ''],\n",
       " ['Cell', 'REPLACEMENT'],\n",
       " ['Cell', ''],\n",
       " ['Cell', 'OFFER'],\n",
       " ['Cell', 'REPLACEMENT'],\n",
       " ['Cell', ''],\n",
       " ['Cell', 'REPLACEMENT'],\n",
       " ['Cell', '1-PART'],\n",
       " ['Cell', 'MINIMUM'],\n",
       " ['Cell', ''],\n",
       " ['Cell', 'CREDIT TO'],\n",
       " ['Cell', 'APPLICABLE'],\n",
       " ['Cell', 'VALUE OVER'],\n",
       " ['Cell', 'TERM'],\n",
       " ['Cell', 'TERM'],\n",
       " ['Cell', 'RE-'],\n",
       " ['Cell', 'PRE-'],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', 'Rate'],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', 'REL #'],\n",
       " ['Cell', 'RLSE SHIPPER'],\n",
       " ['Cell', 'CTRC#'],\n",
       " ['Cell', 'VOLUME'],\n",
       " ['Cell', 'RECEIPT POI'],\n",
       " ['Cell', ''],\n",
       " ['Cell', 'DELIVERY POI'],\n",
       " ['Cell', ''],\n",
       " ['Cell', 'RATE'],\n",
       " ['Cell', 'ENTITY'],\n",
       " ['Cell', 'CTRC#'],\n",
       " ['Cell', 'VOL'],\n",
       " ['Cell', '% VOL COM'],\n",
       " ['Cell', 'AWARD RATE*'],\n",
       " ['Cell', ''],\n",
       " ['Cell', 'RELEASER'],\n",
       " ['Cell', 'MAX RATE**'],\n",
       " ['Cell', 'MAX RATE'],\n",
       " ['Cell', 'START'],\n",
       " ['Cell', 'END'],\n",
       " ['Cell', 'CALL'],\n",
       " ['Cell', 'ARR'],\n",
       " ['Cell', 'STATUS'],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', 'Sched'],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', '3044'],\n",
       " ['Cell', 'southern california gas company'],\n",
       " ['Cell', '8255'],\n",
       " ['Cell', '3057'],\n",
       " ['Cell', '58646'],\n",
       " ['Cell', 'west texas pool'],\n",
       " ['Cell', '10487'],\n",
       " ['Cell', 'socal needles'],\n",
       " ['Cell', '0.4006'],\n",
       " ['Cell', 'enron energy services, inc.'],\n",
       " ['Cell', '27471'],\n",
       " ['Cell', '3057'],\n",
       " ['Cell', ''],\n",
       " ['Cell', '1.0015'],\n",
       " ['Cell', '28'],\n",
       " ['Cell', '85724.39'],\n",
       " ['Cell', '0.4006'],\n",
       " ['Cell', '51434.64'],\n",
       " ['Cell', '2001-02-01 00:00:00'],\n",
       " ['Cell', '2001-02-28 00:00:00'],\n",
       " ['Cell', 'N'],\n",
       " ['Cell', 'Y'],\n",
       " ['Cell', 'Awarded'],\n",
       " ['Cell', '0'],\n",
       " ['Cell', '250'],\n",
       " ['Cell', 'FTS-1'],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', '3042'],\n",
       " ['Cell', 'southern california gas company'],\n",
       " ['Cell', '8255'],\n",
       " ['Cell', '2004'],\n",
       " ['Cell', '58649'],\n",
       " ['Cell', 'central pool'],\n",
       " ['Cell', '10487'],\n",
       " ['Cell', 'socal needles'],\n",
       " ['Cell', '0.4006'],\n",
       " ['Cell', 'sempra energy solutions, llc'],\n",
       " ['Cell', '27486'],\n",
       " ['Cell', '2004'],\n",
       " ['Cell', ''],\n",
       " ['Cell', '0.7011'],\n",
       " ['Cell', '28'],\n",
       " ['Cell', '39340.12'],\n",
       " ['Cell', '0.4006'],\n",
       " ['Cell', '16861.66'],\n",
       " ['Cell', '2001-02-01 00:00:00'],\n",
       " ['Cell', '2001-02-28 00:00:00'],\n",
       " ['Cell', 'N'],\n",
       " ['Cell', 'Y'],\n",
       " ['Cell', 'Awarded'],\n",
       " ['Cell', '0'],\n",
       " ['Cell', '175'],\n",
       " ['Cell', 'FTS-1'],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ['Cell', ''],\n",
       " ...]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convos[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96580e62",
   "metadata": {},
   "source": [
    "## Warm Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a14b8320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the tuner\n",
    "tuner = SAFFUTuner(ignore_case, ignore_space, devstr, warm_vecs, identity_ratio = identity_ratio,\n",
    "                   label_iterations = label_iterations, log_label = log_label, nlabels = nlabels,\n",
    "                   centroids = centroids, icf = icf)\n",
    "\n",
    "# Warm start with params\n",
    "tuner.warm_start(model, convos, dconvos, downsample*10, seed, epochs, \n",
    "                 patience, devsample = devsample, model_file = warm_file,\n",
    "                 reload = reload, verbose = verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e18eb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_params, total_learnable = 0, 0\n",
    "# for name, param in model.named_parameters():\n",
    "#     total_params += int(np.exp(sum(np.log(param.shape))))\n",
    "#     if param.requires_grad:\n",
    "#         total_learnable += int(np.exp(sum(np.log(param.shape)))) # param.shape[0]*param.shape[1]\n",
    "#         # print(name, param.shape[0]*param.shape[1])\n",
    "\n",
    "# print(f\"Total numbers of learnable/all parameters: {total_learnable}/{total_params}\")\n",
    "\n",
    "# model.encoder._V.weight.requires_grad = False\n",
    "\n",
    "# seed = 691; ignore_space = False; ignore_case = False; warm_start = True; verbose = True; \n",
    "# warm_vecs = 1*(2**0 + 0.99999); identity_ratio = 2**(-1); icf = True \n",
    "# log_label = False; nlabels = 1*(2**0); centroids = False; label_iterations = 1*(2**10) # None \n",
    "# epochs = int(np.max([int(downsample/5), 1]))*(2**5)\n",
    "# patience = 2**1\n",
    "# reload = False\n",
    "# warm_file = \"\".join([data_file[:-5] + \"-\", \n",
    "#                      f\"b_{tokenizer.config._bits}-hb_{tokenizer.config._hidden}-\",\n",
    "#                      f\"we_{int(tokenizer.config._wave_encode)}-oa_{tokenizer.config._o_agg}-ra_{tokenizer.config._r_agg}-ba_{tokenizer.config._b_agg}-\",\n",
    "#                      f\"mr_{int(tokenizer.config._mask_r)}-mb_{int(tokenizer.config._mask_b)}-md_{tokenizer.config._model_documents}-\",\n",
    "#                      f\"is_{int(ignore_space)}-ic_{int(ignore_case)}-ws_{int(warm_start)}-wv_{int(warm_vecs)}-ds_{downsample}-seed_{seed}\"])\n",
    "# tuner = SAFFUTuner(ignore_case, ignore_space, devstr, warm_vecs, identity_ratio = identity_ratio, \n",
    "#                    label_iterations = label_iterations, log_label = log_label, nlabels = nlabels, centroids = centroids, icf = icf)\n",
    "# tuner.warm_start(model, convos, dconvos, downsample*10, seed, epochs, patience, devsample = devsample, model_file = warm_file, reload = reload, verbose = verbose"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
