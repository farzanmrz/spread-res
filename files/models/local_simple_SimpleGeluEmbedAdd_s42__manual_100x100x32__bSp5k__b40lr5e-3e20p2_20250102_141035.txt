
Final configuration:
{
  "env": "local",
  "approach": "simple",
  "model_name": "SimpleGeluEmbedAdd",
  "data_dir": "../../data/farzan",
  "data_ds": "manual",
  "seed": 42,
  "THREADS": 12,
  "vocab_size": 5597,
  "vocab_space": true,
  "vocab_case": "both",
  "train_dir": "../../data/farzan/manual_train",
  "val_dir": "../../data/farzan/manual_val",
  "test_dir": "../../data/farzan/manual_test",
  "rows": 100,
  "cols": 100,
  "tokens": 32,
  "batch": 40,
  "lr": 0.005,
  "mu": 0.25,
  "epochs": 20,
  "patience": 2,
  "save_int": 10,
  "save_dir": "../models/",
  "save_name": "local_simple_SimpleGeluEmbedAdd_s42__manual_100x100x32__bSp5k__b40lr5e-3e20p2"
}

================================================================================


Epoch 0
Train Loss: 23.318557739257812, Perplexity: 1.0002332127672626
Val Loss: 18.549795150756836, Perplexity: 1.0001855151573165

Epoch 1
Train Loss: 18.809675216674805, Perplexity: 1.00018811444347
Val Loss: 15.391948699951172, Perplexity: 1.0001539313332115

Epoch 2
Train Loss: 15.63168716430664, Perplexity: 1.000156329089762
Val Loss: 12.852322578430176, Perplexity: 1.000128531485248

Epoch 3
Train Loss: 13.110466957092285, Perplexity: 1.0001311132641637
Val Loss: 10.687918663024902, Perplexity: 1.000106884898414

Epoch 4
Train Loss: 10.963469505310059, Perplexity: 1.000109640705156
Val Loss: 8.784438133239746, Perplexity: 1.000087848239763

Epoch 5
Train Loss: 9.112813949584961, Perplexity: 1.000091132291791
Val Loss: 7.075927257537842, Perplexity: 1.0000707617760718

Epoch 6
Train Loss: 7.514081001281738, Perplexity: 1.000075143633154
Val Loss: 5.525445938110352, Perplexity: 1.0000552559859368

Epoch 7
Train Loss: 6.003488063812256, Perplexity: 1.0000600366827677
Val Loss: 4.123777866363525, Perplexity: 1.0000412386289526

Epoch 8
Train Loss: 4.732602596282959, Perplexity: 1.0000473271458568
Val Loss: 2.905421733856201, Perplexity: 1.0000290546394164

Epoch 9
Train Loss: 3.6612749099731445, Perplexity: 1.0000366134193546
Val Loss: 1.9375724792480469, Perplexity: 1.0000193759125031
Model Saved

Epoch 10
Train Loss: 2.7789061069488525, Perplexity: 1.000027789447189
Val Loss: 1.2371156215667725, Perplexity: 1.0000123712327387

Epoch 11
Train Loss: 2.081183671951294, Perplexity: 1.0000208120532872
Val Loss: 0.7781156897544861, Perplexity: 1.0000077811871708

Epoch 12
Train Loss: 1.5616717338562012, Perplexity: 1.0000156168392802
Val Loss: 0.5187563300132751, Perplexity: 1.0000051875767555

Epoch 13
Train Loss: 1.2230260372161865, Perplexity: 1.0000122303351622
Val Loss: 0.3933829665184021, Perplexity: 1.0000039338374027

Epoch 14
Train Loss: 0.9685271382331848, Perplexity: 1.0000096853182847
Val Loss: 0.34083250164985657, Perplexity: 1.000003408330825

Epoch 15
Train Loss: 0.776139497756958, Perplexity: 1.0000077614250973
Val Loss: 0.32022666931152344, Perplexity: 1.0000032022718204

Epoch 16
Train Loss: 0.6612909436225891, Perplexity: 1.0000066129313017
Val Loss: 0.3141045570373535, Perplexity: 1.0000031410505035

Epoch 17
Train Loss: 0.5897329449653625, Perplexity: 1.0000058973468389
Val Loss: 0.31875649094581604, Perplexity: 1.0000031875699897

Epoch 18
Train Loss: 0.5328704714775085, Perplexity: 1.0000053287189123
Val Loss: 0.307440847158432, Perplexity: 1.0000030744131976

Epoch 19
Train Loss: 0.4951442778110504, Perplexity: 1.0000049514550364
Val Loss: 0.3247106373310089, Perplexity: 1.0000032471116451
Model Saved

TRAINING DONE at epoch 19, best epoch 18
Train Loss = 0.5328704714775085, Perplexity = 1.0000053287189123
Val Loss = 0.307440847158432, Perplexity = 1.0000030744131976
