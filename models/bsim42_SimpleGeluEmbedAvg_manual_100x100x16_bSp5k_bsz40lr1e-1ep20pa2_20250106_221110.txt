
Final configuration:
{
  "env": "bvm",
  "approach": "simple",
  "THREADS": 32,
  "seed": 42,
  "model_base": "glove50",
  "model_name": "SimpleGeluEmbedAvg",
  "rows": 100,
  "cols": 100,
  "tokens": 16,
  "data_ds": "manual",
  "data_dir": "../../../data/farzan",
  "train_dir": "../../../data/farzan/manual_train",
  "val_dir": "../../../data/farzan/manual_val",
  "test_dir": "../../../data/farzan/manual_test",
  "vocab_size": 5597,
  "vocab_space": true,
  "vocab_case": "both",
  "batch": 40,
  "lr": 0.1,
  "mu": 0.25,
  "epochs": 20,
  "patience": 2,
  "save_int": 10,
  "save_dir": "../models/",
  "save_name": "bsim42_SimpleGeluEmbedAvg_manual_100x100x16_bSp5k_bsz40lr1e-1ep20pa2"
}

================================================================================


Epoch 0
Train Loss: 1.7129079103469849, Perplexity: 1.0000171292258069
Val Loss: 0.7026445269584656, Perplexity: 1.0000070264699552

Epoch 1
Train Loss: 0.712165892124176, Perplexity: 1.0000071216842803
Val Loss: 0.4020729660987854, Perplexity: 1.000004020737744

Epoch 2
Train Loss: 0.40179795026779175, Perplexity: 1.0000040179875749
Val Loss: 0.30077892541885376, Perplexity: 1.0000030077937776

Epoch 3
Train Loss: 0.30232474207878113, Perplexity: 1.0000030232519908
Val Loss: 0.2615412175655365, Perplexity: 1.0000026154155959

Epoch 4
Train Loss: 0.2652941048145294, Perplexity: 1.0000026529445671
Val Loss: 0.237630695104599, Perplexity: 1.0000023763097745

Epoch 5
Train Loss: 0.24299323558807373, Perplexity: 1.000002429935308
Val Loss: 0.2206246554851532, Perplexity: 1.0000022062489886

Epoch 6
Train Loss: 0.22845754027366638, Perplexity: 1.0000022845780123
Val Loss: 0.21381859481334686, Perplexity: 1.000002138188234

Epoch 7
Train Loss: 0.22286847233772278, Perplexity: 1.000002228687207
Val Loss: 0.2096129208803177, Perplexity: 1.0000020961314058

Epoch 8
Train Loss: 0.2212611734867096, Perplexity: 1.0000022126141828
Val Loss: 0.18059679865837097, Perplexity: 1.0000018059696174

Epoch 9
Train Loss: 0.19221696257591248, Perplexity: 1.000001922171473
Val Loss: 0.16726061701774597, Perplexity: 1.000001672607569
Model Saved

Epoch 10
Train Loss: 0.18001489341259003, Perplexity: 1.0000018001505544
Val Loss: 0.15600605309009552, Perplexity: 1.0000015600617478

Epoch 11
Train Loss: 0.16927717626094818, Perplexity: 1.0000016927731954
Val Loss: 0.14548833668231964, Perplexity: 1.0000014548844252

Epoch 12
Train Loss: 0.15958188474178314, Perplexity: 1.0000015958201207
Val Loss: 0.13744792342185974, Perplexity: 1.0000013744801788

Epoch 13
Train Loss: 0.15308059751987457, Perplexity: 1.0000015308071468
Val Loss: 0.12930342555046082, Perplexity: 1.0000012930350914

Epoch 14
Train Loss: 0.1450899988412857, Perplexity: 1.0000014509010409
Val Loss: 0.12294352054595947, Perplexity: 1.0000012294359613

Epoch 15
Train Loss: 0.1383214294910431, Perplexity: 1.0000013832152514
Val Loss: 0.11649726331233978, Perplexity: 1.0000011649733116

Epoch 16
Train Loss: 0.13311201333999634, Perplexity: 1.0000013311210194
Val Loss: 0.11132244020700455, Perplexity: 1.0000011132250217

Epoch 17
Train Loss: 0.12860329449176788, Perplexity: 1.000001286033772
Val Loss: 0.10624691098928452, Perplexity: 1.0000010624696742

Epoch 18
Train Loss: 0.12363970279693604, Perplexity: 1.0000012363977924
Val Loss: 0.10207603871822357, Perplexity: 1.0000010207609082

Epoch 19
Train Loss: 0.11985062062740326, Perplexity: 1.0000011985069246
Val Loss: 0.09797429293394089, Perplexity: 1.0000009797434093
Model Saved

TRAINING DONE at epoch 19, best epoch 19
Train Loss = 0.11985062062740326, Perplexity = 1.0000011985069246
Val Loss = 0.09797429293394089, Perplexity = 1.0000009797434093
