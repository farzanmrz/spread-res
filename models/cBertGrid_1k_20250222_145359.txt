
Final configuration:
{
  "env": "colab",
  "approach": "bert",
  "THREADS": 10,
  "seed": 0,
  "model_base": "bert-base-cased",
  "model_name": "BertGrid",
  "rows": 100,
  "cols": 100,
  "tokens": 32,
  "data_ds": "1k",
  "data_dir": "../data",
  "train_dir": "../data/1k_train",
  "val_dir": "../data/1k_val",
  "test_dir": "../data/1k_test",
  "vocab_size": 30522,
  "hidden_size": 32,
  "num_hidden_layers": 1,
  "num_attention_heads": 1,
  "intermediate_size": 128,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "attention_probs_dropout_prob": 0.1,
  "max_position_embeddings": 64,
  "type_vocab_size": 2,
  "initializer_range": 0.02,
  "layer_norm_eps": 1e-12,
  "pad_token_id": 0,
  "gradient_checkpointing": false,
  "batch_size": 12,
  "lr": 0.001,
  "mu": 0.25,
  "epochs": 200,
  "patience": 2,
  "save_int": 50,
  "save_dir": "../models/",
  "save_name": "cBertGrid_1k"
}

================================================================================


Epoch 0
Train Loss: 1.2041476787026248, Perplexity: 1.0000100346143357
Val Loss: 0.9798264371024238, Perplexity: 1.0000081652536448

Epoch 1
Train Loss: 0.8715500008704057, Perplexity: 1.000007262943049
Val Loss: 0.6456567512618171, Perplexity: 1.000005380487402

Epoch 2
Train Loss: 0.62562055440981, Perplexity: 1.0000052135182105
Val Loss: 0.5189187145895429, Perplexity: 1.0000043243319714

Epoch 3
Train Loss: 0.5185865177147424, Perplexity: 1.0000043215636523
Val Loss: 0.4710536317692863, Perplexity: 1.000003925454636

Epoch 4
Train Loss: 0.4652921145976479, Perplexity: 1.0000038774418056
Val Loss: 0.44404176705413395, Perplexity: 1.0000037003549052

Epoch 5
Train Loss: 0.4409089535474777, Perplexity: 1.0000036742480296
Val Loss: 0.42655834390057457, Perplexity: 1.0000035546591837

Epoch 6
Train Loss: 0.421958804575365, Perplexity: 1.0000035163295538
Val Loss: 0.4099693281782998, Perplexity: 1.000003416416904

Epoch 7
Train Loss: 0.41045766357165664, Perplexity: 1.0000034204863797
Val Loss: 0.3979880495203866, Perplexity: 1.0000033165725792

Epoch 8
Train Loss: 0.3958244855279353, Perplexity: 1.0000032985428196
Val Loss: 0.38721027804745567, Perplexity: 1.000003226757523

Epoch 9
Train Loss: 0.3865704339609217, Perplexity: 1.0000032214254717
Val Loss: 0.3772527360253864, Perplexity: 1.000003143777742

Epoch 10
Train Loss: 0.38298494424392926, Perplexity: 1.000003191546295
Val Loss: 0.3672676715585921, Perplexity: 1.0000030605686132

Epoch 11
Train Loss: 0.38472562605765326, Perplexity: 1.0000032060520232
Val Loss: 0.3655854794714186, Perplexity: 1.000003046550303

Epoch 12
Train Loss: 0.37801467304799097, Perplexity: 1.000003150127237
Val Loss: 0.3623797545830409, Perplexity: 1.0000030198358478

Epoch 13
Train Loss: 0.3793057712601192, Perplexity: 1.0000031608864228
Val Loss: 0.35196512275271946, Perplexity: 1.000002933046991

Epoch 14
Train Loss: 0.38911331845308417, Perplexity: 1.0000032426162444
Val Loss: 0.3440328985452652, Perplexity: 1.0000028669449308

Epoch 15
Train Loss: 0.3748012319652002, Perplexity: 1.0000031233484774
Val Loss: 0.33495353493425584, Perplexity: 1.0000027912833533

Epoch 16
Train Loss: 0.39594865134402885, Perplexity: 1.000003299577538
Val Loss: 0.3269614709748162, Perplexity: 1.0000027246826366

Epoch 17
Train Loss: 0.3847987529501986, Perplexity: 1.000003206661416
Val Loss: 0.32173126770390403, Perplexity: 1.0000026810974916

Epoch 18
Train Loss: 0.41176133458294084, Perplexity: 1.0000034313503419
Val Loss: 0.32794668277104694, Perplexity: 1.0000027328927574

Epoch 19
Train Loss: 0.39142597789195044, Perplexity: 1.000003261888469
Val Loss: 0.323066512743632, Perplexity: 1.0000026922245635

EARLY STOPPING at epoch 19, best epoch 17
Train Loss = 0.3847987529501986, Perplexity = 1.000003206661416
Val Loss = 0.32173126770390403, Perplexity = 1.0000026810974916

TRAINING DONE at epoch 19, best epoch 17
Train Loss = 0.3847987529501986, Perplexity = 1.000003206661416
Val Loss = 0.32173126770390403, Perplexity = 1.0000026810974916
