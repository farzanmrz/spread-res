{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve and Compare Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Old Method: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1295/1295 [12:22<00:00,  1.74it/s]\n",
      "Running New Method: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1295/1295 [14:01<00:00,  1.54it/s]\n",
      "Comparing Tensors:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:03,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ x_toks lists are identical!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Comparing Tensors:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:04<00:02,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ x_masks lists are identical!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Comparing Tensors: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:05<00:00,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ y_toks lists are identical!\n",
      "\n",
      "üéâ All tensors from both methods match exactly!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import importlib\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Ensure utils and other dependencies are accessible\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "\n",
    "# Import required utilities and reload\n",
    "from utils import parseutil, setuputil\n",
    "\n",
    "importlib.reload(setuputil)\n",
    "importlib.reload(parseutil)\n",
    "\n",
    "from utils.parseutil import process_csv, process_xls, process_xlsx, test_xlsx\n",
    "from utils.setuputil import get_fileList\n",
    "\n",
    "# Define dataset name and path\n",
    "dataset_name = \"all\"\n",
    "train_dir = f\"../data/{dataset_name}_train\"\n",
    "\n",
    "# Retrieve all spreadsheet files then filter only .xls files\n",
    "all_files, _ = get_fileList(train_dir)\n",
    "xls_files = [file for file in all_files if file.lower().endswith(\".xlsx\")]\n",
    "\n",
    "# Define context window and storage for tensors\n",
    "MAX_ROWS, MAX_COLS, PAD_LENGTH = 100, 100, 32\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "# Storage for tensors from both methods\n",
    "tensor_lists = {\n",
    "    \"old\": {\"x_toks\": [], \"x_masks\": [], \"y_toks\": []},\n",
    "    \"new\": {\"x_toks\": [], \"x_masks\": [], \"y_toks\": []},\n",
    "}\n",
    "\n",
    "\n",
    "def process_files(method, tensor_dict, desc):\n",
    "    \"\"\"\n",
    "    Processes files using the given method and stores the resulting tensors.\n",
    "\n",
    "    Args:\n",
    "        method (function): The function to process the file (`process_xls` or `test_xls`).\n",
    "        tensor_dict (dict): Dictionary to store the tensors for x_toks, x_masks, and y_toks.\n",
    "        desc (str): Description for the tqdm progress bar.\n",
    "    \"\"\"\n",
    "    for file_path in tqdm(xls_files, desc=desc):\n",
    "        try:\n",
    "            x_tok, x_mask, y_tok = method(\n",
    "                file_path,\n",
    "                max_rows=MAX_ROWS,\n",
    "                max_cols=MAX_COLS,\n",
    "                pad_length=PAD_LENGTH,\n",
    "                tokenizer=tokenizer,\n",
    "                vocab=None,\n",
    "            )\n",
    "            tensor_dict[\"x_toks\"].append(x_tok)\n",
    "            tensor_dict[\"x_masks\"].append(x_mask)\n",
    "            tensor_dict[\"y_toks\"].append(y_tok)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_path} with {method.__name__}: {e}\")\n",
    "\n",
    "\n",
    "# Run both methods\n",
    "process_files(process_xlsx, tensor_lists[\"old\"], \"Running Old Method\")\n",
    "process_files(test_xlsx, tensor_lists[\"new\"], \"Running New Method\")\n",
    "\n",
    "\n",
    "def compare_tensor_lists(list1, list2, name, filenames):\n",
    "    \"\"\"\n",
    "    Compares two lists of tensors element-wise and stops at the first mismatch.\n",
    "\n",
    "    Args:\n",
    "        list1 (list): First list of tensors.\n",
    "        list2 (list): Second list of tensors.\n",
    "        name (str): Name of the tensor type being compared.\n",
    "        filenames (list): List of filenames corresponding to the sheets.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if tensors match, False otherwise.\n",
    "    \"\"\"\n",
    "    if len(list1) != len(list2):\n",
    "        print(f\"‚ùå Mismatch in {name} length: {len(list1)} vs {len(list2)}\")\n",
    "        return False\n",
    "\n",
    "    for i, (tensor1, tensor2) in enumerate(zip(list1, list2)):\n",
    "        if tensor1.shape != tensor2.shape:\n",
    "            print(\n",
    "                f\"‚ùå Shape mismatch in {name}[{i}]: {tensor1.shape} vs {tensor2.shape}\"\n",
    "            )\n",
    "            return False\n",
    "\n",
    "        # Find the first mismatched element\n",
    "        diff_indices = (tensor1 != tensor2).nonzero(as_tuple=True)\n",
    "\n",
    "        if diff_indices[0].numel() > 0:  # If there are mismatches\n",
    "            row, col = diff_indices[0][0].item(), diff_indices[1][0].item()\n",
    "\n",
    "            print(f\"\\n‚ùå First mismatch in {name}[{i}] at:\")\n",
    "            print(f\"   üìÇ Sheet index: {i} (File: {filenames[i]})\")\n",
    "            print(f\"   üìå Row: {row}, Col: {col}\")\n",
    "\n",
    "            if name == \"x_toks\":\n",
    "                # Decode tokens for x_toks tensor\n",
    "                old_tokens = tokenizer.convert_ids_to_tokens(\n",
    "                    tensor1[row, col, :].tolist()\n",
    "                )\n",
    "                new_tokens = tokenizer.convert_ids_to_tokens(\n",
    "                    tensor2[row, col, :].tolist()\n",
    "                )\n",
    "\n",
    "                print(f\"\\nüî§ Decoded Tokens from Old Method: {old_tokens}\")\n",
    "                print(f\"üî§ Decoded Tokens from New Method: {new_tokens}\")\n",
    "\n",
    "            print(f\"\\nüìä Old method tensor: {tensor1[row, col, :].tolist()}\")\n",
    "            print(f\"\\nüìä New method tensor: {tensor2[row, col, :].tolist()}\")\n",
    "\n",
    "            # Stop further processing after first mismatch\n",
    "            return False\n",
    "\n",
    "    print(f\"‚úÖ {name} lists are identical!\")\n",
    "    return True\n",
    "\n",
    "\n",
    "# Compare all three tensor lists with tqdm progress bar\n",
    "all_match = True\n",
    "\n",
    "with tqdm(total=len([\"x_toks\", \"x_masks\", \"y_toks\"]), desc=\"Comparing Tensors\") as pbar:\n",
    "    for tensor_name in [\"x_toks\", \"x_masks\", \"y_toks\"]:\n",
    "        match = compare_tensor_lists(\n",
    "            tensor_lists[\"old\"][tensor_name],\n",
    "            tensor_lists[\"new\"][tensor_name],\n",
    "            tensor_name,\n",
    "            xls_files,\n",
    "        )\n",
    "        all_match &= match\n",
    "        pbar.update(1)  # Update progress bar after each comparison\n",
    "\n",
    "if all_match:\n",
    "    print(\"\\nüéâ All tensors from both methods match exactly!\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è Differences detected in tensor values!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vmenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
